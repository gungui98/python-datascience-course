Commit ID,Commit Message,Author Name,Author Email,Changed Files,Pass all checks,Day,Month,Year
b8016e442ecb132d6dafece5d224d9b5e8fde2cd,"Fixes to #3295 Improve RNN-T streaming decoding (#3379)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3379

Fixes `RNNTBeamSearch.infer`'s docstring and removes unused import from tutorial.

Reviewed By: mthrok

Differential Revision: D46227174

fbshipit-source-id: 7c1c3f05a6476cb0437622dea6f3ae6cb3ea9468",Jeff Hwang,jeffhwang@meta.com,"['examples/tutorials/online_asr_tutorial.py', 'torchaudio/models/rnnt_decoder.py']",False,31,5,2023
caf3ac0749eaca441f3f2d517e0dd56a78c8840c,"Disable failing GPU unit test (#3384)

Summary:
Disable failing GPU unit test.
See associated issue: https://github.com/pytorch/audio/issues/3376

Pull Request resolved: https://github.com/pytorch/audio/pull/3384

Reviewed By: mthrok

Differential Revision: D46279324

Pulled By: atalman

fbshipit-source-id: 3a606bb992e0261451f48d1fb458e054f7fd5583",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.github/workflows/unittest-linux-gpu.yml', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/io/stream_reader_test.py', 'test/torchaudio_unittest/prototype/conformer_wav2vec2_test.py', 'test/torchaudio_unittest/prototype/ssl_model_test.py']",False,30,5,2023
9cdf26fdb9ec9cab933ea9a0286a68f77eb7e0bc,"Use const reference (#3389)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3389

Adopt more of const reference in sox source code.

Differential Revision: D46264068

fbshipit-source-id: 809d34a6e16f621c856d4278ef7ce45a5868a717",Moto Hira,moto@meta.com,"['torchaudio/csrc/sox/types.cpp', 'torchaudio/csrc/sox/types.h', 'torchaudio/csrc/sox/utils.cpp', 'torchaudio/csrc/sox/utils.h']",False,30,5,2023
a81b0ed23f0351f86b73fca32522cae7015aad6d,"Simplify sox namespace (#3383)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3383

This commit reduces `torchaudio::sox_*` namespace into `torchaudio::sox`.
Also put Pybind11 registration and TorchBind registration into anonymous namescope.

Differential Revision: D46257367

fbshipit-source-id: 0f0f181eaa72036916e223263daf4b7c298fca0d",Moto Hira,moto@meta.com,"['torchaudio/csrc/sox/effects.cpp', 'torchaudio/csrc/sox/effects.h', 'torchaudio/csrc/sox/effects_chain.cpp', 'torchaudio/csrc/sox/effects_chain.h', 'torchaudio/csrc/sox/io.cpp', 'torchaudio/csrc/sox/io.h', 'torchaudio/csrc/sox/pybind/effects.cpp', 'torchaudio/csrc/sox/pybind/effects.h', 'torchaudio/csrc/sox/pybind/effects_chain.cpp', 'torchaudio/csrc/sox/pybind/effects_chain.h', 'torchaudio/csrc/sox/pybind/io.cpp', 'torchaudio/csrc/sox/pybind/io.h', 'torchaudio/csrc/sox/pybind/pybind.cpp', 'torchaudio/csrc/sox/pybind/utils.cpp', 'torchaudio/csrc/sox/pybind/utils.h', 'torchaudio/csrc/sox/types.cpp', 'torchaudio/csrc/sox/types.h', 'torchaudio/csrc/sox/utils.cpp', 'torchaudio/csrc/sox/utils.h']",True,30,5,2023
6425d46cfc15b5a7073a30cee4024434eeeac7a0,"[Nova] Windows CPU Unittests on Nova (#3329)

Summary:
Continuing with the job migrations from CCI to Nova, this PR introduces the Windows CPU Unittest job as a Nova workflow.

The job is passing: https://github.com/pytorch/audio/actions/runs/5094569687/jobs/9159020192?pr=3329.

Pull Request resolved: https://github.com/pytorch/audio/pull/3329

Reviewed By: huydhn

Differential Revision: D46265649

Pulled By: atalman

fbshipit-source-id: 7659dfbcc8ad400f2e109ff64530e1f768e82ef9",Omkar Salpekar,osalpekar@fb.com,"['.circleci/unittest/windows/scripts/install.sh', '.circleci/unittest/windows/scripts/run_test.sh', '.circleci/unittest/windows/scripts/set_cuda_envs.sh', '.circleci/unittest/windows/scripts/setup_env.sh', '.github/workflows/unittest-windows-cpu.yml']",False,29,5,2023
af932cc7cea4dae15892d9deb4a6bebb8656fa8b,"Fix AudioEffector for mulaw (#3372)

Summary:
When encoding audio with mulaw, the resulting data does not have header, and the StreamReader defaults to 16k Hz, which can strech/shrink the resulting waveform.

Pull Request resolved: https://github.com/pytorch/audio/pull/3372

Reviewed By: hwangjeff

Differential Revision: D46234772

Pulled By: mthrok

fbshipit-source-id: 942c89a8cfe29b0b6f57b3e5b6c9dfd3524ca552",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/effector_test.py', 'torchaudio/io/_effector.py']",False,27,5,2023
1b05ca7e9f4330572eea7e6d49b119bcbf7ea679,"Fix encoding g722 format (#3373)

Summary:
g722 format only supports 16k Hz, but AVCodec does not list this. The implementation does not insert resampling and the resulting audio can be slowed down or sped up.

Pull Request resolved: https://github.com/pytorch/audio/pull/3373

Reviewed By: hwangjeff

Differential Revision: D46233181

Pulled By: mthrok

fbshipit-source-id: 902b3f862a8f7269dc35bc871e868b0e78326c6c",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp']",False,26,5,2023
c120f316bb66b781e143ba3fac14684931e3cc8a,"Use the same CUDNN version on Windows as PyTorch (#3380)

Summary:
11.7 uses 8.5.0; 11.8 uses 8.7.0; 12.1 uses 8.8.1.  Otherwise, Windows vision job (8.5.0) would overwrite the CUDNN version setup by PyTorch (8.7.0) leading to this flaky failures https://github.com/pytorch/pytorch/actions/runs/5088860652/jobs/9146641450

```
RuntimeError: cuDNN version incompatibility: PyTorch was compiled  against (8, 7, 0) but found runtime version (8, 5, 0). PyTorch already comes bundled with cuDNN. One option to resolving this error is to ensure PyTorch can find the bundled cuDNN.
```

Pull Request resolved: https://github.com/pytorch/audio/pull/3380

Reviewed By: atalman

Differential Revision: D46236286

Pulled By: huydhn

fbshipit-source-id: 9ca12d5068c3029688347d52c5c284488f33728d",Huy Do,huydhn@gmail.com,['packaging/windows/internal/cuda_install.bat'],False,26,5,2023
5c0249b0257ff95411e8b92e3d75a62e05a7e92e,"Use cuda 11.8 for circleci tests (#3381)

Summary:
Use cuda 11.8 for circleci tests.
11.7 was deprecated

Pull Request resolved: https://github.com/pytorch/audio/pull/3381

Reviewed By: osalpekar

Differential Revision: D46236223

Pulled By: atalman

fbshipit-source-id: 6d6a8e09603807a07241f31c1bd1e6d3a2b67d9d",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,26,5,2023
05649ca389d66eb280cf1b6ddd161d9878bc8e56,"Temporarily remove test for extract_features (#3378)

Summary:
The tests failed for several bundles. Remove them and will re-add once the root cause is figured out.

Pull Request resolved: https://github.com/pytorch/audio/pull/3378

Reviewed By: atalman

Differential Revision: D46230884

Pulled By: nateanl

fbshipit-source-id: 42056a29b2ec2335268b273d3e37fb517035be92",Zhaoheng Ni,zni@meta.com,['test/torchaudio_unittest/models/wav2vec2/huggingface_intergration_test.py'],False,26,5,2023
37779ef91012adc5a1f8bc6bb85687eaff6fd42a,"Revert ""Upgrade to FFmpeg5 (#3298)"" (#3377)

Summary:
This reverts commit d38a7854234b1a928ee70e62459a4b361b4e1019.

This is temporary revert to unblock unit test migration from circleci to github

Pull Request resolved: https://github.com/pytorch/audio/pull/3377

Reviewed By: mthrok

Differential Revision: D46230498

Pulled By: atalman

fbshipit-source-id: 000d8a9ca00750fc1ca61f4c2cdd6e930a5ce46d",atalman,atalman@fb.com,"['.circleci/unittest/linux/scripts/setup_env.sh', '.circleci/unittest/windows/scripts/setup_env.sh', '.github/workflows/build_docs.yml', '.github/workflows/unittest-linux-gpu.yml', 'docs/source/installation.rst', 'examples/tutorials/device_asr.py', 'examples/tutorials/effector_tutorial.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streamreader_basic_tutorial.py', 'examples/tutorials/streamwriter_advanced.py', 'examples/tutorials/streamwriter_basic_tutorial.py', 'packaging/ffmpeg/build.sh']",False,26,5,2023
9fc0dcaaa7644f07db69187fc6c0ae23cfdc582f,"Improve RNN-T streaming decoding (#3295)

Summary:
This commit fixes the following issues affecting streaming decoding quality
1. The `init_b` hypothesis is only regenerated from blank token if no initial hypotheses are provided.
2. Allows the decoder to receive top-K hypothesis to continue decoding from, instead of using just the top hypothesis at each decoding step.  This dramatically affects decoding quality especially for speech with long pauses and disfluencies.
3. Some minor errors regarding shape checking for length.

This also means that the resulting output is the entire transcript up until that time step, instead of just the incremental change in transcript.

Pull Request resolved: https://github.com/pytorch/audio/pull/3295

Reviewed By: nateanl

Differential Revision: D46216113

Pulled By: hwangjeff

fbshipit-source-id: 8f7efae28dcca4a052f434ca55a2795c9e5ec0b0",Lakshmi Krishnan,102545420+lakshmi-speak@users.noreply.github.com,"['examples/asr/emformer_rnnt/pipeline_demo.py', 'examples/tutorials/online_asr_tutorial.py', 'test/torchaudio_unittest/models/rnnt_decoder/rnnt_decoder_test_impl.py', 'torchaudio/models/rnnt_decoder.py']",False,26,5,2023
c6624fa6aa0154f5968b4bb40bd57c56349c41d7,"Add LRS3 AV-ASR recipe (#3278)

Summary:
This PR adds AV-ASR recipe which contains sample implementations of training and evaluation pipelines for RNNT based automatic, visual, and audio-visual (ASR, VSR, AV-ASR) models on LRS3. This repository includes both streaming/non-streaming modes.

CC stavros99 xiaohui-zhang YumengTao mthrok nateanl hwangjeff

Pull Request resolved: https://github.com/pytorch/audio/pull/3278

Reviewed By: nateanl

Differential Revision: D46121550

Pulled By: mpc001

fbshipit-source-id: bb44b97ae25e87df2a73a707008be46af4ad0fc6",Pingchuan Ma,pingchuanma@fb.com,"['examples/asr/avsr_rnnt/README.md', 'examples/asr/avsr_rnnt/average_checkpoints.py', 'examples/asr/avsr_rnnt/data_module.py', 'examples/asr/avsr_rnnt/data_prep/README.md', 'examples/asr/avsr_rnnt/doc/lip_white.png', 'examples/asr/avsr_rnnt/eval.py', 'examples/asr/avsr_rnnt/lightning.py', 'examples/asr/avsr_rnnt/lightning_av.py', 'examples/asr/avsr_rnnt/lrs3.py', 'examples/asr/avsr_rnnt/models/conformer_rnnt.py', 'examples/asr/avsr_rnnt/models/emformer_rnnt.py', 'examples/asr/avsr_rnnt/models/fusion.py', 'examples/asr/avsr_rnnt/models/resnet.py', 'examples/asr/avsr_rnnt/models/resnet1d.py', 'examples/asr/avsr_rnnt/schedulers.py', 'examples/asr/avsr_rnnt/train.py', 'examples/asr/avsr_rnnt/train_spm.py', 'examples/asr/avsr_rnnt/transforms.py']",False,25,5,2023
f41ba26d7d820165036e74529ec869780d62b24c,"Add StreamReader/Writer custom IO to doc (#3367)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3367

Reviewed By: nateanl

Differential Revision: D46148139

Pulled By: mthrok

fbshipit-source-id: 50f297ac69bb95562976eb452e4e382b8c064c3c",moto,855818+mthrok@users.noreply.github.com,"['docs/source/libtorchaudio.stream_reader.rst', 'docs/source/libtorchaudio.stream_writer.rst', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,24,5,2023
8b85ca5d326465a4344decc63653cb539a1b2f66,"Fix build doc (#3349)

Summary:
Follow-up https://github.com/pytorch/audio/issues/3045
- Revert the removal of HW acceleration doc
- comment out FFmpeg CLI test run

Pull Request resolved: https://github.com/pytorch/audio/pull/3349

Reviewed By: nateanl

Differential Revision: D46121899

Pulled By: mthrok

fbshipit-source-id: dfc030a69f05addec73637cfb6a720c184e37323",moto,855818+mthrok@users.noreply.github.com,"['.github/workflows/build_docs.yml', 'docs/source/index.rst']",False,24,5,2023
71b2634b10bd126c0ef228012aa02c831db68d0e,"Update smoke test (#3346)

Summary:
* Delay the import of torchaudio until the CLI options are parsed.
* Add option to set log level to DEBUG so that it's easy to see the issue with external libraries.

Pull Request resolved: https://github.com/pytorch/audio/pull/3346

Reviewed By: nateanl

Differential Revision: D46022546

Pulled By: mthrok

fbshipit-source-id: 9f988bbd770c2fd2bb260c3cfe02b238a9da2808",moto,855818+mthrok@users.noreply.github.com,['test/smoke_test/smoke_test.py'],True,24,5,2023
a79cf3bafdd35af1e50c2e6df176356603c27122,"Amend commit to gh-pages branch (#3345)

Summary:
This commit changes the way doc is pushed.
It ammends instead of adding a new commit.

Currently each commit in gh-pages contain like 100MB of data. gh-pages branch is fetched by default when `git clone`. So the size of torchaudio repo grows significantly.

Pull Request resolved: https://github.com/pytorch/audio/pull/3345

Reviewed By: nateanl

Differential Revision: D46136612

Pulled By: mthrok

fbshipit-source-id: 39479ee5d1a6888254ef50f0db252453d976d183",moto,855818+mthrok@users.noreply.github.com,['.github/workflows/build_docs.yml'],False,24,5,2023
5a6f4eba022a330e4cb9277ee204dee4eb06790c,"Remove CUDA 11.7 builds; replace with 11.8 (#3360)

Summary:
CC atalman malfet

Pull Request resolved: https://github.com/pytorch/audio/pull/3360

Reviewed By: mthrok

Differential Revision: D46150898

Pulled By: atalman

fbshipit-source-id: 985a0ef69406f48fb15f239d6b16616c0a5379f5",pbialecki,piotr.bialecki@hotmail.de,"['.circleci/config.yml', '.circleci/regenerate.py', '.github/workflows/build_docs.yml', '.github/workflows/unittest-linux-gpu.yml', 'packaging/windows/internal/cuda_install.bat']",False,24,5,2023
8690e6ec9b419299076ef333d9d25d1f59fe92b1,"Resolve lint issue on LaTeX (#3366)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3366

Reviewed By: nateanl

Differential Revision: D46136238

Pulled By: mthrok

fbshipit-source-id: 3432f5d007293831bab21460a79ae26b1bbc81a8",moto,855818+mthrok@users.noreply.github.com,['torchaudio/functional/functional.py'],False,24,5,2023
7d0f33699c5ebd60de028ee95c0faf287f764510,"[BugFix] Fix extract_features method for WavLM models (#3350)

Summary:
resolve https://github.com/pytorch/audio/issues/3347

`position_bias` is ignored in `extract_features` method, this doesn't affect Wav2Vec2 or HuBERT models, but it changes the output of transformer layers (except the first layer) in WavLM model. This PR fixes it by adding `position_bias` to the method.

Pull Request resolved: https://github.com/pytorch/audio/pull/3350

Reviewed By: mthrok

Differential Revision: D46112148

Pulled By: nateanl

fbshipit-source-id: 3d21aa4b32b22da437b440097fd9b00238152596",Zhaoheng Ni,zni@meta.com,"['test/torchaudio_unittest/models/wav2vec2/huggingface_intergration_test.py', 'torchaudio/models/wav2vec2/components.py']",False,23,5,2023
fce54fd121d69b06c10463c036dc6b0e6f9845e1,"[Nova] MacOS Unittests on Nova (#3324)

Summary:
As discussed in the [Torchaudio Migration Proposal](https://docs.google.com/document/d/1PF8biwiGzsjzfEBM78mlLiRrkcsGsvuYkeqkI66Ym8A/edit), this PR moves MacOS unittest job to Nova tooling. Note that this does not touch anything within the existing CircleCI job at the moment.

Passing job: https://github.com/pytorch/audio/actions/runs/4932497525/jobs/8815581251?pr=3324

Pull Request resolved: https://github.com/pytorch/audio/pull/3324

Reviewed By: atalman, mthrok

Differential Revision: D46113524

Pulled By: osalpekar

fbshipit-source-id: d048d300489f992fa187628cb6744d95ab4fb68a",Omkar Salpekar,osalpekar@fb.com,"['.github/workflows/unittest-macos-cpu.yml', 'test/torchaudio_unittest/common_utils/case_utils.py']",False,23,5,2023
fa59855f9535c9ebbbbdb83e65a29578e89e0b68,"Fix cuda test failure (#3363)

Summary:
Fix https://github.com/pytorch/audio/issues/3361

When adding FunctionalCUDAOnlyTest, the class should inherit from `TestBaseMixin` instead of `Functional`

Pull Request resolved: https://github.com/pytorch/audio/pull/3363

Reviewed By: atalman, osalpekar

Differential Revision: D46112084

Pulled By: nateanl

fbshipit-source-id: 67c6472fda98cb718e0fc53ab248beda745feab5",Zhaoheng Ni,zni@meta.com,['test/torchaudio_unittest/functional/functional_impl.py'],False,23,5,2023
d850ff61643c00b6517b00011f4d52e1bc3897d2,"Unset BPS when using sox vorbis (#3359)

Summary:
When saving audio with vorbis, BPS should not be specified, otherwise warnings that cannot be turned off are shown.

Address: https://github.com/pytorch/audio/issues/3358

Pull Request resolved: https://github.com/pytorch/audio/pull/3359

Reviewed By: nateanl

Differential Revision: D46095037

Pulled By: mthrok

fbshipit-source-id: 6885a12dc3ec84bf39f0159ee58d1a2a87cff7e4",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/sox/utils.cpp'],False,23,5,2023
2255a0fc9f6b204f152da7920f116a0c22a1da35,"[Nova] Linux CPU Unittests to Nova (#3323)

Summary:
As discussed in the [Torchaudio Migration Proposal](https://docs.google.com/document/d/1PF8biwiGzsjzfEBM78mlLiRrkcsGsvuYkeqkI66Ym8A/edit), this PR moves the Linux CPU unittest job to Nova tooling. Note that this does not disable the existing CircleCI job at the moment.

Passing Job: https://github.com/pytorch/audio/actions/runs/4986115298/jobs/8926499354?pr=3323

Pull Request resolved: https://github.com/pytorch/audio/pull/3323

Reviewed By: atalman, mthrok

Differential Revision: D46113506

Pulled By: osalpekar

fbshipit-source-id: 1778c360e17b9d02c63bcc60100834c75798d380",Omkar Salpekar,osalpekar@fb.com,"['.circleci/unittest/linux/scripts/run_test.sh', '.github/workflows/unittest-linux-cpu.yml']",False,23,5,2023
f046f7e3c1ed2133b59b8c0aca8e51311496500e,"[audio] add CTC forced alignment API tutorial to torchaudio (#3356)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3356

move the forced aligner tutorial to torchaudio, with some formatting changes

Reviewed By: mthrok

Differential Revision: D46060238

fbshipit-source-id: d90e7db5669a58d1e9ef5c2ec3c6d175b4e394ec",Xiaohui Zhang,xiaohuizhang@meta.com,"['docs/source/index.rst', 'examples/tutorials/ctc_forced_alignment_api_tutorial.py']",False,23,5,2023
150234bd6ad9f78c3603168c3f9371651fba5054,"Cleaning up Deprecated Jobs from CCI Config (#3340)

Summary:
Cleaning up CCI configs that are no longer used.

Pull Request resolved: https://github.com/pytorch/audio/pull/3340

Reviewed By: mthrok

Differential Revision: D46077882

Pulled By: osalpekar

fbshipit-source-id: 0dce08fc14b5efc4517ab1f559e7ef7eb245af64",Omkar Salpekar,osalpekar@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py']",False,22,5,2023
c0702338f35f42d12e371b8f3bcb914b77470dd0,"Update forced_align document (#3357)

Summary:
- Fix latex formula rendering issue
- Add `devices` and `properties` tags
- Fix grammar

Pull Request resolved: https://github.com/pytorch/audio/pull/3357

Reviewed By: mthrok

Differential Revision: D46068633

Pulled By: nateanl

fbshipit-source-id: 80cb84508396fbcaf81c068228d46a24bb63b975",Zhaoheng Ni,zni@meta.com,['torchaudio/functional/functional.py'],False,22,5,2023
8a893fb3bbcb4b9707c7496b5e7547a0a6b2e288,"Fix CPU kernel of forced_align function (#3354)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3354

when start ==0, the first item instead of Sth item of t row in backPtr_a should be 0.

Reviewed By: xiaohui-zhang

Differential Revision: D46059971

fbshipit-source-id: 89933134878513034eae033764b19f8562f24cb8",Zhaoheng Ni,zni@meta.com,"['test/torchaudio_unittest/functional/functional_impl.py', 'torchaudio/csrc/forced_align/cpu/compute.cpp']",False,22,5,2023
011f7f3dffb3ac5a5520dac60a1f800056a81e48,"Add doc for forced_align (#3355)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3355

Reviewed By: xiaohui-zhang

Differential Revision: D46060254

Pulled By: nateanl

fbshipit-source-id: c2e44f994739755daf049fe350dd24a987a9cc29",Zhaoheng Ni,zni@meta.com,['docs/source/functional.rst'],False,22,5,2023
f9b4f74fd5e8a3ec92d77b20102d187090a8ad15,"Revert D45960556: add CTC forced alignment API tutorial to torchaudio

Differential Revision:
D45960556

Original commit changeset: 93f2271f7130

Original Phabricator Diff: D45960556

fbshipit-source-id: d22883fbcf9c5f2bb5d49274bcc194bdffaca72a",Moto Hira,moto@fb.com,['examples/tutorials/ctc_forced_aligment_api_tutorial.py'],False,21,5,2023
93adc3e4396dd1b83ed556fae503a9ba4a471273,"add CTC forced alignment API tutorial to torchaudio (#3351)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3351

move the forced aligner tutorial to torchaudio, with some formatting changes

Reviewed By: vineelpratap, nateanl

Differential Revision: D45960556

fbshipit-source-id: 93f2271f71307404e6a7732385cf7d646dc8ceaa",Xiaohui Zhang,xiaohuizhang@meta.com,['examples/tutorials/ctc_forced_aligment_api_tutorial.py'],False,21,5,2023
e7935cff440360e29116fcd28da4c0ddc770b866,"[audio][PR] Add forced_align function to torchaudio (#3348)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3348

 The pull request adds a CTC-based forced alignment function that supports both CPU and CUDA deviced. The function takes the CTC emissions and target labels as inputs and generates the corresponding labels for each frame.

Reviewed By: vineelpratap, xiaohui-zhang

Differential Revision: D45867265

fbshipit-source-id: 3e25b06bf9bc8bb1bdcdc08de7f4434d912154cb",Zhaoheng Ni,zni@meta.com,"['CMakeLists.txt', 'test/torchaudio_unittest/functional/functional_cuda_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'tools/setup_helpers/extension.py', 'torchaudio/_extension/__init__.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/forced_align/compute.cpp', 'torchaudio/csrc/forced_align/compute.h', 'torchaudio/csrc/forced_align/cpu/compute.cpp', 'torchaudio/csrc/forced_align/gpu/compute.cu', 'torchaudio/csrc/pybind/pybind.cpp', 'torchaudio/csrc/utils.cpp', 'torchaudio/csrc/utils.h', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py']",False,20,5,2023
0db5ab2558232c6b29f4e98e0e9d007b49d28960,"Build and use GPU-enabled FFmpeg in doc CI (#3045)

Summary:
This commit add the step to build FFmpeg with GPU decoder in build_doc job so that we can use GPU decoder/encoder in documentations.

Pull Request resolved: https://github.com/pytorch/audio/pull/3045

Reviewed By: nateanl

Differential Revision: D45965739

Pulled By: mthrok

fbshipit-source-id: c167eb3ef347860a51efa906068fa2daa556f017",moto,855818+mthrok@users.noreply.github.com,"['.github/workflows/build_docs.yml', 'docs/source/index.rst']",False,19,5,2023
72d3fe0951c27a5ff665f270f36e0d5f51c50359,"Improve the performance of YUV420P frame conversion (#3342)

Summary:
This commit improve the performance of conversions of YUV420P format from AVFrame to torch Tensor.

It changes two things;
1. Change the implementation of nearest-neighbor upsampling from `torch::nn::functional::interpolate` to manual data copy.
2.  Get rid of intermediate UV plane copy

The following compares the time it takes to process 30 seconds of YUV420P frame at 25 FPS of resolution 320x240. The measurement times are sorted by values.

Some observations
* `torch::nn::functional::interpolate` with `torch::kNearest` option is not as fast as copying data manually.
* switching from `interpolate` to manual data copy reduces the variance.

run | main | 1 | 1+2 | improvement (from main to 1+2)
-- | -- | -- | -- | --
1 | 0.452250583 | 0.417490125 | 0.40155375 | 11.21%
2 | 0.462039958 | 0.42006675 | 0.401764125 | 13.05%
3 | 0.463067666 | 0.42416 | 0.402651334 | 13.05%
4 | 0.464228166 | 0.424545458 | 0.402985667 | 13.19%
5 | 0.465777375 | 0.425629208 | 0.405604625 | 12.92%
6 | 0.469628666 | 0.427044333 | 0.40628525 | 13.49%
7 | 0.475935125 | 0.42805875 | 0.406412167 | 14.61%
8 | 0.482277667 | 0.429921209 | 0.407279 | 15.55%
9 | 0.496695208 | 0.431182792 | 0.442013791 | 11.01%
10 | 0.546653625 | 0.541639584 | 0.4711585 | 13.81%

[second]

Increasing the resolution, the improvement is smaller but is consistent.

run | main | 1+2 | improvement
-- | -- | -- | --
1 | 4.032393 | 3.991784667 | 1.01%
2 | 4.052248084 | 3.992672208 | 1.47%
3 | 4.07705575 | 4.000541666 | 1.88%
4 | 4.143954792 | 4.020671584 | 2.98%
5 | 4.170711959 | 4.025753125 | 3.48%
6 | 4.240229292 | 4.045504875 | 4.59%
7 | 4.267384042 | 4.045588125 | 5.20%
8 | 4.277025958 | 4.061980083 | 5.03%
9 | 4.312192042 | 4.163251959 | 3.45%
10 | 4.406109875 | 4.312560334 | 2.12%

<details><summary>code</summary>

```python
import time

from torchaudio.io import StreamReader

def test():
    r = StreamReader(src=""testsrc=duration=30"", format=""lavfi"")
    # r = StreamReader(src=""testsrc=duration=30:size=1080x720"", format=""lavfi"")
    r.add_video_stream(-1, filter_desc=""format=yuv420p"")
    t0 = time.monotonic()
    r.process_all_packets()
    elapsed = time.monotonic() - t0
    print(elapsed)

for _ in range(10):
    test()
```
</details>

<details><summary>env</summary>

```
PyTorch version: 2.1.0.dev20230325
Is debug build: False
CUDA used to build PyTorch: None
ROCM used to build PyTorch: N/A

OS: macOS 13.3.1 (arm64)
GCC version: Could not collect
Clang version: 14.0.6
CMake version: version 3.22.1
Libc version: N/A

Python version: 3.9.16 (main, Mar  8 2023, 04:29:24)  [Clang 14.0.6 ] (64-bit runtime)
Python platform: macOS-13.3.1-arm64-arm-64bit
Is CUDA available: False
CUDA runtime version: No CUDA
CUDA_MODULE_LOADING set to: N/A
GPU models and configuration: No CUDA
Nvidia driver version: No CUDA
cuDNN version: No CUDA
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Apple M1

Versions of relevant libraries:
[pip3] torch==2.1.0.dev20230325
[pip3] torchaudio==2.1.0a0+541b525
[conda] pytorch                   2.1.0.dev20230325         py3.9_0    pytorch-nightly
[conda] torchaudio                2.1.0a0+541b525           dev_0    <develop>
```

</details>

Pull Request resolved: https://github.com/pytorch/audio/pull/3342

Reviewed By: xiaohui-zhang

Differential Revision: D45947716

Pulled By: mthrok

fbshipit-source-id: 17e5930f57544b4f2e48a9b2185464694a88ab68",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/conversion.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.h']",False,17,5,2023
c11661e063e015d5ed9750babc398329f58c7069,"Improve the performance of NV12 frame conversion (#3344)

Summary:
Similar to https://github.com/pytorch/audio/pull/3342, this commit improves the performance of NV12 frame conversion.

It changes two things;

- Change the implementation of nearest-neighbor upsampling from `torch::nn::functional::interpolate` to manual data copy.
- Get rid of intermediate UV plane copy

with 320x240

run | main | pr | improvement
-- | -- | -- | --
1 | 0.600671417 | 0.464993125 | 22.59%
2 | 0.638846084 | 0.456763542 | 28.50%
3 | 0.64158175 | 0.458295333 | 28.57%
4 | 0.649868584 | 0.455450583 | 29.92%
5 | 0.612171333 | 0.462435625 | 24.46%
6 | 0.6128095 | 0.456716166 | 25.47%
7 | 0.632084583 | 0.463357083 | 26.69%
8 | 0.610733083 | 0.46148625 | 24.44%
9 | 0.613825834 | 0.4559555 | 25.72%
10 | 0.653857458 | 0.455375375 | 30.36%

[second]

with 1080x720 video

run | main | pr | improvement
-- | -- | -- | --
1 | 4.984154333 | 4.21090375 | 15.51%
2 | 4.988090625 | 4.239649375 | 15.00%
3 | 4.988896375 | 4.227277458 | 15.27%
4 | 4.998186584 | 4.161077042 | 16.75%
5 | 5.06180425 | 4.191672584 | 17.19%
6 | 5.108769667 | 4.198468458 | 17.82%
7 | 5.151363625 | 4.181942167 | 18.82%
8 | 5.199527875 | 4.239319084 | 18.47%
9 | 5.224903708 | 4.194901959 | 19.71%
10 | 5.333422583 | 4.320925792 | 18.98%

[second]

<details><summary>code</summary>

```python
import time

from torchaudio.io import StreamReader

def test():
    r = StreamReader(src=""testsrc=duration=30"", format=""lavfi"")
    # r = StreamReader(src=""testsrc=duration=30:size=1080x720"", format=""lavfi"")
    r.add_video_stream(-1, filter_desc=""format=nv12"")
    t0 = time.monotonic()
    r.process_all_packets()
    elapsed = time.monotonic() - t0
    print(elapsed)

for _ in range(10):
    test()
```
</details>

<details><summary>env</summary>

```
PyTorch version: 2.1.0.dev20230325
Is debug build: False
CUDA used to build PyTorch: None
ROCM used to build PyTorch: N/A

OS: macOS 13.3.1 (arm64)
GCC version: Could not collect
Clang version: 14.0.6
CMake version: version 3.22.1
Libc version: N/A

Python version: 3.9.16 (main, Mar  8 2023, 04:29:24)  [Clang 14.0.6 ] (64-bit runtime)
Python platform: macOS-13.3.1-arm64-arm-64bit
Is CUDA available: False
CUDA runtime version: No CUDA
CUDA_MODULE_LOADING set to: N/A
GPU models and configuration: No CUDA
Nvidia driver version: No CUDA
cuDNN version: No CUDA
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Apple M1

Versions of relevant libraries:
[pip3] torch==2.1.0.dev20230325
[pip3] torchaudio==2.1.0a0+541b525
[conda] pytorch                   2.1.0.dev20230325         py3.9_0    pytorch-nightly
[conda] torchaudio                2.1.0a0+541b525           dev_0    <develop>
```

</details>

Pull Request resolved: https://github.com/pytorch/audio/pull/3344

Reviewed By: xiaohui-zhang

Differential Revision: D45948511

Pulled By: mthrok

fbshipit-source-id: ae9b300cbcb4295f3f7470736f258280005a21e5",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/conversion.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.h']",False,17,5,2023
3ffd76c84bb48841c5d1f5e773fba9c5c71662d3,"Fix for breadcrumbs displaying ""Old version (stable)"" on Nightly build (#3333)

Summary:
Previously, `breadcrumbs.html` identified a nightly build version by the prefix ""Nightly"" which would normally be prepended to the version in `conf.py`. However, the version string is coming through without the ""Nightly"" prefix, so this change causes `breadcrumbs.html` to key on the substring ""dev"" instead.

The reason we aren't getting ""Nightly"" is apparently because the environment variable BUILD_VERSION is available, so `conf.py` is using the value of that env var instead of the version string imported from the `torchaudio` module itself, which actually appears to be incorrect; see below.

If I install torchaudio using

    conda install torchaudio -c pytorch-nightly

then `torchaudio.__version__` returns the incorrect version string:

    2.0.0.dev20230309

Pull Request resolved: https://github.com/pytorch/audio/pull/3333

Reviewed By: mthrok

Differential Revision: D45926466

Pulled By: carljparker

fbshipit-source-id: d5516f2d9f1716c2400d3e9b285bd5d32b4b3a77",Carl Parker,carljparker@meta.com,['docs/source/_templates/breadcrumbs.html'],False,17,5,2023
c12f4734807b57f3d5a27fac91296fe9efdced58,"Add 420p10le CPU support to StreamReader (#3332)

Summary:
This commit add support to decode YUV420P010LE format.

The image tensor returned by this format
- NCHW format (C == 3)
- int16 type
- value range [0, 2^10).

Note that the value range is different from what ""hevc_cuvid"" decoder
returns. ""hevc_cuvid"" decoder uses full range of int16 (internally,
it's uint16) to express the color (with some intervals), but the values
returned by CPU ""hevc"" decoder are with in [0, 2^10).

Address https://github.com/pytorch/audio/issues/3331

Pull Request resolved: https://github.com/pytorch/audio/pull/3332

Reviewed By: hwangjeff

Differential Revision: D45925097

Pulled By: mthrok

fbshipit-source-id: 4e669b65c030f388bba2fdbb8f00faf7e2981508",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.h', 'torchaudio/csrc/ffmpeg/stream_reader/post_process.cpp']",False,17,5,2023
d38a7854234b1a928ee70e62459a4b361b4e1019,"Upgrade to FFmpeg5 (#3298)

Summary:
This commit upgrade the version of FFmpeg compiled against TorchAudio binary distribution to 5.0.4.

FFmpeg 5.0 was released in Jan 2022, and many package managers provide a version of FFmpeg v5.
Conda-forge lists 5.1 for all the platforms TorchAudio supports.https://anaconda.org/conda-forge/ffmpeg

Pull Request resolved: https://github.com/pytorch/audio/pull/3298

Reviewed By: hwangjeff

Differential Revision: D45865599

Pulled By: mthrok

fbshipit-source-id: d95638eb80daaf477a710a992f4ead9b9009bb9b",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/unittest/linux/scripts/setup_env.sh', '.circleci/unittest/windows/scripts/setup_env.sh', '.github/workflows/build_docs.yml', '.github/workflows/unittest-linux-gpu.yml', 'docs/source/installation.rst', 'examples/tutorials/device_asr.py', 'examples/tutorials/effector_tutorial.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streamreader_basic_tutorial.py', 'examples/tutorials/streamwriter_advanced.py', 'examples/tutorials/streamwriter_basic_tutorial.py', 'packaging/ffmpeg/build.sh']",False,16,5,2023
e4c1d70b782ebbf65277f5868458b49f0d69110f,"Remove obsolete third party dependencies of CTC decoder (#3339)

Summary:
TorchAudio has migrated CTC decoder to flashlight-text, and code related CTC decoder was removed in https://github.com/pytorch/audio/issues/3236.

This commit cleans up the residual, removes the third party libraries used for CTC decoder, and mention to environment variable for CTC decoder.

Pull Request resolved: https://github.com/pytorch/audio/pull/3339

Reviewed By: nateanl

Differential Revision: D45920878

Pulled By: mthrok

fbshipit-source-id: 8d93e64138697781570e5b0b1c9f86e1a7923a89",moto,855818+mthrok@users.noreply.github.com,"['CONTRIBUTING.md', 'docs/source/build.rst', 'setup.py', 'third_party/CMakeLists.txt', 'third_party/bzip2/CMakeLists.txt', 'third_party/lzma/CMakeLists.txt', 'third_party/zlib/CMakeLists.txt']",False,16,5,2023
04f67546680c6dd7dba903e1af9a22c01dfcf920,"[Doc] Fix a word in documents (#3334)

Summary:
A redundant ""and"" just removed.

Pull Request resolved: https://github.com/pytorch/audio/pull/3334

Reviewed By: xiaohui-zhang

Differential Revision: D45864314

Pulled By: mthrok

fbshipit-source-id: ad67bde8fa73eac995fbd0d3809709cc38486884",Amir Masoud Nourollah,61701369+Nourollah@users.noreply.github.com,['torchaudio/transforms/_transforms.py'],False,16,5,2023
002475765eea21067776f7d5215ff6e57026b682,"Switch windows nightly builds to GHA (#3330)

Summary:
Switch windows nightly builds to GHA

Similar to: https://github.com/pytorch/vision/pull/7578

Pull Request resolved: https://github.com/pytorch/audio/pull/3330

Reviewed By: mthrok

Differential Revision: D45871892

Pulled By: atalman

fbshipit-source-id: 817490a2abcaffceec5174c624f9e7d0377bbc4a",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.github/workflows/build-conda-windows.yml', '.github/workflows/build_wheels_windows.yml']",False,15,5,2023
d9643f50eeb261584689599c05686687edb3fb28,"Clean-up StreamReader/StreamWriter interface (#3328)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3328

Make the `AVIOContext`-based constructor protected for better encapsulation.
AVFormatContext and optional AVIOContext are managed by StreamReader/Writer, so it's better that they are abstracted away from client code.

Reviewed By: hwangjeff

Differential Revision: D45779629

fbshipit-source-id: 44c31e8af785447cb47aad0c44bf4ecf1aeebeaa",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h'],False,11,5,2023
1c7309d2614c510272f472caba68f6a7d9adf21c,"Add doc preview (#3326)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3326

Reviewed By: hwangjeff

Differential Revision: D45760678

Pulled By: mthrok

fbshipit-source-id: 79b5d846c93516ca90c9700279124a9a04470242",moto,855818+mthrok@users.noreply.github.com,['.github/workflows/build_docs.yml'],False,11,5,2023
608775bf32fa9339e13f0a0a961211a915f16d7d,"Add 2.0.1 to the version compatibility matrix (#3325)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3325

Reviewed By: hwangjeff

Differential Revision: D45759434

Pulled By: mthrok

fbshipit-source-id: f3b1127fcf3b23beeab61fb7ff18f1b89b11ddc6",moto,855818+mthrok@users.noreply.github.com,['docs/source/installation.rst'],False,11,5,2023
4463fbdfbbc29fbc78d5dcd4f61cd9d0a806432c,"[BC-Breaking] Switch to the backend dispatcher (#3241)

Summary:
This commit makes the code defaults to the backend dispatcher by default. Enabling backend dispatcher puts the FFmpeg-based I/O implementation on higher priority (if the corresponding FFmpeg is available), and allows individual function call to specify the backend.

See also https://github.com/pytorch/audio/issues/2950

Pull Request resolved: https://github.com/pytorch/audio/pull/3241

Reviewed By: hwangjeff

Differential Revision: D44709068

Pulled By: mthrok

fbshipit-source-id: 43aac3433f78a681df6669e9ac46e8ecf3beb1be",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/backend/utils_test.py', 'torchaudio/backend/utils.py']",False,10,5,2023
2ab49e5badb932c55c6f28a2b4b115a57050fa0e,"Add AudioEffector tutorial (#3226)

Summary:
https://output.circle-artifacts.com/output/job/fbfa6d9a-5014-42ac-8e77-c1e9565747e8/artifacts/0/docs/tutorials/effector_tutorial.html

Pull Request resolved: https://github.com/pytorch/audio/pull/3226

Reviewed By: nateanl

Differential Revision: D45402724

Pulled By: mthrok

fbshipit-source-id: bc9d1bc071f6f5062b9cc35d743b4a3016306262",moto,855818+mthrok@users.noreply.github.com,"['docs/source/index.rst', 'examples/tutorials/effector_tutorial.py']",False,10,5,2023
667c6a9ee4eeb5f786426e2821ebc31731b4847d,"Update `torchaudio` doc and tutorial (#3285)

Summary:
This commit is preparation for landing dispatcher switch in https://github.com/pytorch/audio/issues/3241

Making FFmpeg backend default causes some issues on tutorials, so this commit disable it.
The IO tutorial will be updated after https://github.com/pytorch/audio/issues/3241 is landed to accommodate the change.

Since it is necessary to mention the changes related to migration in the IO tutorial,
I also update the IO documentation to include migration work so that  it's easy to redirect.

Pull Request resolved: https://github.com/pytorch/audio/pull/3285

Reviewed By: nateanl

Differential Revision: D45671237

Pulled By: mthrok

fbshipit-source-id: cb541f6bd93cd9920019b8ec83210ea69d34f133",moto,855818+mthrok@users.noreply.github.com,"['docs/source/torchaudio.rst', 'examples/tutorials/audio_io_tutorial.py']",False,10,5,2023
5a85a4617d7a84e30ae494af91b265de3cb6a145,"[BC-Breaking] Update InverseMelScale solution (#3280)

Summary:
Address https://github.com/pytorch/audio/issues/2643

- replace `SGD` optimization with `torch.linalg.lstsq` which is much faster.
- Add autograd test for `InverseMelScale`
- update other tests

Pull Request resolved: https://github.com/pytorch/audio/pull/3280

Reviewed By: hwangjeff

Differential Revision: D45679988

Pulled By: nateanl

fbshipit-source-id: a42e8bff9dc0f38e47e0482fd8a2aad902eedd59",Zhaoheng Ni,zni@meta.com,"['test/torchaudio_unittest/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/transforms/_transforms.py']",False,10,5,2023
282ed27ac7ff341a749d94a61013f62f5ab41975,"Remove NumPy from conda build env (#3315)

Summary:
NumPy is an optional runtime dependency of TorchAudio, and it is not required at build time.

Pull Request resolved: https://github.com/pytorch/audio/pull/3315

Reviewed By: nateanl

Differential Revision: D45702243

Pulled By: mthrok

fbshipit-source-id: 6ca6598931764c46be6323868e8cce7c8adc5024",moto,855818+mthrok@users.noreply.github.com,"['packaging/torchaudio/meta.yaml', 'torchaudio/csrc/cuctc/src/python_binding.cpp']",False,9,5,2023
8d7268f172259b276930f58d1845dfe11cc03f11,"Refactor StreamReader/Writer PyBinding (#3296)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3296

Reviewed By: hwangjeff

Differential Revision: D45503774

fbshipit-source-id: 806c22bd0f54fd0cea43d61ef3dbedd67ffeb012",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/pybind/fileobj.cpp', 'torchaudio/csrc/ffmpeg/pybind/fileobj.h', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp']",False,9,5,2023
007cca239dc480b38984f5b8b8ca834b6432e59e,"Add StreamReaderCustomIO (#3320)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3320

Add StreamReaderCustomIO, which is analogous to StreamWriterCustomIO and which takes custom read/seek functions to fetch media data.

Reviewed By: hwangjeff

Differential Revision: D45482843

fbshipit-source-id: 3ccf771c0fdce153aaa7551053e9a77facedc983",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h']",True,9,5,2023
51767917462cba1dfef471eaf074cc8ce14f5db8,"Refactor StreamWriterCustomIO (#3319)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3319

* Merge the source with StreamWriter
* Add docstrings
* Move CustomIO to detail::CustomOutput to prepare for adding CustomInput

Reviewed By: hwangjeff

Differential Revision: D45481807

fbshipit-source-id: 4a9ac8a57acda47b126f8ae18e607b72919f9988",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_custom_io.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_custom_io.h']",True,9,5,2023
51cc1cbf8e3c9ff7d6d7f3192b41cb4612fa3599,"Fix batch consistency test for InverseBarkScale (#3322)

Summary:
The batch consistency test function should call `InverseBarkScale` instead of `InverseMelScale`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3322

Reviewed By: mthrok

Differential Revision: D45691769

Pulled By: nateanl

fbshipit-source-id: 4a1ed80c4a56c3a847a49a8d02f8b5cbe4f09045",Zhaoheng Ni,zni@meta.com,['test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py'],False,9,5,2023
3a49a2d274cb9fd2ba949e4eb628c674acaa2899,"[BE] Add description to wheel package (#3321)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3321

Reviewed By: atalman, mthrok

Differential Revision: D45673225

Pulled By: malfet

fbshipit-source-id: f2b915f3307ba95445702e3018254ad254fe2bb3",Nikita Shulga,nshulga@meta.com,['setup.py'],False,9,5,2023
a8dc4de5fa4fbed1332e7667abb247bc63b081f0,"fix doc of specaugment transform (#3314)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3314

Reviewed By: nateanl

Differential Revision: D45621958

Pulled By: xiaohui-zhang

fbshipit-source-id: 17555a865790adadc2abd40a86571596386a12fc",Xiaohui Zhang,xiaohuizhang@fb.com,['torchaudio/transforms/_transforms.py'],False,5,5,2023
05ef7dc68d76a11f9fbb93944e0b7cbaa0d53b33,"Update squim tutorial (#3313)

Summary:
Add scatter plots for STOI, PESQ, Si-SDR, and MOS scores to demonstrate the performance of `SquimObjective` and `SquimSubjective` models and how close they are to the ground truths.

Pull Request resolved: https://github.com/pytorch/audio/pull/3313

Reviewed By: hwangjeff

Differential Revision: D45620311

Pulled By: nateanl

fbshipit-source-id: cb58ffd3744df4749b9385876da8de0cffd93557",Zhaoheng Ni,zni@meta.com,['examples/tutorials/squim_tutorial.py'],False,5,5,2023
82febc59ad1d068144ee6d9fba7766628b521bbb,"Add SpecAugment transform (#3309)

Summary:
(2/2 of the previous https://github.com/pytorch/audio/pull/2360 which I accidentally closed)

The previous way of doing SpecAugment via Frequency/TimeMasking transforms has the following problems:
- Only zero masking can be done; masking by mean value is not supported.
- mask_along_axis is hard-coded to mask the 1st dimension and mask_along_axis_iid is hard-code to mask the 2nd or 3rd dimension of the input tensor.
- For 3D spectrogram tensors where the first dimension is batch or channel, features from the same batch or different channels have to use the same mask, because mask_along_axis_iid only support 4D tensors, because of the above hard-coding
- For 2D spectrogram tensors w/o a batch or channel dimension, Time/Frequency masking can't be applied at all, since mask_along_axis only support 3D tensors, because of the above hard-coding.
- It's not straightforward to apply multiple time/frequency masks by the current design. If we need N masks across time/frequency axis, we need to sequentially apply N Frequency/TimeMasking transforms to input tensors, and such API looks very inconvenient. We need to introduce a separate SpecAugment transform to handle this.

To solve these issues, here we
[done in the previous [PR](https://github.com/pytorch/audio/pull/3289)] Extend mask_along_axis_iid to support 3D+ tensors and mask_along_axis to support 2D+ tensors. Now both of them are able to mask one of the last two dimensions (where the time or frequency dimension lives) of the input tensor.
[done in this PR] Introducing SpecAugment transform.

Pull Request resolved: https://github.com/pytorch/audio/pull/3309

Reviewed By: nateanl

Differential Revision: D45592926

Pulled By: xiaohui-zhang

fbshipit-source-id: 97cd686dbb6c1c6ff604716b71a876e616aaf1a2",Xiaohui Zhang,xiaohuizhang@fb.com,"['test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",False,5,5,2023
1e3af12f121bf60bf8ac601af3160ba98417584e,"Fix missing PTS initialization with NVIDIA encoder (#3312)

Summary:
Fix **Failed to write packet (Invalid argument)** error when encoding FLV video streams using NVIDIA hardware encoders.

Resolve https://github.com/pytorch/audio/issues/3311

Pull Request resolved: https://github.com/pytorch/audio/pull/3312

Reviewed By: nateanl

Differential Revision: D45611656

Pulled By: mthrok

fbshipit-source-id: 531a83a27d3b19ed9e9aedd161769c60aa0bd175",huyao,qsct9501@126.com,['torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp'],False,5,5,2023
bfb4701706a818d1beacb73ec45b9bb1174e0332,"Fix doc version (#3310)

Summary:
Fixes the regression caused by build_doc job GHA migration. The version number is not properly set.

Pull Request resolved: https://github.com/pytorch/audio/pull/3310

Reviewed By: nateanl

Differential Revision: D45607829

Pulled By: mthrok

fbshipit-source-id: 3450a38fa6982fcc56676a80144e9eed1aad02ec",moto,855818+mthrok@users.noreply.github.com,['.github/workflows/build_docs.yml'],False,5,5,2023
3e897ca79d3c8081a575fb1dd31ccc57d23a77d7,"Fix MKL issue on Intel mac build (#3307)

Summary:
* Remove MKL and NumPy from Conda build env
* Remove `caffe2::mkl` dependency from `torch_cpu`, which introduced unnecessary and undesided dependency on Intel mac.

TorchAudio does not use BLAS libraries directly, thus all the mentions to MKL should be removed from the codebase.
However, this was causing an issue on Intel mac. It turned out that `torch_cpu` target is pulling `caffe2::mkl` dependency, and the linker on macOS keeps library dependency even if no symbol from that library is used. This stray mkl dependency should be fixed on core side, but also we can modify the target temporarily and remove them.

Also we don't need NumPy on build/run time, so that is removed as well.

Pull Request resolved: https://github.com/pytorch/audio/pull/3307

Reviewed By: atalman

Differential Revision: D45606944

Pulled By: mthrok

fbshipit-source-id: 853411ccbbca31796b808a2b052b4cfa564718cd",moto,855818+mthrok@users.noreply.github.com,"['cmake/TorchAudioHelper.cmake', 'packaging/pkg_helpers.bash', 'packaging/torchaudio/meta.yaml', 'packaging/vs2019/conda_build_config.yaml']",False,5,5,2023
1e48af06a95fe839110a24d53dd57216d7986906,"Add older mkl build contraint only (#3302)

Summary:
Similar to what we used to have here:
https://github.com/pytorch/test-infra/pull/3896/files

Pull Request resolved: https://github.com/pytorch/audio/pull/3302

Reviewed By: nateanl

Differential Revision: D45574845

Pulled By: atalman

fbshipit-source-id: 142c35dfd811a5f5c170dcd082bec8d055edd9cb",atalman,atalman@fb.com,['packaging/torchaudio/meta.yaml'],False,4,5,2023
b5795943c83e64853150070825e335f14c9278d6,"Add mkl dependency to torchaudio MacOS x86 builds (#3300)

Summary:
Add mkl dependency to torchaudio MacOS x86 builds

Already tested here: https://github.com/pytorch/audio/actions/runs/4878179835/jobs/8703586137

Pull Request resolved: https://github.com/pytorch/audio/pull/3300

Reviewed By: jeanschmidt, mthrok

Differential Revision: D45566352

Pulled By: atalman

fbshipit-source-id: a0376016506891240b2dd03d4fa4889028bf764b",atalman,atalman@fb.com,['packaging/torchaudio/meta.yaml'],False,4,5,2023
74bd971a16c12dc062b504c3562da9c8b36713e0,"Extend mask_along_axis{,_iid} (#3289)

Summary:
(1/2 of the previous [PR](https://github.com/pytorch/audio/pull/2360) which I accidentally closed)

The previous way of doing SpecAugment via Frequency/TimeMasking transforms has the following problems:
- Only zero masking can be done; masking by mean value is not supported.
- mask_along_axis is hard-coded to mask the 1st dimension and mask_along_axis_iid is hard-code to mask the 2nd or 3rd dimension of the input tensor.
- For 3D spectrogram tensors where the first dimension is batch or channel, features from the same batch or different channels have to use the same mask, because mask_along_axis_iid only support 4D tensors, because of the above hard-coding
- For 2D spectrogram tensors w/o a batch or channel dimension, Time/Frequency masking can't be applied at all, since mask_along_axis only support 3D tensors, because of the above hard-coding.
- It's not straightforward to apply multiple time/frequency masks by the current design.

To solve these issues, here we
- Extend mask_along_axis_iid to support 3D tensors and mask_along_axis to support 2D tensors. Now both of them are able to mask one of the last two dimensions (where the time or frequency dimension lives) of the input tensor.

The introduction of SpecAugment transform will be done in another PR.

Pull Request resolved: https://github.com/pytorch/audio/pull/3289

Reviewed By: hwangjeff

Differential Revision: D45460357

Pulled By: xiaohui-zhang

fbshipit-source-id: 91bf448294799f13789d96a13d4bae2451461ef3",Xiaohui Zhang,xiaohuizhang@fb.com,"['test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/transforms/transforms_test.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,4,5,2023
c51f20f9c5fd15e60702d3e4cbfe5d68c16a487a,"Fix lint and format PR label message (#3299)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3299

Reviewed By: xiaohui-zhang

Differential Revision: D45530945

Pulled By: mthrok

fbshipit-source-id: 3443e4de693898534687b26ee1a9376ff86651f9",moto,855818+mthrok@users.noreply.github.com,['.github/process_commit.py'],False,3,5,2023
76f91135990f44c456f53f99012ce626fb967ad0,"[AutoAccept][Codemod][FBSourceBlackLinter] Daily `arc lint --take BLACK`

Reviewed By: adamjernst

Differential Revision: D45522319

fbshipit-source-id: d73a137c8738a215cc711ad39461f5b2f9ba76da",generatedunixname89002005367269,generatedunixname89002005367269@fb.com,['tools/release_notes/classify_prs.py'],False,3,5,2023
bc9451e6b4dd01f8a5e4702e030f34316dbb8113,"Remove build doc job from CCI (#3293)

Summary:
https://github.com/pytorch/audio/pull/3292 migrates the doc deployment to GHA.

Pull Request resolved: https://github.com/pytorch/audio/pull/3293

Reviewed By: xiaohui-zhang

Differential Revision: D45527256

Pulled By: mthrok

fbshipit-source-id: 18eb2580243b6b842147caaac10b3d28aa3d6dd0",moto,855818+mthrok@users.noreply.github.com,"['.circleci/build_docs/commit_docs.sh', '.circleci/build_docs/install_wheels.sh', '.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py']",False,3,5,2023
171a65d3cbce49965dd307ad929b69d871feb0f9,"Fix doc deloyment condition (#3294)

Summary:
Follow-up of https://github.com/pytorch/audio/issues/3292

Doc deployment is gated by branch_name == nightly, but nightly branch fires push and PR events and there will be two deployment jobs.

This commit specify push event.

Pull Request resolved: https://github.com/pytorch/audio/pull/3294

Reviewed By: hwangjeff

Differential Revision: D45501983

Pulled By: mthrok

fbshipit-source-id: 8eb66b463800f6a30affafb27f5f2448a561cfe1",moto,855818+mthrok@users.noreply.github.com,['.github/workflows/build_docs.yml'],False,3,5,2023
d8a095efdc323dee20d8c839fadf6edecdfd84e7,"[Nova] Add windows conda workflows (#3288)

Summary:
[Nova] Add windows conda workflows
Same as: https://github.com/pytorch/vision/pull/7547

Pull Request resolved: https://github.com/pytorch/audio/pull/3288

Reviewed By: osalpekar

Differential Revision: D45456203

Pulled By: atalman

fbshipit-source-id: 067fd3b9abaeb9b7b0cd45c05b7c72982dfbfe0f",atalman,atalman@fb.com,['.github/workflows/build-conda-windows.yml'],False,2,5,2023
79d6795d5c35dbca0067138a14cd2e2867149be6,"Deploy documentation from GHA (#3292)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3292

Reviewed By: nateanl

Differential Revision: D45492729

Pulled By: mthrok

fbshipit-source-id: 11578166854c01deb50a6011550a91b87b426385",moto,855818+mthrok@users.noreply.github.com,['.github/workflows/build_docs.yml'],False,2,5,2023
37f2b4f03462cac9b20f28e9a4c5d669b96531ae,"adjust reference PR labels and add labeling guidance (#3162)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3162

Reviewed By: mthrok

Differential Revision: D43964995

Pulled By: xiaohui-zhang

fbshipit-source-id: bba8fffe25f2f39f558f080fef319b1df4c6e440",Xiaohui Zhang,xiaohuizhang@fb.com,"['.github/process_commit.py', 'tools/release_notes/classify_prs.py']",False,2,5,2023
27471a02fbaa7ee96fb33fc37227c19f6a0ceba0,"Adding win wheels builds (#3287)

Summary:
Adding win wheels builds
Same as : https://github.com/pytorch/vision/pull/7540

Pull Request resolved: https://github.com/pytorch/audio/pull/3287

Reviewed By: osalpekar

Differential Revision: D45452770

Pulled By: atalman

fbshipit-source-id: e70ad3a8f456e805b46da3d1752c42208dadb8da",atalman,atalman@fb.com,['.github/workflows/build_wheels_windows.yml'],False,1,5,2023
795bdc2ee6116465aa65672833c17e39169a38bb,"Add CUDA 12.1 builds (#3284)

Summary:
CC atalman malfet

Pull Request resolved: https://github.com/pytorch/audio/pull/3284

Reviewed By: mthrok

Differential Revision: D45444670

Pulled By: atalman

fbshipit-source-id: d0cf8696a99000c2b9a7e41ceeb781f5a54daeda",pbialecki,piotr.bialecki@hotmail.de,"['.circleci/config.yml', '.circleci/regenerate.py', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",False,1,5,2023
9b93e7df8c53631ef964cfff118772f4f9fa17bd,"Add tutorial for TorchAudio-SQUIM pipelines (#3279)

Summary:
The PR adds a tutorial that demonstrates how to use pre-trained `TorchAudio-SQUIM` pipelines to estimate objective and subjective metric scores (PESQ, STOI, Si-SDR, MOS).

Pull Request resolved: https://github.com/pytorch/audio/pull/3279

Reviewed By: hwangjeff

Differential Revision: D45415404

Pulled By: nateanl

fbshipit-source-id: abcaeadcca0eabc2dca53b607eac6257a701c903",Zhaoheng Ni,zni@meta.com,"['docs/source/index.rst', 'examples/tutorials/squim_tutorial.py']",False,29,4,2023
0a1801ed5864e4f84850f5617ab03e26f9bd79d4,"Add cuctc decoder (#3096)

Summary:
This PR implements a CUDA based ctc prefix beam search decoder.

Attach serveral benchmark results using V100 below:
|decoder type| model |datasets       | decoding time (secs)| beam size | batch size | model unit | subsampling times | vocab size |
|--------------|---------|------|-----------------|------------|-------------|------------|-----------------------|------------|
| cuctc |  conformer nemo    |dev clean        |7.68s | 8           |  32       | bpe         |    4  | 1000|
| cuctc |  conformer nemo   |dev clean  (sort by length)      |1.6s | 8           |  32       | bpe         |    4  | 1000|
| cuctc |  wav2vec2.0 torchaudio |dev clean                                |22s | 10           |  1       | char         |    2  | 29|
| cuctc |   conformer espnet   |aishell1 test                             | 5s | 10           |  24       | char         |    4  | 4233|

Note:
1.  The design is to parallel computation through batch and vocab axis, for loop the frames axis. So it's more friendly with smaller sequence lengths, larger vocab size comparing with CPU implementations.
2. WER is the same as CPU implementations. However, it can't decode with LM now.

Resolves: https://github.com/pytorch/audio/issues/2957.

Pull Request resolved: https://github.com/pytorch/audio/pull/3096

Reviewed By: nateanl

Differential Revision: D44709397

Pulled By: mthrok

fbshipit-source-id: 3078c54a2b44dc00eb4a81b4c657487eeff8c155",Yuekai Zhang,zhangyuekai@foxmail.com,"['CMakeLists.txt', 'CONTRIBUTING.md', 'docs/source/_templates/autosummary/cuda_ctc_decoder_class.rst', 'docs/source/index.rst', 'docs/source/models.decoder.rst', 'examples/asr/librispeech_cuda_ctc_decoder/README.md', 'examples/asr/librispeech_cuda_ctc_decoder/inference.py', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/models/decoder/cuda_ctc_decoder_test.py', 'third_party/LICENSES_BUNDLED.txt', 'tools/setup_helpers/extension.py', 'torchaudio/csrc/cuctc/CMakeLists.txt', 'torchaudio/csrc/cuctc/LICENSE', 'torchaudio/csrc/cuctc/include/ctc_prefix_decoder.h', 'torchaudio/csrc/cuctc/include/ctc_prefix_decoder_host.h', 'torchaudio/csrc/cuctc/src/bitonic_topk/LICENSE', 'torchaudio/csrc/cuctc/src/bitonic_topk/bitonic_sort.cuh', 'torchaudio/csrc/cuctc/src/bitonic_topk/pow2_utils.cuh', 'torchaudio/csrc/cuctc/src/bitonic_topk/warpsort_topk.cuh', 'torchaudio/csrc/cuctc/src/ctc_fast_divmod.cuh', 'torchaudio/csrc/cuctc/src/ctc_prefix_decoder.cpp', 'torchaudio/csrc/cuctc/src/ctc_prefix_decoder_kernel_v2.cu', 'torchaudio/csrc/cuctc/src/device_data_wrap.h', 'torchaudio/csrc/cuctc/src/device_log_prob.cuh', 'torchaudio/csrc/cuctc/src/python_binding.cpp', 'torchaudio/models/decoder/__init__.py', 'torchaudio/models/decoder/_cuda_ctc_decoder.py', 'torchaudio/utils/ffmpeg_utils.py']",False,28,4,2023
151ac4d85007c7e14d9ece9023a2c2b4b0cc6a40,"Introduce StreamWriterCustomIO (#3277)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3277

Adds `StreamWriterCustomIO` to support encoding and writing media to arbitrary destinations.

Reviewed By: mthrok

Differential Revision: D44904807

fbshipit-source-id: 23a47531973a7dce0638feb825d38c81d46dc02f",Jeff Hwang,jeffhwang@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_custom_io.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_custom_io.h']",False,25,4,2023
5472cdae84cf1ed3f098be196df06d791c301d43,"Update url for collect_env.py (#3271)

Summary:
The `master` branch of PyTorch has been updated to `main` recently. The url of `collect_env.py` in the new issue page should be updated as well.

Pull Request resolved: https://github.com/pytorch/audio/pull/3271

Reviewed By: xiaohui-zhang

Differential Revision: D45087038

Pulled By: nateanl

fbshipit-source-id: 167262ae6ed179baabcf55064fc5f0f0ac3b0be9",Zhaoheng Ni,zni@meta.com,['.github/ISSUE_TEMPLATE/bug-report.yml'],False,19,4,2023
70350a6931b31ce7ae80377685f7e138b06dfa25,"Amend StreamReader docs to reflect deprecation of tensor decoding (#3272)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3272

Reviewed By: mthrok

Differential Revision: D45095440

Pulled By: hwangjeff

fbshipit-source-id: 135eb0f5d9047bf172563a9a05a9d2e323796d4d",hwangjeff,jeffhwang@meta.com,['torchaudio/io/_stream_reader.py'],False,19,4,2023
94f5027ea7ded87448682f3beb16dc53cad176f7,"Add multi-channel DNN beamforming training recipe (#3036)

Summary:
The PR adds the training recipe of DNN beamforming for multi-channel speech enhancement.

Pull Request resolved: https://github.com/pytorch/audio/pull/3036

Reviewed By: hwangjeff

Differential Revision: D45061841

Pulled By: nateanl

fbshipit-source-id: 48ede5dd579efe200669dbc83e9cb4dea809e4b4",nateanl,nizhaoheng@gmail.com,"['examples/dnn_beamformer/README.md', 'examples/dnn_beamformer/datamodule.py', 'examples/dnn_beamformer/eval.py', 'examples/dnn_beamformer/model.py', 'examples/dnn_beamformer/train.py', 'examples/dnn_beamformer/utils.py']",False,18,4,2023
d5b2996b974b25a7c40e0673e9e71224469f9256,"Merge key_padding_mask into attn_mask_rel_pos in WavLM (#3265)

Summary:
When `key_padding_mask` is not `None`, it needs to be combined with `attn_mask_rel_pos` as one mask for `scaled_dot_product_attention` function.

Pull Request resolved: https://github.com/pytorch/audio/pull/3265

Reviewed By: hwangjeff

Differential Revision: D44901093

Pulled By: nateanl

fbshipit-source-id: 73ca7af48faf7f4eb36b35b603187a11e5582c70",Zhaoheng Ni,zni@meta.com,['torchaudio/models/wav2vec2/wavlm_attention.py'],False,12,4,2023
cc7b8bd439bf6b2cc09c7d71084e5302044d4d91,"Allow overwrite temp data in ffmpeg test (#3263)

Summary:
When `TORCHAUDIO_TEST_TEMP_DIR` is set,
all the unit test temporary data are stored in the  given directory.
Running unit tests multiple times reuses the
directory and the temporary files from the
previous test runs are found there.

FFmpeg save test writes reference data to the
temporary directory, but it is not given the
overwrite flag (""-y""), so it fails in such cases.

This commit fixes that.

Pull Request resolved: https://github.com/pytorch/audio/pull/3263

Reviewed By: hwangjeff

Differential Revision: D44859003

Pulled By: mthrok

fbshipit-source-id: 2db92fbdec1c015455f3779e10a18f7f1146166b",moto,855818+mthrok@users.noreply.github.com,['test/torchaudio_unittest/backend/dispatcher/ffmpeg/save_test.py'],False,12,4,2023
563e409cc165ed046c89402e45405649ecb85011,"Specify backend directly in test (#3262)

Summary:
Preparation to land https://github.com/pytorch/audio/pull/3241

This commit applies patch to make the sox_io TorchScript test pass when dispatcher is enabled.

Pull Request resolved: https://github.com/pytorch/audio/pull/3262

Reviewed By: hwangjeff

Differential Revision: D44897513

Pulled By: mthrok

fbshipit-source-id: 9b65f705cd02324328a2bc1c414aa4b7ca0fed32",moto,855818+mthrok@users.noreply.github.com,['test/torchaudio_unittest/backend/sox_io/torchscript_test.py'],False,12,4,2023
4b0254ba6365016e1fefd95afeab07ad862fadc1,"Fix nightly doc build (CircleCI) (#3258)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3258

Reviewed By: nateanl

Differential Revision: D44859397

Pulled By: mthrok

fbshipit-source-id: 361ac6a8c7092cc753f77d7745ec178760e8b9c3",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,11,4,2023
623e33d957a5be5fc5ec8e474efea43777915216,"Update windows build doc (#3257)

Summary:
GCC should not be used when building FFmpeg for torchaudio, as torchaudio uses MSVC (cl.exe)

Pull Request resolved: https://github.com/pytorch/audio/pull/3257

Reviewed By: nateanl

Differential Revision: D44835169

Pulled By: mthrok

fbshipit-source-id: 038c70caae58cec47dd2d6d08b8244c193104eda",moto,855818+mthrok@users.noreply.github.com,['docs/source/build.windows.rst'],False,11,4,2023
adb03385dfe95b8d7734213607423f6d8b2e65fa,"Use scaled_dot_product_attention in WavLM attention (#3252)

Summary:
Fix https://github.com/pytorch/audio/issues/3219.

`torch.nn.MultiheadAttention` will throw an error if `torch.no_grad()` and mask are both given. The pull request fixes it by replacing the forward method with `torch.nn.functional.scaled_dot_product_attention`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3252

Reviewed By: mthrok

Differential Revision: D44798634

Pulled By: nateanl

fbshipit-source-id: abfa7fb84b7bd71848a92ab26da5a5f0f095c665",Zhaoheng Ni,zni@meta.com,['torchaudio/models/wav2vec2/wavlm_attention.py'],False,10,4,2023
94cc4bd91c531e5cacf2c193116ad0b481a92a4e,"Use scaled_dot_product_attention in Wav2vec2/HuBERT's SelfAttention (#3253)

Summary:
Replace the attention computation with `torch.nn.functional.scaled_dot_product_attention` to improve running efficiency.

Pull Request resolved: https://github.com/pytorch/audio/pull/3253

Reviewed By: mthrok

Differential Revision: D44800353

Pulled By: nateanl

fbshipit-source-id: 41550d868c809099aadbe812b0ebe2c38121efb8",Zhaoheng Ni,zni@meta.com,['torchaudio/models/wav2vec2/components.py'],False,10,4,2023
5a5b0fc39dfdaaf2d6cf75e00e1c4a5a382dd59f,"Update description of Squim pipelines (#3254)

Summary:
- Add citations of [`TorchAudio-Squim`](https://arxiv.org/abs/2304.01448) publication.
- Update descriptions in the `SQUIM_OBJECTIVE` and `SQUIM_SUBJECTIVE` pipelines.

Pull Request resolved: https://github.com/pytorch/audio/pull/3254

Reviewed By: hwangjeff

Differential Revision: D44802015

Pulled By: nateanl

fbshipit-source-id: ca08298ec1eafefdd671ff2e010ef18f7372f9f8",Zhaoheng Ni,zni@meta.com,"['docs/source/refs.bib', 'torchaudio/prototype/pipelines/squim_pipeline.py']",False,10,4,2023
a6602715525e297063dbf2c300332594f90d59e1,"Get rid of (pseudo) hungarian notation (#3255)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3255

Prefixing what is always pointer with `p` does not improve readability...

Reviewed By: hwangjeff

Differential Revision: D44799531

fbshipit-source-id: bc2ce4e534009e2cb577719953207ddb82cf2d3d",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,10,4,2023
631bcc9fcbe5a548c5a7ff3d64a958a20f21432f,"Simplify FilterGraph interface (#3251)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3251

Removes unnecessary media type check in FilterGraph.
Allows to define filters that have different media type for input and output.

Reviewed By: nateanl

Differential Revision: D44792340

fbshipit-source-id: e00497e0d30b5b3c3aacc66dd9b8c401757af288",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/stream_reader/post_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp']",False,7,4,2023
ea78478ed82daea4900c9c4f02cb0ff91a5c407a,"Tweak managed pointer interface (#3249)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3249

- Put ptr member private so that it's more secure and subclasses won't mess with it
- Remove unused `reset` method
- Do not default construct the managed object
  - Introduce helper function for default allocation.
    (for AVFrame and AVPacket as they are allocated in both reader and writer)
  - for others, allocation logics are moved to where it is used.
- Remove unused `pHWBufferRef` attribute from `StreamWriter`.

Reviewed By: hwangjeff

Differential Revision: D44775297

fbshipit-source-id: ff6db528152cd54c1ae398191110c30b9c1e238c",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/packet_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/post_process.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/encoder.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,7,4,2023
f7c8a7d3864ae7bb505f676aa2db941ecc304ded,"Remove temp channel for python 3.11, simplify logic around cuda (#3250)

Summary:
Remove temp channel for python 3.11, simplify logic around cuda

Pull Request resolved: https://github.com/pytorch/audio/pull/3250

Reviewed By: mthrok

Differential Revision: D44788219

Pulled By: atalman

fbshipit-source-id: 421ff9e0bf1818b41e395708cc4589d4a9c865bd",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/unittest/windows/scripts/install.sh', '.circleci/unittest/windows/scripts/set_cuda_envs.sh', 'packaging/build_conda.sh']",False,7,4,2023
000878e01034d8e80e5bf7273e6541be91e15515,"Introduce packet passthrough feature to streaming api (#3220)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3220

Introduces methods to `StreamReader` and `StreamWriter` that allow for reading and writing `AVPacket` instances rather than tensors. Useful for efficiently remuxing data pulled as is from source.

Reviewed By: mthrok

Differential Revision: D44271536

fbshipit-source-id: 9b9d743c0119a5eb564fa628fd6a67806d120985",Jeff Hwang,jeffhwang@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/stream_reader/packet_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/packet_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_writer/packet_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/packet_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,7,4,2023
9da92cdb0f657d23ccf5594387398e4033a76f58,"Fix path normalization for StreamWriter-based save operation (#3248)

Summary:
Follow up of https://github.com/pytorch/audio/issues/3243. Save compat module had different semantics than info and load, which requires different way of performing path normalization.

Pull Request resolved: https://github.com/pytorch/audio/pull/3248

Reviewed By: hwangjeff

Differential Revision: D44774997

Pulled By: mthrok

fbshipit-source-id: 4b967ae3ca6b45850d455b8e95aaa31762c5457e",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/_backend/utils.py', 'torchaudio/io/_compat.py']",False,7,4,2023
ae614ed3d38ea24f49c8066233c1bc079510514f,"Remove custom flashlight import (#3246)

Summary:
In https://github.com/pytorch/audio/pull/3232, the CTC decoder is excluded from binary distribution.
To use CTCDecoder, users need to install flashlight-text.

Currently, if flashlight-text is not available, torchaudio still attempts to import the custom bundle.
This commit clean up this behavior by delaying the error until one of the components is actually used,
and providing a better message.

Pull Request resolved: https://github.com/pytorch/audio/pull/3246

Test Plan:
Binary smoke tests import torchaudio without installing flashlight.
Unit test CI jobs run the CTC decoder with flashlight installed.

Reviewed By: jacobkahn

Differential Revision: D44748413

Pulled By: mthrok

fbshipit-source-id: 21d2cbd9961ed88405a739cc682071066712f5e4",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/models/decoder/__init__.py', 'torchaudio/models/decoder/_ctc_decoder.py']",False,6,4,2023
f4d94cab0cc0af0c89565084998ecf2d6ba8a38a,"Add frame writing API to StreamWriter (#3244)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3244

Adds methods to `StreamWriter` that allow for passing in `AVFrame` instances rather than tensors.

Reviewed By: mthrok

Differential Revision: D44589256

fbshipit-source-id: f100e0d349708482b873a9a4bae1eaf5eb65301a",Jeff Hwang,jeffhwang@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/tensor_converter.cpp']",False,6,4,2023
d69e8857f4d2e347d5ea4da568ed619c0d3a6c39,"Fix path-like object support in FFmpeg dispatcher (#3243)

Summary:
In dispatcher mode, FFmpeg backend does not handle file-like object, and C++ implementation raises an issue.

This commit fixes it by normalizing file-like object to string.

Pull Request resolved: https://github.com/pytorch/audio/pull/3243

Reviewed By: nateanl

Differential Revision: D44719280

Pulled By: mthrok

fbshipit-source-id: 9dae459e2a5fb4992b4ef53fe4829fe8c35b2edd",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/backend/dispatcher/ffmpeg/info_test.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/load_test.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/save_test.py', 'torchaudio/_backend/utils.py']",False,5,4,2023
5053aa7f494a952997c4b889d4b833a7efe49268,"Remove source for flashlight-text bundle (#3236)

Summary:
Following https://github.com/pytorch/audio/pull/3232, static build of flashlight-text has been disabled and removed from nightly build.

This commit removes the related source/build from torchaudio code base.

Pull Request resolved: https://github.com/pytorch/audio/pull/3236

Reviewed By: jacobkahn

Differential Revision: D44712539

Pulled By: mthrok

fbshipit-source-id: a201c89b5046f224526309cd4e17a5105e58a949",moto,855818+mthrok@users.noreply.github.com,"['.gitmodules', 'CMakeLists.txt', 'third_party/flashlight-text/CMakeLists.txt', 'third_party/flashlight-text/submodule', 'third_party/kenlm/CMakeLists.txt', 'third_party/kenlm/kenlm', 'tools/setup_helpers/extension.py']",False,5,4,2023
ab40a3a3d6e24040efbd845b1b8908504dd22bea,"[BC-breaking] Make I/O optional arguments kw-only (#3227)

Summary:
Recently, we added bunch of options to make StreamReader/Writer flexible. As a result, their methods have many number of arguments, and some of them have semantic grouping.

For example, the arguments of ``StreamWriter.add_video_stream`` are roughly grouped as follow;

- Information about input media format
   `frame_rate`, `width`, `height`, `format`
- Information about encoder
   `encoder`, `encoder_option`
- Information about codec configuration
   `codec_config`
- Information about encode media format
   `encoder_format`, `encoder_frame_rate`, `encoder_width`, `encoder_height`
- Information about additional processing
   `filter_desc`
- Hardware acceleration
   `hw_accel`

We do not know what arguments will be added in the future, but when we do,
we want to keep them roughly grouped, by inserting the new argument
somewhere in a middle without breaking backward compatibility.

This commit puts most of them in keyword-only argument, so that we can
rearrange them without breaking backward compatibility.

Pull Request resolved: https://github.com/pytorch/audio/pull/3227

Reviewed By: hwangjeff

Differential Revision: D44681620

Pulled By: mthrok

fbshipit-source-id: b55f6168f4c2f3d0f59731b9bb0db4ae54e5a90f",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/io/_compat.py', 'torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py']",False,4,4,2023
3844a2bdc733e5a82922ed7d8e81c23b1dd7316b,"Disable CTC decoder bundle by default (#3232)

Summary:
As we migrate to use upstream flashlight-text and KenLM, this PR disable building CTC decoder by default.
This will stop shipping flashlight-text and KenLM bundle in torchaudio binary.

Ref: https://github.com/pytorch/audio/issues/3088

cc jacobkahn

Pull Request resolved: https://github.com/pytorch/audio/pull/3232

Reviewed By: hwangjeff

Differential Revision: D44650872

Pulled By: mthrok

fbshipit-source-id: 2415623abaf3cafa181135db5112d3c711137cd7",moto,855818+mthrok@users.noreply.github.com,"['.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh', '.github/workflows/build_docs.yml', '.github/workflows/integration-test.yml', '.github/workflows/unittest-linux-gpu.yml', 'tools/setup_helpers/extension.py']",False,4,4,2023
ea212c6e35c430c4dcc9f0987ab9cbb42f72b9c3,"Swap in assertions for decoder setup checks (#3235)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3235

Reviewed By: mthrok

Differential Revision: D44653654

Pulled By: hwangjeff

fbshipit-source-id: f28a6068e826581d76ed4a216adb6019b6486e53",hwangjeff,jeffhwang@meta.com,['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp'],False,4,4,2023
0d57a3af7c9fad46fc9920085af99d41f453bc69,"Remove linux GPU unit test from CircleCI (#3231)

Summary:
Linux GPU unit test on CircleCI relies on custom Docker image with CUDA 10.2.

PyTorch 2.0 does not support CUDA 10, so these tests have not run for a while.

We have GPU tests on GHA for Linux, so we can get rid of them.

Windows GPU tests are not ported to GHA yet, but they are still working on CircleCI, so we don't delete them yet.

Pull Request resolved: https://github.com/pytorch/audio/pull/3231

Reviewed By: hwangjeff

Differential Revision: D44639302

Pulled By: mthrok

fbshipit-source-id: c1fd39f4805a50a12af4259d423985fe453fd229",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py']",False,4,4,2023
0c1e3253a891040eec1c994861cebee27ad04282,"Fix virtual function issue with CTC decoder (#3230)

Summary:
Currently, creating CTCDecoder object by passing a language model to
`lm` argument without assigning it to a variable elsewhere causes
`RuntimeError: Tried to call pure virtual function ""LM::start""`.

According to discussions on PyBind11, (
https://github.com/pybind/pybind11/discussions/4013 and
https://github.com/pybind/pybind11/pull/2839
) this is due to Python object garbage-collected by the time
it's used by code implemented in C++. It attempts to call
methods defined in Python, which overrides the base pure virtual
function, but the object which provides this override gets
deleted by garbage collrector, as the original object is not
reference counted.

This commit fixes this by simply assiging the given `lm` object
as an attribute of CTCDecoder class.

Address https://github.com/pytorch/audio/issues/3218

Pull Request resolved: https://github.com/pytorch/audio/pull/3230

Reviewed By: hwangjeff

Differential Revision: D44642989

Pulled By: mthrok

fbshipit-source-id: a90af828c7c576bc0eb505164327365ebaadc471",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/models/decoder/ctc_decoder_test.py', 'torchaudio/models/decoder/_ctc_decoder.py']",False,3,4,2023
6270e609f2a76b1fd7cf29ab69bdb2832278114f,"[Internal] Log GPU decoder/encoder usage (#3233)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3233

Log usage when cuvid/nvenc is called.

Reviewed By: nateanl

Differential Revision: D44569410

fbshipit-source-id: 7c1e9fe70134af29c784fd076d1b128c9d2e0066",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp']",False,3,4,2023
61c31bc0f6a3a5d4065a8a33314d4206c2a09095,"Migrate the binding of FFmpeg utils to PyBind11 (#3228)

Summary:
Utilities functions are only available to Python, so no need to use TorchBind for them.
This should allow us to remove link-whole flag when linking `libtorchaudio_ffmpeg` part.

Pull Request resolved: https://github.com/pytorch/audio/pull/3228

Reviewed By: nateanl

Differential Revision: D44639560

Pulled By: mthrok

fbshipit-source-id: 5116073ee8c5ab572c63ad123942c4826bfe1100",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/_extension/utils.py', 'torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/utils.cpp', 'torchaudio/utils/ffmpeg_utils.py']",False,3,4,2023
c22cd16750c273c997749bc537c1fced280188be,"Use upstream flashlight-text in CI unittest (#3225)

Summary:
Initial step to migrate to upstream CTC decoder.

https://circleci.com/api/v1.1/project/github/pytorch/audio/1174432/output/107/0?file=true&allocation-id=642636c6eaaa102ce75beb8e-0-build%2FB77C8AB

Pull Request resolved: https://github.com/pytorch/audio/pull/3225

Reviewed By: nateanl

Differential Revision: D44581338

Pulled By: mthrok

fbshipit-source-id: 1517fa0cd5e4ba001d136eb0dfc2a9349afcd2da",moto,855818+mthrok@users.noreply.github.com,"['.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh', '.github/workflows/build_docs.yml', '.github/workflows/unittest-linux-gpu.yml']",False,3,4,2023
a4036248fd4de3662f8fb61c8783bf6bc49b3de7,"Add AudioEffector (#3163)

Summary:
This commit adds a new feature AudioEffector, which can be used to
apply various effects and codecs to waveforms in Tensor.

Under the hood it uses StreamWriter and StreamReader to apply
filters and encode/decode.

This is going to replace the deprecated `apply_codec` and
`apply_sox_effect_tensor` functions.

It can also perform online, chunk-by-chunk filtering.

Tutorial to follow.

closes https://github.com/pytorch/audio/issues/3161

Pull Request resolved: https://github.com/pytorch/audio/pull/3163

Reviewed By: hwangjeff

Differential Revision: D44576660

Pulled By: mthrok

fbshipit-source-id: 2c5cc87082ab431315d29d56d6ac9efaf4cf7aeb",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/io_class.rst', 'docs/source/io.rst', 'test/torchaudio_unittest/io/common.py', 'test/torchaudio_unittest/io/effector_test.py', 'test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/io/__init__.py', 'torchaudio/io/_effector.py', 'torchaudio/io/_stream_writer.py']",False,1,4,2023
fda41bbf6fe961e388eba10f98bb6263dc83b7b8,"Fix typo in forced alignment tutorial (#3222)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3222

Reviewed By: nateanl

Differential Revision: D44539424

Pulled By: mthrok

fbshipit-source-id: 8fbcb5f9918c9930c939bcd448493fa5cf604545",Nouran Ali,nouranalimohammed@gmail.com,['examples/tutorials/forced_alignment_tutorial.py'],False,31,3,2023
bb75caa4b06a753340774c64f355ae7a585ae91e,"Decouple StreamProcessor construction and decoder configuration (#3223)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3223

Each `StreamProcessor` is responsible for processing a source stream. In the case where we support packet passthrough, `StreamProcessor`'s choice of decoder is irrelevant as no decoding is performed. Currently, however, `StreamProcessor` requires decoder params and fixes a decoder at construction time. To accommodate this future packet passthrough use case, this PR decouples the construction of `StreamProcessor` from the configuration of the decoder that it uses.

Reviewed By: mthrok

Differential Revision: D44554934

fbshipit-source-id: 1d1a89015e1181b71dfb95c928de4fc3ec6f63b6",Jeff Hwang,jeffhwang@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp']",False,31,3,2023
493b50180ba2d5adfb892ecee6224a4ab8b665d1,"Add qscale to CodecConfig option (#3224)

Summary:
This commit adds the equivalent of `qscale` option in FFmpeg to StreamWriter.CodecConfig.
`qscale` enables variable bit rate.

The following figure illustrates the difference between currently available configs.
From top to bottom; original, `compression_level=1`, `compression_level=9`, `bit_rate=192k`, `bit_rate=8k`, `qscale=9`, `qscale=1`.
![Figure_1](https://user-images.githubusercontent.com/855818/228990681-368bf84f-00a7-4248-80ac-6ee728da8f1a.png)

Pull Request resolved: https://github.com/pytorch/audio/pull/3224

Reviewed By: hwangjeff

Differential Revision: D44563633

Pulled By: mthrok

fbshipit-source-id: ff74cd803b5abf1222f087e3e46ba7d81a35f672",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/types.h', 'torchaudio/io/_stream_writer.py']",False,31,3,2023
1b648626eb278276d32188a2c45fc691a2a36f4f,"Support encode spec change in StreamWriter (#3207)

Summary:
This commit adds support for changing the spec of media
(such as sample rate, #channels, image size and frame rate)
on-the-fly at encoding time.

The motivation behind this addition is that certain media
formats support only limited number of spec, and it is
cumbersome to require client code to change the spec
every time.

For example, OPUS supports only 48kHz sampling rate, and
vorbis only supports stereo.

To make it easy to work with media of different formats,
this commit makes it so that anything that's not compatible
with the format is automatically converted, and allows
users to specify the override.

Notable implementation detail is that, for sample format and
pixel format, the default value of encoder has higher precedent
to source value, while for other attributes like sample rate and
#channels, the source value has higher precedent as long as
they are supported.

Pull Request resolved: https://github.com/pytorch/audio/pull/3207

Reviewed By: nateanl

Differential Revision: D44439622

Pulled By: mthrok

fbshipit-source-id: 09524f201d485d201150481884a3e9e4d2aab081",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/io/_stream_writer.py']",False,30,3,2023
4bc4ca754a3ec961a148bcceeb9c8b124fd896a5,"Support changing the number of channels in StreamReader (#3216)

Summary:
This commit adds `num_channels` argument,
which allows one to change the number of channels on-the-fly.

Pull Request resolved: https://github.com/pytorch/audio/pull/3216

Reviewed By: hwangjeff

Differential Revision: D44516925

Pulled By: mthrok

fbshipit-source-id: 3e5a11b3fdbb19071f712a8148e27aff60341df3",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/io/_stream_reader.py']",False,30,3,2023
09ccf7cc0dea7251b57041701a1251e420e85029,"Reduce io tests (#3217)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3217

This commit removes some tests for file-like object from StreamWriter test.

The rational is that testing things after the output file is opened are
same for file-like object and regular files. Things like filter-graph and
encoder format change does not affect how the encoded bynary are written.

Reviewed By: hwangjeff

Differential Revision: D44518626

fbshipit-source-id: 821ec20deca92e5e5c85bf4d47997eed51735374",Moto Hira,moto@meta.com,['test/torchaudio_unittest/io/stream_writer_test.py'],False,29,3,2023
c76fd58b4620fa7da35a087367e322c3f39fa5b0,"Reuse HW device context in GPU encoder (#3215)

Summary:
In https://github.com/pytorch/audio/issues/3178, a mechanism to cache HW device context was introduced.
This commit applies the reuse in StreamWriter, so that
when using GPU video decoding and encoding, they are shared.

This gives back about 250 - 300 MB of GPU memory.

 ---

Q: What is HW device context?
From https://ffmpeg.org/doxygen/4.1/structAVHWDeviceContext.html#details
> This struct aggregates all the (hardware/vendor-specific) ""high-level"" state, i.e.
>
> state that is not tied to a concrete processing configuration. E.g., in an API that supports hardware-accelerated encoding and decoding, this struct will (if possible) wrap the state that is common to both encoding and decoding and from which specific instances of encoders or decoders can be derived.

Pull Request resolved: https://github.com/pytorch/audio/pull/3215

Reviewed By: nateanl

Differential Revision: D44504051

Pulled By: mthrok

fbshipit-source-id: 77579cdc8bd9e9b8a218e3f29031d091cda83860",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp']",False,29,3,2023
c07a96ab07aeaf8b3966d7672f592e7a1b186090,"Remove the note about AAC (#3214)

Summary:
There is a part of StreamWriter tutorial that warns about corrupted AAC audio output, but this is no longer relevant thus this commit deletes it.

Pull Request resolved: https://github.com/pytorch/audio/pull/3214

Reviewed By: nateanl

Differential Revision: D44504030

Pulled By: mthrok

fbshipit-source-id: 4d26d582e9fb87d4e6fa674c05fe3192bc223eef",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/streamwriter_basic_tutorial.py'],False,29,3,2023
0cd4e391ab98a8ab8a735d8b2178b43ce6004ddc,"Fix typo in audio resampling tutorial (#3212)

Summary:
Fix https://github.com/pytorch/audio/issues/3211

Pull Request resolved: https://github.com/pytorch/audio/pull/3212

Reviewed By: mthrok

Differential Revision: D44472523

Pulled By: nateanl

fbshipit-source-id: eb519b0045e7518ad13863a53271745a80d89a21",nateanl,nizhaoheng@gmail.com,['examples/tutorials/audio_resampling_tutorial.py'],False,28,3,2023
715eb34ad5b21feb6b9341a98a1716524e25067f,"Add additional filter graph option to StreamWriter (#3194)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3194

Reviewed By: hwangjeff

Differential Revision: D44283910

Pulled By: mthrok

fbshipit-source-id: 49125724896bf7190ec27f056b6bfef260019f8e",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/tensor_converter.cpp', 'torchaudio/io/_stream_writer.py']",False,28,3,2023
0846a411aa349bed8dac751923443b1a08f5257e,"Set default value to optional arguments (#3208)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3208

StreamReader/Writer is evolving and the number of arguments in
add_stream methods are growing.

This commit adds default values to these arguments.

Reviewed By: hwangjeff

Differential Revision: D44447263

fbshipit-source-id: e1c09956d78c2b4738bbeafb88195ec8e8ca5513",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,28,3,2023
ac998eb16d244e1c7381f4396671ca4519aa9933,"Fix initialization of HW acceleration (#3209)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3209

The previous code prints out the uninitialized variable when
invalid HW acceleration is provided.

This commit fixes it.

Reviewed By: hwangjeff

Differential Revision: D44449715

fbshipit-source-id: 8b76cfc27816d5ea9fbc2bc37a3148f09a8ed6ed",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp'],False,28,3,2023
b1de9f1ac2d0da727d96ff3ed4958c461ed704b3,"Revise encoder config arg and docstrings (#3203)

Summary:
For `StreamWriter`,
* Renames arg `config` to codec_config`.
* Renames struct `EncodingConfig` and dataclass `EncodeConfig` to `CodecConfig`.
* Adds docstrings for arg codec_config`.
* Updates `chunk` to `frames` in `write_*_chunk` methods.

Pull Request resolved: https://github.com/pytorch/audio/pull/3203

Reviewed By: mthrok

Differential Revision: D44350153

Pulled By: hwangjeff

fbshipit-source-id: 1b940b1366a43ec0565c362bfcbf62744088b343",hwangjeff,jeffhwang@meta.com,"['docs/source/_templates/autosummary/io_class.rst', 'test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/types.h', 'torchaudio/io/_stream_writer.py']",False,27,3,2023
4eac61a3a6c908bd85ab45c3cba26217afaab55e,"Refactor the initialization of EncodeProcess (#3205)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3205

This commit refactors the initialization of EncodeProcess.

Interface-wise, the signature of the constructor of EncodeProcess
has made simpler just to take rvalues of its components, and the
initialization of the components have been moved to helper functions.

Implementat-wise, the order that the components are initialized is
revised, and the source of initialization parameters is also revised.

For example, the original implementation first creates AVCodecContext,
and passes it around to create the other components. This relied on
an assumption that parameters AVCodecContext has (such as image size
and sample rate) are same as the source data. This is not always right,
and as we will introduce custom filter graph and allow on-the-fly
transform of rates and dimensions, it will become even less correct.

The new initialization constructs source AVFrame, TensorConverter and
FilterGraph from source attributes. This makes it easy to introduce
on-the-fly transform.

Reviewed By: nateanl

Differential Revision: D44360650

fbshipit-source-id: bf0e77dc1a5a40fc8e9870c50d07339d812762e8",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/encoder.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encoder.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,27,3,2023
d8a37a21746de6ec14c2d7e0e8273b22aa76f01c,"Properly set #samples passed to encoder (#3204)

Summary:
Some audio encoders expect specific, exact number of samples described as in `AVCodecContext.frame_size`.

The `AVFrame.nb_samples` is set for the frames passed to `AVFilterGraph`,
but frames coming out of the graph do not necessarily have the same numbr of frames.

This causes issues with encoding OPUS (among others).

This commit fixes it by inserting `asetnsamples` to filter graph if a fixed number of samples is requested.

Note:
It turned out that FFmpeg 4.1 has issue with OPUS encoding. It does not properly discard some sample.
We should probably move the minimum required FFmpeg to 4.2, but I am not sure if we can enforce it via ABI.
Work around will be to issue an warning if encoding OPUS with 4.1. (follow-up)

Pull Request resolved: https://github.com/pytorch/audio/pull/3204

Reviewed By: nateanl

Differential Revision: D44374668

Pulled By: mthrok

fbshipit-source-id: 10ef5333dc0677dfb83c8e40b78edd8ded1b21dc",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/tensor_converter.cpp']",False,25,3,2023
583174acfec932845b55fe6eac24e13345ab78db,"[torchaudio] Use more specific includes than torch/script.h (#3198)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3198

Fixes build after following diff to use F14 maps in pickler internally.

Reviewed By: mthrok

Differential Revision: D44098387

fbshipit-source-id: 9777517369d9a3f2599b273c04bf4a014f411f12",Scott Wolchok,swolchok@meta.com,"['torchaudio/csrc/rnnt/gpu/compute.cu', 'torchaudio/csrc/rnnt/gpu/compute_alphas.cu', 'torchaudio/csrc/rnnt/gpu/compute_betas.cu']",False,23,3,2023
3240de923d3a9f9efe4333eb84afc59231f8f180,"Support YUV444P in GPU decoder (#3199)

Summary:
With the support of CUDA filter in https://github.com/pytorch/audio/issues/3183, it is now possible to change the pixel format of CUDA frame.

This commit adds conversion for YUV444P format.

Pull Request resolved: https://github.com/pytorch/audio/pull/3199

Reviewed By: hwangjeff

Differential Revision: D44323928

Pulled By: mthrok

fbshipit-source-id: 6d9b205e7235df5f21e7d3e06166b3a169f1ae9f",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.h', 'torchaudio/csrc/ffmpeg/stream_reader/post_process.cpp']",False,23,3,2023
68fa1d3f42e2ba8916e67015204a4a105723b93a,"Add SquimSubjective pre-trained pipeline (#3197)

Summary:
The PR adds the pre-trained pipeline for `SquimSubjective` model which predicts MOS score for speech enhancement task.

Pull Request resolved: https://github.com/pytorch/audio/pull/3197

Reviewed By: mthrok

Differential Revision: D44313244

Pulled By: nateanl

fbshipit-source-id: 905095ff77006e9f441faa826fc25d9d8681e8aa",Zhaoheng Ni,zni@meta.com,"['README.md', 'docs/source/prototype.pipelines.rst', 'docs/source/refs.bib', 'test/integration_tests/prototype/squim_pipeline_test.py', 'torchaudio/prototype/models/squim/subjective.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/squim_pipeline.py']",False,23,3,2023
92eff1545e68fe733b3d5905d82dd07a6deaa5b6,"Warn if decoding YUV images with different plane size (#3201)

Summary:
StreamReader behaves differently when dealing with YUV formats.
It implicitly converts the image format to YUV444P because
otherwise image planes do not have the same shape and it is not
possible to express it as a regular PyTorch Tensor with dedicated
dimension for each color channel.

This is commit adds warnings to such conversions.

Pull Request resolved: https://github.com/pytorch/audio/pull/3201

Reviewed By: nateanl

Differential Revision: D44311017

Pulled By: mthrok

fbshipit-source-id: 73a02a19c013c0263f349e1f3a3603e3d3eddb6a",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/stream_reader/conversion.cpp'],False,23,3,2023
e584fc46232712fd5036895ad7f0d709620463e4,"Fix prototype.models documentation (#3202)

Summary:
In the nightly documentation, ""Prototype Factory Functions of Beta Models"" is listed as an individual section, which is not correct.
<img width=""310"" alt=""image"" src=""https://user-images.githubusercontent.com/8653221/227262349-604b99e8-1b20-4b19-9711-81e7b6cfa62e.png"">

After the PR, the section outlook is fixed
<img width=""285"" alt=""image"" src=""https://user-images.githubusercontent.com/8653221/227262893-b938d81e-6c4b-432a-833c-95981bca5e65.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/3202

Reviewed By: mthrok

Differential Revision: D44338663

Pulled By: nateanl

fbshipit-source-id: 09f591b9e4af66ebf34fb423bd5c30d4630f0b88",Zhaoheng Ni,zni@meta.com,['docs/source/prototype.models.rst'],False,23,3,2023
bf1214a922d80c84bd2450d544542f9d9cc91aaf,"Set ""experimental"" automatically when using native opus/vorbis encoder (#3192)

Summary:
OPUS encoder and VORBIS encoders require ""strict=experimental"" flags. This commit enables it automatically.

The rational behind of it is typically we care if we can encode these formats at all and not how they are encoded. (This might be concern when these encoder becomes more mature on FFmpeg side and providing flags would result in weird behavior)

Also when writing high-level functions that uses StreamWriter, if we do not set these flags, then these high-level functions have to add new options that should be passed down to StreamWriter, which turned out to be very painful in https://github.com/pytorch/audio/issues/3163

Pull Request resolved: https://github.com/pytorch/audio/pull/3192

Reviewed By: nateanl

Differential Revision: D44275089

Pulled By: mthrok

fbshipit-source-id: 74a757b4b7fc8467c8c88ffcb54fbaf89d6e4384",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp']",False,23,3,2023
aa590a1b313ce35866aa4925fda2f7fb310f3911,"Fix oscillator bank test (#3196)

Summary:
Follow up of https://github.com/pytorch/audio/pull/3083

Pull Request resolved: https://github.com/pytorch/audio/pull/3196

Reviewed By: nateanl

Differential Revision: D44308940

Pulled By: mthrok

fbshipit-source-id: e3ef27656e74c28ae78b767517d8e0ba3a9ac4a6",moto,855818+mthrok@users.noreply.github.com,['test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py'],False,22,3,2023
da86fbc78e48b716fc59809e6b76493fbdeb9a3f,"[Nova] Windows Adopt ffmpeg build to be executed from github actions (#3193)

Summary:
Adopt ffmpeg build to be executed from github actions for windows

Tested by manually invoking this script:
```
c:\actions-runner\_work\test-infra\test-infra\pytorch\audio
Chocolatey v1.2.1
Installing the following packages:
msys2
By installing, you accept licenses for the packages.
msys2 v20230318.0.0 already installed.
 Use --force to reinstall, specify a version to install, or try upgrade.

Chocolatey installed 0/1 packages.
 See the log for details (C:\ProgramData\chocolatey\logs\chocolatey.log).

Warnings:
 - msys2 - msys2 v20230318.0.0 already installed.
 Use --force to reinstall, specify a version to install, or try upgrade.

Did you know the proceeds of Pro (and some proceeds from other
 licensed editions) go into bettering the community infrastructure?
 Your support ensures an active community, keeps Chocolatey tip-top,
 plus it nets you some awesome features!
 https://chocolatey.org/compare
warning: base-devel-2022.12-2 is up to date -- skipping
warning: mingw-w64-x86_64-binutils-2.40-2 is up to date -- skipping
warning: mingw-w64-x86_64-crt-git-10.0.0.r234.g283e5b23a-1 is up to date -- skipping
warning: mingw-w64-x86_64-gcc-12.2.0-10 is up to date -- skipping
warning: mingw-w64-x86_64-gcc-ada-12.2.0-10 is up to date -- skipping
warning: mingw-w64-x86_64-gcc-fortran-12.2.0-10 is up to date -- skipping
warning: mingw-w64-x86_64-gcc-libgfortran-12.2.0-10 is up to date -- skipping
warning: mingw-w64-x86_64-gcc-libs-12.2.0-10 is up to date -- skipping
warning: mingw-w64-x86_64-gcc-objc-12.2.0-10 is up to date -- skipping
warning: mingw-w64-x86_64-gdb-13.1-3 is up to date -- skipping
warning: mingw-w64-x86_64-gdb-multiarch-13.1-3 is up to date -- skipping
warning: mingw-w64-x86_64-headers-git-10.0.0.r234.g283e5b23a-1 is up to date -- skipping
warning: mingw-w64-x86_64-libgccjit-12.2.0-10 is up to date -- skipping
warning: mingw-w64-x86_64-libmangle-git-10.0.0.r234.g283e5b23a-1 is up to date -- skipping
warning: mingw-w64-x86_64-libwinpthread-git-10.0.0.r234.g283e5b23a-1 is up to date -- skipping
warning: mingw-w64-x86_64-make-4.4-2 is up to date -- skipping
warning: mingw-w64-x86_64-pkgconf-1~1.8.0-2 is up to date -- skipping
warning: mingw-w64-x86_64-tools-git-10.0.0.r234.g283e5b23a-1 is up to date -- skipping
warning: mingw-w64-x86_64-winpthreads-git-10.0.0.r234.g283e5b23a-1 is up to date -- skipping
warning: mingw-w64-x86_64-winstorecompat-git-10.0.0.r234.g283e5b23a-1 is up to date -- skipping
warning: diffutils-3.9-1 is up to date -- skipping
 there is nothing to do

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>set VC_VERSION_LOWER=16

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>set VC_VERSION_UPPER=17

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>for /F ""usebackq tokens=*"" %i in (`""C:\Program F
iles (x86)\Microsoft Visual Studio\Installer\vswhere.exe"" -legacy -products * -version [16,17) -property installationPath`) do (if exis
t ""%i"" if exist ""%i\VC\Auxiliary\Build\vcvarsall.bat"" (
set ""VS15INSTALLDIR=%i""
 set ""VS15VCVARSALL=%i\VC\Auxiliary\Build\vcvarsall.bat""
 goto vswhere
) )

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>(if exist ""C:\Program Files (x86)\Microsoft Visu
al Studio\2019\BuildTools"" if exist ""C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Auxiliary\Build\vcvarsall.bat"" (
set ""VS15INSTALLDIR=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools""
 set ""VS15VCVARSALL=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Auxiliary\Build\vcvarsall.bat""
 goto vswhere
) )

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>if """" == """" (call ""C:\Program Files (x86)\Micros
oft Visual Studio\2019\BuildTools\VC\Auxiliary\Build\vcvarsall.bat"" x64   || exit /b 1 )  else (call ""C:\Program Files (x86)\Microsoft
Visual Studio\2019\BuildTools\VC\Auxiliary\Build\vcvarsall.bat"" x64    || exit /b 1 )
**********************************************************************
** Visual Studio 2019 Developer Command Prompt v16.8.6
** Copyright (c) 2020 Microsoft Corporation
**********************************************************************
[vcvarsall.bat] Environment initialized for: 'x64'

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>set DISTUTILS_USE_SDK=1

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>set args=bash

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>shift

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>if [./packaging/ffmpeg/build.sh] == [] goto done

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>set args=bash ./packaging/ffmpeg/build.sh

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>shift

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>goto start

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>if [] == [] goto done

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>if ""bash ./packaging/ffmpeg/build.sh"" == """" (
echo Usage: vc_env_helper.bat [command] [args]
 echo e.g. vc_env_helper.bat cl /c test.cpp
)

runneruser@EC2AMAZ-S19AQ2Q C:\actions-runner\_work\test-infra\test-infra\pytorch\audio>bash ./packaging/ffmpeg/build.sh   || exit /b 1
+ prefix=C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg
+ args=
+ [[ msys == \m\s\y\s ]]
+ args=--toolchain=msvc
++ mktemp -d -t ffmpeg-build.XXXXXXXXXX
+ build_dir=/tmp/ffmpeg-build.bVdKugGnTP
+ trap 'cleanup $?' EXIT
+ cd /tmp/ffmpeg-build.bVdKugGnTP
+ curl -LsS -o ffmpeg.tar.gz https://github.com/FFmpeg/FFmpeg/archive/refs/tags/n4.1.8.tar.gz
+ tar -xf ffmpeg.tar.gz --strip-components 1
+ ./configure --prefix=C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg --disable-all --disable-everythin
g --disable-programs --disable-doc --disable-debug --disable-autodetect --disable-x86asm --disable-iconv --disable-encoders --disable-d
ecoders --disable-hwaccels --disable-muxers --disable-demuxers --disable-parsers --disable-bsfs --disable-protocols --disable-devices -
-disable-filters --disable-asm --disable-static --enable-shared --enable-rpath --enable-pic --enable-avcodec --enable-avdevice --enable
-avfilter --enable-avformat --enable-avutil --toolchain=msvc
install prefix            C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg
source path               .
C compiler                cl
C library                 msvcrt
ARCH                      c (generic)
big-endian                no
runtime cpu detection     yes
debug symbols             no
strip symbols             no
optimize for size         no
optimizations             yes
static                    no
shared                    yes
postprocessing support    no
network support           yes
threading support         w32threads
safe bitstream reader     yes
texi2html enabled         no
perl enabled              yes
pod2man enabled           yes
makeinfo enabled          yes
makeinfo supports HTML    yes

External libraries:

External libraries providing hardware acceleration:

Libraries:
avcodec                    avdevice                   avfilter                   avformat                   avutil

Programs:

Enabled decoders:

Enabled encoders:

Enabled hwaccels:

Enabled parsers:

Enabled demuxers:

Enabled muxers:

Enabled protocols:

Enabled filters:

Enabled bsfs:
null

Enabled indevs:

Enabled outdevs:

License: LGPL version 2.1 or later
+ make -j install
GEN     libavdevice/libavdevice.version
GEN     libavfilter/libavfilter.version
GEN     libavformat/libavformat.version
GEN     libavcodec/libavcodec.version
GEN     libavutil/libavutil.version
INSTALL doc/examples/avio_dir_cmd.c
INSTALL doc/examples/avio_reading.c
INSTALL doc/examples/decode_audio.c
INSTALL doc/examples/decode_video.c
INSTALL doc/examples/demuxing_decoding.c
INSTALL doc/examples/encode_audio.c
INSTALL doc/examples/encode_video.c
INSTALL doc/examples/extract_mvs.c
INSTALL doc/examples/filter_audio.c
INSTALL doc/examples/filtering_audio.c
INSTALL doc/examples/filtering_video.c
INSTALL doc/examples/http_multiclient.c
INSTALL doc/examples/hw_decode.c
INSTALL doc/examples/metadata.c
INSTALL doc/examples/muxing.c
INSTALL doc/examples/qsvdec.c
INSTALL doc/examples/remuxing.c
INSTALL doc/examples/resampling_audio.c
INSTALL doc/examples/scaling_video.c
INSTALL doc/examples/transcode_aac.c
INSTALL doc/examples/transcoding.c
INSTALL doc/examples/vaapi_encode.c
INSTALL doc/examples/vaapi_transcode.c
INSTALL doc/examples/README
INSTALL doc/examples/Makefile
CC      libavdevice/avdevice.o
CC      libavdevice/reverse.o
avdevice.c
reverse.c
libavdevice/avdevice.c(88): warning C4996: 'av_oformat_next': was declared deprecated
libavdevice/avdevice.c(92): warning C4996: 'av_iformat_next': was declared deprecated
CC      libavdevice/utils.o
INSTALL doc/examples/avio_dir_cmd.c
INSTALL doc/examples/avio_reading.c
INSTALL doc/examples/decode_audio.c
INSTALL doc/examples/decode_video.c
INSTALL doc/examples/demuxing_decoding.c
CC      libavdevice/alldevices.o
INSTALL doc/examples/encode_audio.c
INSTALL doc/examples/encode_video.c
INSTALL doc/examples/extract_mvs.c
INSTALL doc/examples/filter_audio.c
INSTALL doc/examples/filtering_audio.c
INSTALL doc/examples/filtering_video.c
INSTALL doc/examples/http_multiclient.c
INSTALL doc/examples/hw_decode.c
INSTALL doc/examples/metadata.c
INSTALL doc/examples/muxing.c
INSTALL doc/examples/qsvdec.c
INSTALL doc/examples/remuxing.c
INSTALL doc/examples/resampling_audio.c
INSTALL doc/examples/scaling_video.c
INSTALL doc/examples/transcode_aac.c
INSTALL doc/examples/transcoding.c
INSTALL doc/examples/vaapi_encode.c
INSTALL doc/examples/vaapi_transcode.c
INSTALL doc/examples/README
INSTALL doc/examples/Makefile
utils.c
CC      libavformat/dump.o
CC      libavformat/allformats.o
alldevices.c
dump.c
allformats.c
CC      libavformat/id3v1.o
CC      libavformat/golomb_tab.o
CC      libavformat/metadata.o
CC      libavformat/log2_tab.o
id3v1.c
golomb_tab.c
log2_tab.c
CC      libavdevice/file_open.o
metadata.c
CC      libavformat/protocols.o
file_open.c
CC      libavformat/avio.o
CC      libavformat/format.o
protocols.c
format.c
libavformat/protocols.c(99): warning C4090: '=': different 'const' qualifiers
avio.c
CC      libavformat/file_open.o
CC      libavformat/cutils.o
CC      libavcodec/ac3_parser.o
file_open.c
CC      libavformat/aviobuf.o
libavformat/format.c(308): warning C4090: 'function': different 'const' qualifiers
aviobuf.c
cutils.c
ac3_parser.c
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavcodec\get_bits.h(481): warning C4101: 're_cache': unreferenced local variable
CC      libavformat/qtpalette.o
libavformat/avio.c(113): warning C4267: 'initializing': conversion from 'size_t' to 'int', possible loss of dataCC      libavformat/id3
v2.o

libavformat/avio.c(276): warning C4090: 'function': different 'const' qualifiers
libavformat/avio.c(281): warning C4090: 'function': different 'const' qualifiers
libavformat/avio.c(285): warning C4090: 'function': different 'const' qualifiers
CC      libavcodec/allcodecs.o
CC      libavformat/network.o
CC      libavcodec/avpacket.o
id3v2.c
qtpalette.c
CC      libavcodec/adts_parser.o
CC      libavcodec/avpicture.o
avpacket.c
allcodecs.c
network.c
adts_parser.c
libavformat/aviobuf.c(389): warning C4267: '+=': conversion from 'size_t' to 'int', possible loss of data
libavformat/aviobuf.c(1230): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
libavformat/aviobuf.c(1265): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
CC      libavcodec/avdct.o
libavcodec/avpacket.c(131): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
libavcodec/avpacket.c(307): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavcodec/avpacket.c(321): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavcodec/avpacket.c(512): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
avpicture.c
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavcodec\get_bits.h(481): warning C4101: 're_cache': unreferenced local variable
CC      libavformat/mux.o
CC      libavformat/utils.o
CC      libavcodec/bitstream_filter.o
avdct.c
libavformat/id3v2.c(347): warning C4090: 'function': different 'const' qualifiers
CC      libavformat/os_support.o
mux.c
utils.c
bitstream_filter.c
CC      libavformat/options.o
libavformat/network.c(340): warning C4267: 'function': conversion from 'size_t' to 'socklen_t', possible loss of data
libavformat/network.c(377): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
libavformat/network.c(428): warning C4267: 'function': conversion from 'size_t' to 'socklen_t', possible loss of data
libavformat/network.c(485): warning C4267: 'function': conversion from 'size_t' to 'socklen_t', possible loss of dataCC libavcodec/bits
tream_filters.o

libavformat/network.c(500): warning C4267: 'function': conversion from 'size_t' to 'socklen_t', possible loss of dataCC libavcodec/d3d1
1va.o

libavformat/network.c(537): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavformat/network.c(538): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
CC      libavformat/url.o
os_support.c
CC      libavformat/sdp.o
CC      libavformat/riff.o
CC      libavcodec/bsf.o
url.c
d3d11va.c
options.c
bitstream_filters.c
CC      libavcodec/bitstream.o
CC      libavcodec/dirac.o
libavformat/utils.c(225): warning C4996: 'av_codec_next': was declared deprecated
riff.c
sdp.c
bsf.c
libavformat/utils.c(4716): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavformat/utils.c(5520): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavformat/utils.c(5539): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
dirac.c
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavcodec\get_bits.h(481): warning C4101: 're_cache': unreferenced local variable
bitstream.c
libavcodec/bitstream.c(125): warning C4334: '<<': result of 32-bit shift implicitly converted to 64 bits (was 64-bit shift intended?)
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavcodec\get_bits.h(481): warning C4101: 're_cache': unreferenced local variable
CC      libavcodec/fdctdsp.o
CC      libavcodec/codec_desc.o
libavformat/options.c(64): warning C4996: 'av_iformat_next': was declared deprecated
libavformat/options.c(69): warning C4996: 'av_oformat_next': was declared deprecated
fdctdsp.c
libavformat/options.c(73): warning C4996: 'av_iformat_next': was declared deprecatedCC  libavcodec/encode.o

libavformat/options.c(77): warning C4996: 'av_oformat_next': was declared deprecated
CC      libavcodec/faanidct.o
libavformat/url.c(77): warning C4267: 'return': conversion from 'size_t' to 'int', possible loss of data
codec_desc.c
encode.c
CC      libavcodec/faandct.o
CC      libavcodec/decode.o
CC      libavcodec/dv_profile.o
faanidct.c
libavcodec/encode.c(365): warning C4996: 'avcodec_encode_video2': was declared deprecated
libavcodec/encode.c(368): warning C4996: 'avcodec_encode_audio2': was declared deprecated
faandct.c
dv_profile.c
decode.c
CC      libavcodec/idctdsp.o
libavcodec/decode.c(845): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
idctdsp.c
CC      libavcodec/imgconvert.o
CC      libavcodec/jfdctint.o
CC      libavcodec/jfdctfst.o
jfdctint.c
imgconvert.c
jfdctfst.c
CC      libavcodec/jni.o
CC      libavcodec/jrevdct.o
CC      libavcodec/log2_tab.o
CC      libavcodec/mediacodec.o
jrevdct.c
jni.c
log2_tab.c
mediacodec.c
CC      libavcodec/file_open.o
CC      libavcodec/null_bsf.o
CC      libavcodec/options.o
CC      libavcodec/mathtables.o
CC      libavcodec/mjpegenc_huffman.o
options.c
file_open.c
null_bsf.c
mathtables.c
mjpegenc_huffman.c
libavcodec/options.c(61): warning C4996: 'av_codec_next': was declared deprecated
libavcodec/options.c(66): warning C4996: 'av_codec_next': was declared deprecated
CC      libavcodec/parser.o
CC      libavcodec/profiles.o
CC      libavcodec/mpeg12framerate.o
CC      libavcodec/pthread.o
parser.c
profiles.c
mpeg12framerate.c
pthread.c
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavcodec\get_bits.h(481): warning C4101: 're_cache': unreferenced local variable
CC      libavcodec/simple_idct.o
CC      libavcodec/raw.o
CC      libavcodec/pthread_slice.o
CC      libavcodec/qsv_api.o
simple_idct.c
CC      libavcodec/reverse.o
raw.c
CC      libavcodec/xiph.o
pthread_slice.c
CC      libavcodec/vorbis_parser.o
qsv_api.c
reverse.c
CC      libavcodec/parsers.o
xiph.c
vorbis_parser.c
CC      libavcodec/pthread_frame.o
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavcodec\get_bits.h(481): warning C4101: 're_cache': unreferenced local variable
parsers.c
pthread_frame.c
CC      libavutil/aes.o
aes.c
CC      libavutil/audio_fifo.o
CC      libavutil/base64.o
CC      libavutil/avstring.o
CC      libavutil/aes_ctr.o
audio_fifo.c
CC      libavcodec/utils.o
avstring.c
base64.c
CC      libavutil/bprint.o
CC      libavutil/blowfish.o
CC      libavutil/adler32.o
libavutil/avstring.c(246): warning C4267: 'function': conversion from 'size_t' to 'unsigned int', possible loss of data
libavutil/avstring.c(248): warning C4267: 'function': conversion from 'size_t' to 'unsigned int', possible loss of dataaes_ctr.c

libavutil/avstring.c(352): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
CC      libavutil/camellia.o
utils.c
blowfish.c
adler32.c
bprint.c
CC      libavutil/buffer.o
CC      libavutil/color_utils.o
CC      libavutil/channel_layout.o
.\libavutil/mem_internal.h(42): warning C4267: '=': conversion from 'size_t' to 'unsigned int', possible loss of data
libavutil/bprint.c(190): warning C4267: '=': conversion from 'size_t' to 'unsigned int', possible loss of data
libavutil/bprint.c(215): warning C4267: 'function': conversion from 'size_t' to 'unsigned int', possible loss of data
camellia.c
buffer.c
color_utils.c
CC      libavutil/cast5.o
channel_layout.c
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavcodec\get_bits.h(481): warning C4101: 're_cache': unreferenced local variable
libavcodec/utils.c(1361): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
libavcodec/utils.c(2034): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
cast5.c
CC      libavutil/cpu.o
cpu.c
CC      libavutil/crc.o
CC      libavutil/dict.o
CC      libavutil/des.o
des.c
crc.c
dict.c
CC      libavutil/downmix_info.o
libavutil/cpu.c(185): warning C4090: 'function': different 'const' qualifiers
libavutil/cpu.c(264): warning C4090: 'function': different 'const' qualifiers
CC      libavutil/display.o
downmix_info.c
CC      libavutil/error.o
CC      libavutil/eval.o
CC      libavutil/encryption_info.o
CC      libavutil/fixed_dsp.o
display.c
CC      libavutil/hmac.o
error.c
eval.c
encryption_info.c
fixed_dsp.c
hmac.c
CC      libavutil/hash.o
libavutil/fixed_dsp.c(161): warning C4028: formal parameter 1 different from declaration
libavutil/fixed_dsp.c(161): warning C4028: formal parameter 2 different from declaration
CC      libavutil/fifo.o
CC      libavutil/hwcontext.o
CC      libavutil/float_dsp.o
hash.c
fifo.c
CC      libavutil/file.o
CC      libavutil/imgutils.o
hwcontext.c
float_dsp.c
CC      libavutil/integer.o
CC      libavutil/frame.o
file.c
imgutils.c
CC      libavutil/file_open.o
CC      libavutil/intmath.o
CC      libavutil/lfg.o
libavutil/imgutils.c(527): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
libavutil/imgutils.c(527): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
frame.c
integer.c
file_open.c
libavutil/frame.c(760): warning C4090: 'function': different 'const' qualifiers
libavutil/frame.c(903): warning C4267: '-=': conversion from 'size_t' to 'int', possible loss of data
libavutil/frame.c(904): warning C4267: '-=': conversion from 'size_t' to 'int', possible loss of data
libavutil/frame.c(915): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
libavutil/frame.c(919): warning C4267: 'function': conversion from 'size_t' to 'int', possible loss of data
libavutil/frame.c(937): warning C4267: '-=': conversion from 'size_t' to 'int', possible loss of data
libavutil/frame.c(938): warning C4267: '-=': conversion from 'size_t' to 'int', possible loss of data
intmath.c
lfg.c
CC      libavutil/lls.o
lls.c
CC      libavutil/log2_tab.o
CC      libavutil/mastering_display_metadata.o
CC      libavutil/mathematics.o
log2_tab.c
CC      libavutil/mem.o
CC      libavutil/md5.o
mastering_display_metadata.c
mathematics.c
mem.c
md5.c
CC      libavutil/murmur3.o
CC      libavutil/log.o
C:\tools\msys64\tmp\ffmpeg-build.bVdKugGnTP\libavutil\mem_internal.h(42): warning C4267: '=': conversion from 'size_t' to 'unsigned int
', possible loss of data
libavutil/mem.c(495): warning C4267: '=': conversion from 'size_t' to 'unsigned int', possible loss of data
murmur3.c
log.c
libavutil/md5.c(103): warning C4101: 'i': unreferenced local variableCC libavutil/parseutils.o

CC      libavutil/opt.o
CC      libavutil/pixelutils.o
parseutils.c
CC      libavutil/pixdesc.o
CC      libavutil/reverse.o
CC      libavutil/rational.o
libavutil/parseutils.c(367): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavutil/parseutils.c(372): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavutil/parseutils.c(479): warning C4267: 'initializing': conversion from 'size_t' to 'int', possible loss of data
opt.c
pixelutils.c
CC      libavutil/rc4.o
pixdesc.c
rational.c
reverse.c
libavutil/opt.c(189): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavutil/opt.c(440): warning C4133: 'function': incompatible types - from 'AVPixelFormat (__cdecl *)(const char *)' to 'int (__cdecl *
)(const char *)'
libavutil/opt.c(446): warning C4133: 'function': incompatible types - from 'AVSampleFormat (__cdecl *)(const char *)' to 'int (__cdecl
*)(const char *)'
libavutil/opt.c(847): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
libavutil/opt.c(982): warning C4133: 'function': incompatible types - from 'AVPixelFormat *' to 'int *'
libavutil/opt.c(987): warning C4133: 'function': incompatible types - from 'AVSampleFormat *' to 'int *'
libavutil/opt.c(1632): warning C4090: 'function': different 'const' qualifiers
libavutil/opt.c(1675): warning C4090: 'function': different 'const' qualifiers
libavutil/opt.c(1877): warning C4090: 'function': different 'const' qualifiers
libavutil/pixdesc.c(2551): warning C4267: '=': conversion from 'size_t' to 'int', possible loss of data
rc4.c
CC      libavutil/ripemd.o
CC      libavutil/sha.o
CC      libavutil/samplefmt.o
ripemd.c
samplefmt.c
CC      libavutil/sha512.o
sha.c
libavutil/ripemd.c(136): warning C4101: 't': unreferenced local variable
libavutil/ripemd.c(193): warning C4101: 't': unreferenced local variable
libavutil/ripemd.c(318): warning C4101: 't': unreferenced local variable
libavutil/ripemd.c(390): warning C4101: 't': unreferenced local variable
sha512.c
CC      libavutil/stereo3d.o
CC      libavutil/xtea.o
CC      libavutil/slicethread.o
CC      libavutil/threadmessage.o
stereo3d.c
xtea.c
CC      libavutil/timecode.o
slicethread.c
CC      libavutil/xga_font_data.o
CC      libavutil/utils.o
threadmessage.c
timecode.c
CC      libavutil/tree.o
utils.c
CC      libavutil/random_seed.o
xga_font_data.c
CC      libavutil/twofish.o
tree.c
CC      libavutil/time.o
CC      libavutil/tea.o
CC      libavutil/spherical.o
random_seed.c
time.c
twofish.c
tea.c
spherical.c
CC      libavfilter/avfiltergraph.o
CC      libavfilter/audio.o
avfiltergraph.c
GEN     libavdevice/libavdevice.pc
audio.c
CC      libavfilter/buffersrc.o
CC      libavfilter/fifo.o
buffersrc.c
CC      libavfilter/allfilters.o
fifo.c
CC      libavfilter/log2_tab.o
CC      libavfilter/framequeue.o
CC      libavfilter/framepool.o
CC      libavfilter/graphdump.o
CC      libavfilter/drawutils.o
allfilters.c
CC      libavfilter/formats.o
INSTALL libavdevice/avdevice.h
INSTALL libavdevice/version.h
log2_tab.c
framepool.c
framequeue.c
graphdump.c
CC      libavfilter/buffersink.o
drawutils.c
formats.c
CC      libavfilter/transform.o
CC      libavfilter/avfilter.o
libavfilter/framequeue.c(143): warning C4267: '-=': conversion from 'size_t' to 'int', possible loss of data
libavfilter/framequeue.c(144): warning C4267: '-=': conversion from 'size_t' to 'int', possible loss of data
libavfilter/graphdump.c(79): warning C4267: '=': conversion from 'size_t' to 'unsigned int', possible loss of data
libavfilter/graphdump.c(86): warning C4267: '=': conversion from 'size_t' to 'unsigned int', possible loss of data
libavfilter/graphdump.c(108): warning C4267: '=': conversion from 'size_t' to 'unsigned int', possible loss of data
libavfilter/graphdump.c(72): warning C4267: 'initializing': conversion from 'size_t' to 'unsigned int', possible loss of data
libavfilter/graphdump.c(73): warning C4267: 'initializing': conversion from 'size_t' to 'unsigned int', possible loss of data
libavfilter/graphdump.c(77): warning C4267: 'initializing': conversion from 'size_t' to 'unsigned int', possible loss of data
libavfilter/graphdump.c(84): warning C4267: 'initializing': conversion from 'size_t' to 'unsigned int', possible loss of data
libavfilter/graphdump.c(133): warning C4267: 'initializing': conversion from 'size_t' to 'unsigned int', possible loss of data
buffersink.c
GEN     libavfilter/libavfilter.pc
CC      libavfilter/pthread.o
CC      libavfilter/graphparser.o
libavfilter/buffersink.c(137): warning C4133: '=': incompatible types - from 'const int *' to 'const AVPixelFormat *'
transform.c
avfilter.c
CC      libavfilter/video.o
pthread.c
graphparser.c
GEN     libavformat/libavformat.pc
INSTALL libavfilter/avfilter.h
INSTALL libavfilter/buffersink.h
INSTALL libavfilter/buffersrc.h
INSTALL libavfilter/version.h
video.c
GEN     libavcodec/libavcodec.pc
libavfilter/avfilter.c(51): warning C4101: 'buf': unreferenced local variable
INSTALL libavformat/avformat.h
INSTALL libavformat/avio.h
INSTALL libavformat/version.h
INSTALL libavcodec/ac3_parser.h
INSTALL libavcodec/adts_parser.h
INSTALL libavcodec/avcodec.h
INSTALL libavcodec/avdct.h
INSTALL libavcodec/avfft.h
INSTALL libavcodec/d3d11va.h
INSTALL libavcodec/dirac.h
INSTALL libavcodec/dv_profile.h
INSTALL libavcodec/dxva2.h
INSTALL libavcodec/jni.h
INSTALL libavcodec/mediacodec.h
INSTALL libavcodec/qsv.h
INSTALL libavcodec/vaapi.h
INSTALL libavcodec/vdpau.h
INSTALL libavcodec/version.h
INSTALL libavcodec/videotoolbox.h
INSTALL libavcodec/vorbis_parser.h
INSTALL libavcodec/xvmc.h
GEN     libavutil/libavutil.pc
GEN     libavdevice/libavdevice.ver
INSTALL libavutil/adler32.h
INSTALL libavutil/aes.h
INSTALL libavutil/aes_ctr.h
INSTALL libavutil/attributes.h
INSTALL libavutil/audio_fifo.h
INSTALL libavutil/avassert.h
INSTALL libavutil/avstring.h
INSTALL libavutil/avutil.h
INSTALL libavutil/base64.h
INSTALL libavutil/blowfish.h
INSTALL libavutil/bprint.h
INSTALL libavutil/bswap.h
INSTALL libavutil/buffer.h
INSTALL libavutil/cast5.h
INSTALL libavutil/camellia.h
INSTALL libavutil/channel_layout.h
INSTALL libavutil/common.h
INSTALL libavutil/cpu.h
INSTALL libavutil/crc.h
INSTALL libavutil/des.h
INSTALL libavutil/dict.h
INSTALL libavutil/display.h
INSTALL libavutil/downmix_info.h
INSTALL libavutil/encryption_info.h
INSTALL libavutil/error.h
INSTALL libavutil/eval.h
INSTALL libavutil/fifo.h
INSTALL libavutil/file.h
INSTALL libavutil/frame.h
INSTALL libavutil/hash.h
INSTALL libavutil/hmac.h
INSTALL libavutil/hwcontext.h
INSTALL libavutil/hwcontext_cuda.h
INSTALL libavutil/hwcontext_d3d11va.h
INSTALL libavutil/hwcontext_drm.h
INSTALL libavutil/hwcontext_dxva2.h
INSTALL libavutil/hwcontext_qsv.h
INSTALL libavutil/hwcontext_mediacodec.h
INSTALL libavutil/hwcontext_vaapi.h
INSTALL libavutil/hwcontext_videotoolbox.h
INSTALL libavutil/hwcontext_vdpau.h
INSTALL libavutil/imgutils.h
INSTALL libavutil/intfloat.h
INSTALL libavutil/intreadwrite.h
INSTALL libavutil/lfg.h
INSTALL libavutil/log.h
INSTALL libavutil/macros.h
INSTALL libavutil/mathematics.h
INSTALL libavutil/mastering_display_metadata.h
INSTALL libavutil/md5.h
INSTALL libavutil/mem.h
INSTALL libavutil/motion_vector.h
INSTALL libavutil/murmur3.h
INSTALL libavutil/opt.h
INSTALL libavutil/parseutils.h
INSTALL libavutil/pixdesc.h
INSTALL libavutil/pixelutils.h
INSTALL libavutil/pixfmt.h
INSTALL libavutil/random_seed.h
INSTALL libavutil/rc4.h
INSTALL libavutil/rational.h
INSTALL libavutil/replaygain.h
INSTALL libavutil/ripemd.h
INSTALL libavutil/samplefmt.h
INSTALL libavutil/sha.h
INSTALL libavutil/sha512.h
INSTALL libavutil/spherical.h
INSTALL libavutil/stereo3d.h
INSTALL libavutil/threadmessage.h
INSTALL libavutil/time.h
INSTALL libavutil/timecode.h
INSTALL libavutil/timestamp.h
INSTALL libavutil/tree.h
INSTALL libavutil/twofish.h
INSTALL libavutil/version.h
INSTALL libavutil/xtea.h
INSTALL libavutil/tea.h
INSTALL libavutil/avconfig.h
INSTALL libavutil/ffversion.h
GEN     libavformat/libavformat.ver
GEN     libavcodec/libavcodec.ver
GEN     libavutil/libavutil.ver
GEN     libavfilter/libavfilter.ver
EXTERN_PREFIX="""" ./compat/windows/makedef libavutil/libavutil.ver libavutil/adler32.o libavutil/aes.o libavutil/aes_ctr.o libavutil/aud
io_fifo.o libavutil/avstring.o libavutil/base64.o libavutil/blowfish.o libavutil/bprint.o libavutil/buffer.o libavutil/camellia.o libav
util/cast5.o libavutil/channel_layout.o libavutil/color_utils.o libavutil/cpu.o libavutil/crc.o libavutil/des.o libavutil/dict.o libavu
til/display.o libavutil/downmix_info.o libavutil/encryption_info.o libavutil/error.o libavutil/eval.o libavutil/fifo.o libavutil/file.o
 libavutil/file_open.o libavutil/fixed_dsp.o libavutil/float_dsp.o libavutil/frame.o libavutil/hash.o libavutil/hmac.o libavutil/hwcont
ext.o libavutil/imgutils.o libavutil/integer.o libavutil/intmath.o libavutil/lfg.o libavutil/lls.o libavutil/log.o libavutil/log2_tab.o
 libavutil/mastering_display_metadata.o libavutil/mathematics.o libavutil/md5.o libavutil/mem.o libavutil/murmur3.o libavutil/opt.o lib
avutil/parseutils.o libavutil/pixdesc.o libavutil/pixelutils.o libavutil/random_seed.o libavutil/rational.o libavutil/rc4.o libavutil/r
everse.o libavutil/ripemd.o libavutil/samplefmt.o libavutil/sha.o libavutil/sha512.o libavutil/slicethread.o libavutil/spherical.o liba
vutil/stereo3d.o libavutil/tea.o libavutil/threadmessage.o libavutil/time.o libavutil/timecode.o libavutil/tree.o libavutil/twofish.o l
ibavutil/utils.o libavutil/xga_font_data.o libavutil/xtea.o > libavutil/avutil-56.def
INSTALL libavdevice/libavdevice.pc
INSTALL libavfilter/libavfilter.pc
INSTALL libavformat/libavformat.pc
INSTALL libavcodec/libavcodec.pc
INSTALL libavutil/libavutil.pc
LD      libavutil/avutil-56.dll
LINK : warning LNK4044: unrecognized option '/Wl,-rpath,C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/
lib'; ignored
   Creating library libavutil/avutil.lib and object libavutil/avutil.exp
EXTERN_PREFIX="""" ./compat/windows/makedef libavcodec/libavcodec.ver libavcodec/ac3_parser.o libavcodec/adts_parser.o libavcodec/allcode
cs.o libavcodec/avdct.o libavcodec/avpacket.o libavcodec/avpicture.o libavcodec/bitstream.o libavcodec/bitstream_filter.o libavcodec/bi
tstream_filters.o libavcodec/bsf.o libavcodec/codec_desc.o libavcodec/d3d11va.o libavcodec/decode.o libavcodec/dirac.o libavcodec/dv_pr
ofile.o libavcodec/encode.o libavcodec/faandct.o libavcodec/faanidct.o libavcodec/fdctdsp.o libavcodec/file_open.o libavcodec/idctdsp.o
 libavcodec/imgconvert.o libavcodec/jfdctfst.o libavcodec/jfdctint.o libavcodec/jni.o libavcodec/jrevdct.o libavcodec/log2_tab.o libavc
odec/mathtables.o libavcodec/mediacodec.o libavcodec/mjpegenc_huffman.o libavcodec/mpeg12framerate.o libavcodec/null_bsf.o libavcodec/o
ptions.o libavcodec/parser.o libavcodec/parsers.o libavcodec/profiles.o libavcodec/pthread.o libavcodec/pthread_frame.o libavcodec/pthr
ead_slice.o libavcodec/qsv_api.o libavcodec/raw.o libavcodec/reverse.o libavcodec/simple_idct.o libavcodec/utils.o libavcodec/vorbis_pa
rser.o libavcodec/xiph.o > libavcodec/avcodec-58.def
EXTERN_PREFIX="""" ./compat/windows/makedef libavfilter/libavfilter.ver libavfilter/allfilters.o libavfilter/audio.o libavfilter/avfilter
.o libavfilter/avfiltergraph.o libavfilter/buffersink.o libavfilter/buffersrc.o libavfilter/drawutils.o libavfilter/fifo.o libavfilter/
formats.o libavfilter/framepool.o libavfilter/framequeue.o libavfilter/graphdump.o libavfilter/graphparser.o libavfilter/log2_tab.o lib
avfilter/pthread.o libavfilter/transform.o libavfilter/video.o > libavfilter/avfilter-7.def
INSTALL libavutil/avutil.dll
STRIP   install-libavutil-shared
skipping strip C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/bin/avutil-56.dll
INSTALL libavutil/avutil.dll
INSTALL libavutil/avutil.dll
LD      libavcodec/avcodec-58.dll
LINK : warning LNK4044: unrecognized option '/Wl,-rpath,C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/
lib'; ignored
   Creating library libavcodec/avcodec.lib and object libavcodec/avcodec.exp
LD      libavfilter/avfilter-7.dll
LINK : warning LNK4044: unrecognized option '/Wl,-rpath,C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/
EXTERN_PREFIX="""" ./compat/windows/makedef libavdevice/libavdevice.ver libavdevice/alldevices.o libavdevice/avdevice.o libavdevice/file_opeEXTERN_PREFIX="""" ./compat/windows/makedef libavdevice/libavdevice.ver libavdevice/alldevices.o libavdevice/avdevice.o libavdevice/file_openNSTALL libavformat/avformat.dll
.o libavdevice/reverse.o libavdevice/utils.o > libavdevice/avdevice-58.def
INSTALL libavformat/avformat.dll
EXTERN_PREFIX="""" ./compat/windows/makedef libavdevice/libavdevice.ver libavdevice/alldevices.o libavdevice/avdevice.o libavdevice/file_ope
n.o libavdevice/reverse.o libavdevice/utils.o > libavdevice/avdevice-58.def
INSTALL libavformat/avformat.dll
STRIP   install-libavformat-shared
skipping strip C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/bin/avformat-58.dll                         INSTALL libavformat/avformat.dll                                                                                                          INSTALL libavformat/avformat.dll
LD      libavdevice/avdevice-58.dll
LINK : warning LNK4044: unrecognized option '/Wl,-rpath,C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/lib
'; ignored
   Creating library libavdevice/avdevice.lib and object libavdevice/avdevice.exp
INSTALL libavdevice/avdevice.dll
STRIP   install-libavdevice-shared
skipping strip C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/bin/avdevice-58.dll                         INSTALL libavdevice/avdevice.dll                                                                                                          INSTALL libavdevice/avdevice.dll                                                                                                          + ls C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/bin C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/include C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/lib C:/actions-runner/
_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/share
'C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/bin':
avcodec.lib     avdevice.lib     avfilter.lib    avformat.lib     avutil.lib
avcodec-58.dll  avdevice-58.dll  avfilter-7.dll  avformat-58.dll  avutil-56.dll

'C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/include':
libavcodec  libavdevice  libavfilter  libavformat  libavutil

'C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/lib':
avcodec-58.def  avdevice-58.def  avfilter-7.def  avformat-58.def  avutil-56.def  pkgconfig

'C:/actions-runner/_work/test-infra/test-infra/pytorch/audio/third_party/ffmpeg/share':
ffmpeg
++ uname
+ [[ MINGW64_NT-10.0-17763 == Darwin ]]
+ cleanup 0
+ rm -rf /tmp/ffmpeg-build.bVdKugGnTP
runneruser@EC2AMAZ-S19AQ2Q c:\actions-runner\_work\test-infra\test-infra\pytorch\audio>

```

Pull Request resolved: https://github.com/pytorch/audio/pull/3193

Reviewed By: DanilBaibak

Differential Revision: D44294838

Pulled By: atalman

fbshipit-source-id: 7522d329537daf99dff8a12db8afdeeffaa2138c",atalman,atalman@fb.com,['packaging/ffmpeg/build.bat'],False,22,3,2023
a8a16238cb8ba468b334fe86709d5c6e06eac16d,"Add SquimSubjective Model (#3189)

Summary:
Add model architecture and factory functions for `SquimSubjective` which predicts subjective evaluation metric scores (e.g. MOS) for speech enhancement task.

Pull Request resolved: https://github.com/pytorch/audio/pull/3189

Reviewed By: mthrok

Differential Revision: D44267255

Pulled By: nateanl

fbshipit-source-id: f8060398b14c625b38ea1bb2417f61aeaec3f1db",Zhaoheng Ni,zni@meta.com,"['docs/source/_templates/autosummary/prototype_model_class.rst', 'docs/source/prototype.models.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/prototype/squim_test.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/squim/__init__.py', 'torchaudio/prototype/models/squim/subjective.py']",False,21,3,2023
f8d8ffb5f135587b95c2962ab473a201f1ed1224,"Update prototype Conformer doc & docstring (#3191)

Summary:
To suppress local warning of flake8 <120

Pull Request resolved: https://github.com/pytorch/audio/pull/3191

Reviewed By: nateanl

Differential Revision: D44263027

Pulled By: mthrok

fbshipit-source-id: b3e48dba21fc5c9813f07e624a93f38a68956c6e",moto,855818+mthrok@users.noreply.github.com,"['docs/source/prototype.pipelines.rst', 'torchaudio/prototype/pipelines/rnnt_pipeline.py']",False,21,3,2023
3bd769f8b4c62a9c3ce7fd0d57acd8809bb2c85e,"Default to float64 for cumsum in oscillator_bank (#3083)

Summary:
oscillator_bank perform cumsum on large number of elements and typically, float32 is not good enough.

This PR makes the cumsum operation default to float64, so that the result is better.

Pull Request resolved: https://github.com/pytorch/audio/pull/3083

Reviewed By: nateanl

Differential Revision: D44257182

Pulled By: mthrok

fbshipit-source-id: a38a465d33559a415e8c744e61292f4fab64b0e1",moto,855818+mthrok@users.noreply.github.com,['torchaudio/prototype/functional/_dsp.py'],False,21,3,2023
28192ff42b7cab04855befbc4153c861ef62cdc3,"Fix style issue in io module (#3190)

Summary:
Fixes the issue
https://app.circleci.com/pipelines/github/pytorch/audio/15501/workflows/ebaa2c87-efc3-44a8-b86d-5a3b99870588/jobs/1164478

Pull Request resolved: https://github.com/pytorch/audio/pull/3190

Reviewed By: nateanl

Differential Revision: D44263564

Pulled By: mthrok

fbshipit-source-id: e610be3a91888c859ebdc31081b2d1ba9d61737e",moto,855818+mthrok@users.noreply.github.com,['torchaudio/io/_stream_reader.py'],False,21,3,2023
9640757f11db2afec7a021b09db55a1326a811b9,"Use keyword arguments for librosa.filters.mel in HiFiGAN unit test (#3185)

Summary:
In librosa 0.10 release, positional arguments are deprecated (see https://github.com/librosa/librosa/pull/1521 for details). The PR fixes the HiFiGAN unit test by using keyword arguments for `librosa.filters.mel` function.

Pull Request resolved: https://github.com/pytorch/audio/pull/3185

Reviewed By: mthrok

Differential Revision: D44218852

Pulled By: nateanl

fbshipit-source-id: 6171f7bec6a2144917697c1d640e701d95ec60d7",Zhaoheng Ni,zni@meta.com,"['.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh', '.github/workflows/unittest-linux-gpu.yml', 'docs/requirements-tutorials.txt', 'test/torchaudio_unittest/prototype/hifi_gan/original/meldataset.py']",False,21,3,2023
f6e3d070040f1a2f7c204b510a6ef9425bd4d36e,"Refactor the internal of StreamReader (#3188)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3188

Refactor the process after decoding in StreamRader.

The post-decode process consists of three parts,
1. preprocessing using FilterGraph
2. conversion to Tensor
3. store in Buffer

The FilterGraph class is a thin wrapper around AVFilterGraph
structure from FFmpeg and it is agnostic to media type. However
Tensor conversion and buffering consists of bunch of different
logics.

Currently, conversion process is abstracted away with
template, i.e. `template<typename Conversion> Buffer`, and the whole
process is implemeted in Sink class which consists of `FilterGraph`
and `Buffer` which internally contains Conversion logic, even
though conversion logic and buffer have nothing in common and beter
logically separated.

The new implementation replaces `Sink` class with `IPostDecodeProcess`
interface, which contains the three components.
The different post process is implemented as a template argument of the
actual implementation, i.e.

```c++
template<typename Converter, typename Buffer>
ProcessImpl : IPostDecodeProcess
```

and stored as `unique_ptr<IPostDecodeProcess>` on `StreamProcessor`.
([functionoid pattern](https://isocpp.org/wiki/faq/pointers-to-members#functionoids), which allows to eliminate all the branching based on the media format.)

Note:
This implementation was not possible at the initial version of
StreamReader, as there was no way of knowing the media attributes coming out
of `AVFilterGraph`. https://github.com/pytorch/audio/pull/3155 and https://github.com/pytorch/audio/pull/3183
added features to parse it properly, so we can finally make the post processing strongly-typed.

Reviewed By: hwangjeff

Differential Revision: D44242647

fbshipit-source-id: 96b8c6c72a2b8af4fa86a9b02292c65078ee265b",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/post_process.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/post_process.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h']",False,21,3,2023
c17226a0d577bac18c54e3a301b3308ea01f4501,"Refactor StreamReader internals (#3184)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3184

Tweak internals of StreamReader
1. Pass time_base to Buffer class so that
    * no need to pass frame_duration separately
    * Conversion of PTS to double type can be delayed until when it's popped
2. Merge `get_output_timebase` method into `get_output_stream_info`.
3. If filter description is not provided, fill in null filter at top-level StreamReader
4. Expose filer and filter description from Sink class to get rid of wrapper get methods.

Reviewed By: nateanl

Differential Revision: D44207976

fbshipit-source-id: f25ac9be69c9897e9dcec0c6e978f29b83b166e8",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h']",False,20,3,2023
9533d30079a3e2cc74438562dd782471490609ce,"Fix GPU memory leak on StreamReader (#3186)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3186

Fix the GPU memory leak introduced in https://github.com/pytorch/audio/pull/3183

The HW frames context is owned by AVCodecContext.
The removed `av_buffer_ref` call increased the ferenrence counting unnecessarily,
and prevented AVCodecContext from feeing the resource.

(Note: this ignores all push blocking failures!)

Reviewed By: nateanl

Differential Revision: D44231876

fbshipit-source-id: 9be2c33049dd02a3fa82a85271de7fb62e5b09ea",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp'],False,20,3,2023
c5b965589e187b75d7fc51fa544c27111b201244,"Support CUDA frame in FilterGraph (#3183)

Summary:
This commit adds CUDA frame support to FilterGraph

It initializes and attaches CUDA frames context to FilterGraph,
so that CUDA frames can be processed in FilterGraph.

As a result, it enables
1. CUDA filter support such as `scale_cuda`
2. Properly retrieve the pixel format coming out of FilterGraph when
   CUDA HW acceleration is enabled. (currently it is reported as ""cuda"")

Resolves https://github.com/pytorch/audio/issues/3159

Pull Request resolved: https://github.com/pytorch/audio/pull/3183

Reviewed By: hwangjeff

Differential Revision: D44183722

Pulled By: mthrok

fbshipit-source-id: 522d21039c361ddfaa87fa89cf49c19d210ac62f",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.github/workflows/unittest-linux-gpu.yml', 'test/torchaudio_unittest/assets/testsrc.hevc', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp']",False,20,3,2023
0c8c138c89960e6105d7b61677a9799ad9924904,"Cache HW device context (#3178)

Summary:
TODO: add cache release

Pull Request resolved: https://github.com/pytorch/audio/pull/3178

Reviewed By: hwangjeff

Differential Revision: D44136275

Pulled By: mthrok

fbshipit-source-id: 4eaf646fe17a469e8bbbdf43441d5532f9f8461d",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/hw_context.cpp', 'torchaudio/csrc/ffmpeg/hw_context.h', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/utils/ffmpeg_utils.py']",False,17,3,2023
59f067b78838ef49b8b8399496b2a745ad9b2b92,"Bump version to 2.1 (#3181)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3181

Reviewed By: nateanl

Differential Revision: D44167788

Pulled By: mthrok

fbshipit-source-id: 375293df836456adc40020d323efbc0aebc60d83",moto,855818+mthrok@users.noreply.github.com,['version.txt'],True,17,3,2023
b2e07b58d4dd8028aa9bdc2207a4a624139044cf,"Update compatibility matrix (#3182)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3182

Reviewed By: nateanl

Differential Revision: D44167810

Pulled By: mthrok

fbshipit-source-id: 6ecbae54224ef7ba32835e4006aa5f2dc16b9acb",moto,855818+mthrok@users.noreply.github.com,['docs/source/installation.rst'],False,17,3,2023
9bb3507014059bddea1fa6a53cebaedd96824cf1,"Add EncodingConfig (#3179)

Summary:
Adds config object `EncodingConfig` and modifies `StreamWriter` to allow for passing in additional encoder configuration parameters, e.g. bit rate and compression level.

Pull Request resolved: https://github.com/pytorch/audio/pull/3179

Pull Request resolved: https://github.com/pytorch/audio/pull/3164

Reviewed By: mthrok

Differential Revision: D43861413

Pulled By: hwangjeff

fbshipit-source-id: c1682cb2f6e682ab6f1a506511d2be7c7b254161",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/io_class.rst', 'test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/types.h', 'torchaudio/io/_stream_writer.py']",False,17,3,2023
a6b34a5d9765b3e3111e4f22e734f815c1ab174e,"Fix initialization of `get_trellis`. (#3172)

Summary:
Fix https://github.com/pytorch/audio/issues/3166. In `get_trellis` method, the index of blank symbol is regarded as 0 by default. It should be changed to `blank_id`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3172

Reviewed By: mthrok

Differential Revision: D44090889

Pulled By: nateanl

fbshipit-source-id: d119f4ded895d31aeefd59f8d975224870100264",jiyuntu-eero,jiyuntu@eero.com,['examples/tutorials/forced_alignment_tutorial.py'],False,16,3,2023
014d7140b6482be0d069b825a94bb35ffc5e400f,"Refactor Tensor conversion in StreamReader (#3170)

Summary:
Currently, when the Buffer converts AVFrame* to torch::Tensor,
it checks the format at each time a frame is passed, and
perform the conversion.

This commit changes it so that the conversion operation is
pre-instantiated at the time outside stream is configured.

It introduces Converter implementations for various formats,
and use template to embed them in Buffer class.
This way, branching like if/switch are eliminated from
decoding path.

Pull Request resolved: https://github.com/pytorch/audio/pull/3170

Reviewed By: xiaohui-zhang

Differential Revision: D44048293

Pulled By: mthrok

fbshipit-source-id: 30d8b240a5695d7513f499ce17853f2f0ffcab9f",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/conversion.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp']",False,16,3,2023
92f2ea89ac4fed31f804bc6a22cd9ae55e6f620e,"Enhance UX on TorchAudio pages to improve awareness of doc versioning (#3167)

Summary:
- Boldface the version-selection UX and increase size by three percent.
- Add text to breadcrumbs to indicate version and stability.
- New `breadcrumbs.html` in `_templates` overrides Sphinx version.

I create a new variable in `conf.py`, **version_stable**, which has the version number for the most-recent stable release. I define this variable in the **html_context** dictionary so that it is visible to the templates.

I use this approach because I was not able to find any other way of discerning the current stable release during the build. Note that the `versions.html` file--which identifies the current stable release--appears to be available only in the **gh-pages** branch and so it is not available at build time.

However, this means that someone will need to update `conf.py` whenever the current stable release changes.

Pull Request resolved: https://github.com/pytorch/audio/pull/3167

Reviewed By: mthrok

Differential Revision: D44112224

Pulled By: carljparker

fbshipit-source-id: e76f5cb6734a784d161342964459577aa9b64cac",Carl Parker,carljparker@fb.com,"['docs/source/_templates/breadcrumbs.html', 'docs/source/_templates/layout.html', 'docs/source/conf.py']",False,15,3,2023
ee0b97f24e89ae99af5c69a6fae4c4750aede3c0,"Fix MFCC autograd test (#3169)

Summary:
Autograd test randomly fails for MFCC transform. Fix it by increasing `nondet_tol` to `1e-10`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3169

Reviewed By: xiaohui-zhang, mthrok

Differential Revision: D44069673

Pulled By: nateanl

fbshipit-source-id: addafefe381104e778b09bfbaafb322df1d9054c",Zhaoheng Ni,zni@meta.com,['test/torchaudio_unittest/transforms/autograd_test_impl.py'],False,15,3,2023
6a8ed4a252e653ddd52bd31b3eb53edc1273ce40,"Add documentation introducing I/O backend revision (#3147)

Summary:
Adds documentation that introduces forthcoming I/O backend revision and provides enablement directions for the current release.

Doc pages:
https://output.circle-artifacts.com/output/job/9c0e5a49-eaf4-404c-b910-ca1b18bb289b/artifacts/0/docs/torchaudio.html

Pull Request resolved: https://github.com/pytorch/audio/pull/3147

Reviewed By: mthrok

Differential Revision: D43824019

Pulled By: hwangjeff

fbshipit-source-id: ad21d60c7e8f69f64859c56a8ca75735ddc22e40",hwangjeff,jeffhwang@meta.com,"['docs/Makefile', 'docs/post_process_dispatcher.py', 'docs/source/backend.rst', 'docs/source/torchaudio.rst', 'torchaudio/_backend/__init__.py', 'torchaudio/_backend/utils.py']",False,14,3,2023
10aec5bd50a5ce0792adf5848de4a268319dd3ba,"Update compatibility matrix (#3168)

Summary:
Add `2.0.0` release to the compatibility matrix

Pull Request resolved: https://github.com/pytorch/audio/pull/3168

Reviewed By: mthrok

Differential Revision: D44059197

Pulled By: nateanl

fbshipit-source-id: a2830d059be90eddeab72b30e85cdfc393369bf8",Zhaoheng Ni,zni@meta.com,['docs/source/installation.rst'],False,14,3,2023
a8f4e97bd5356a7a77510cdf6a3a62e25a5dc602,"Refactor StreamReader - let StreamProcessor own codec context (#3157)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3157

AVCodecContext plays central role in decoding and encoding.
Currently in StreamReader, the object is owned inside of Decoder class
and it's not accessible from other objects.

This commit move the ownership of AVCodecContext out of Decoder to
StreamProcessor class so that other components can check access its field.

Also, the Decoder class, which is super thin wrapper around AVCodecContext
object, is now absorbed to StreamProcessor class.

Reviewed By: xiaohui-zhang

Differential Revision: D43924664

fbshipit-source-id: e53254955d9ce16871e393bcd8bb2794ce6a51ff",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h']",False,9,3,2023
430dd17cc432234ba8a598f5ed10a2e263cc3b0b,"Remove private helper methods from StreamReader (#3156)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3156

Remove helper methods that are not worthy of being private method

Reviewed By: xiaohui-zhang

Differential Revision: D43919385

fbshipit-source-id: 2ce4efaf5ec9418076e78c7ce1f842e0dd7e3028",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h']",False,9,3,2023
85cb37e262a6d204f117d945fdeacac148af1bfc,"Fix documentation of functional and transforms (#3134)

Summary:
Address #3101. The documentation for `power=1` should represent magnitude instead of energy.

Pull Request resolved: https://github.com/pytorch/audio/pull/3134

Reviewed By: mthrok

Differential Revision: D43910652

Pulled By: nateanl

fbshipit-source-id: e0768438e819222a5dde6b86c5123ab0e8af59fb",cai525,65025996+cai525@users.noreply.github.com,"['torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,8,3,2023
146195d8367d346745e5f92eb9a4035486a38a84,"Include format information after filter (#3155)

Summary:
This commit adds fields to OutputStream, which shows the result
of fitlers, such as width and height after filtering.

Before

```
OutputStream(
    source_index=0,
    filter_description='fps=3,scale=width=320:height=320,format=pix_fmts=gray')
```

After

```
OutputVideoStream(
    source_index=0,
    filter_description='fps=3,scale=width=320:height=320,format=pix_fmts=gray',
    media_type='video',
    format='gray',
    width=320,
    height=320,
    frame_rate=3.0)
```

Pull Request resolved: https://github.com/pytorch/audio/pull/3155

Reviewed By: nateanl

Differential Revision: D43882399

Pulled By: mthrok

fbshipit-source-id: 620676b1a06f293fdd56de8203a11120f228fa2d",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/io_class.rst', 'test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/io/_stream_reader.py']",False,8,3,2023
8d2f6f8d2a63a84366f6c17c837d0e034d26a443,"Support overwriting PTS in StreamWriter (#3135)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3135

Reviewed By: xiaohui-zhang

Differential Revision: D43724273

Pulled By: mthrok

fbshipit-source-id: 9b52823618948945a26e57d5b3deccbf5f9268c1",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/io/_stream_writer.py']",False,8,3,2023
3212a25785080883869363a7fe6c1ad99ec72e13,"Resolve the usage of deprecated method (#3149)

Summary:
FFmpeg 5 introduced a new API for channel configuration and channel_layout is deprecated.

This commit fixes one of the deprecated messages.

Pull Request resolved: https://github.com/pytorch/audio/pull/3149

Reviewed By: nateanl

Differential Revision: D43874808

Pulled By: mthrok

fbshipit-source-id: 3e76e8c8f1f34758b1014a426e77260e663b18ee",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/filter_graph.cpp'],False,7,3,2023
1923be04f98e3721c1621f25ff9c604285acae1c,"Use deterministic algorithms for filtfilt autograd tests (#3150)

Summary:
`filtfilt` function uses `lfilter`, which calls `conv_1d` operation internally. `conv_1d` is expected to have autograd test failures (see https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html). The PR uses deterministic algorithms in the autograd tests to make `filtfilt` related tests pass.

Pull Request resolved: https://github.com/pytorch/audio/pull/3150

Reviewed By: mthrok

Differential Revision: D43872977

Pulled By: nateanl

fbshipit-source-id: c3d6ec281f34db8a7092526ccb245797bf2338da",Zhaoheng Ni,zni@meta.com,"['test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/autograd_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py']",False,7,3,2023
67a49f3c86e4f68848a389d45c797e31c540ac26,"Fix LFCC autograd test (#3154)

Summary:
Autograd test randomly failed on gpu linux machine. Increase `nondet_tol` to make it pass.

Pull Request resolved: https://github.com/pytorch/audio/pull/3154

Reviewed By: mthrok

Differential Revision: D43873028

Pulled By: nateanl

fbshipit-source-id: a6668c47967a085e5eafb00e2dd4e61b2b46412e",Zhaoheng Ni,zni@meta.com,['test/torchaudio_unittest/transforms/autograd_test_impl.py'],False,7,3,2023
502d5811505c806f95b92ae777388e9e6d3532fd,"Raise an error is StreamWriter is not opened (#3152)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3152

In StreamWriter, if the destination is not opened when attempting to write data, it causes segmentation fault.
This commit adds guard so that instead of segfault, it will error-out.

Reviewed By: nateanl

Differential Revision: D43852649

fbshipit-source-id: aef5db7c1508f8a7db5834c2ab6de3cad09f9d60",Moto Hira,moto@meta.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,7,3,2023
cea12eaf988cb4f14b88f057e87a5b1fcfe4c28c,"Fix Adam and AdamW initializers in wav2letter example (#3145)

Summary:
In wav2letter example there is passed `momentum` to `Adam` and `AdamW` initializer, which is not a correct parameter. To fix that we need to add `beta_1` and `beta_2` to arguments and replace `momentum` with them. I also added `eps` similar to `Adadelta` initializer.

Pull Request resolved: https://github.com/pytorch/audio/pull/3145

Reviewed By: mthrok

Differential Revision: D43847713

Pulled By: nateanl

fbshipit-source-id: 94f7c48232fabf520cfce81471694cb545d160c6",Maciej Torhan,maciek97x@gmail.com,['examples/pipeline_wav2letter/main.py'],False,7,3,2023
8a9ab2a4fd116f3c97d864e2d0638e5f0be57cf6,"Refactor encoding process (#3146)

Summary:
After the series of simplification, audio/video encoding processes
can be merged, and it allows the gets rid of the boilerplate code.

Pull Request resolved: https://github.com/pytorch/audio/pull/3146

(Note: this ignores all push blocking failures!)

Reviewed By: xiaohui-zhang

Differential Revision: D43815640

fbshipit-source-id: 2a14e372b2cc75db7eeabc27d855a24c3f7d5063",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/stream_writer/audio_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encode_process.h', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/tensor_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/tensor_converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",False,6,3,2023
b96a7ebb120b6347d6181995dac19613fb534130,"Fix linux gpu tests (#3144)

Summary:
Environment variable `TORCHAUDIO_TEST_ALLOW_SKIP_IF_NO_MACOS ` needs to be added when running the bash script

Pull Request resolved: https://github.com/pytorch/audio/pull/3144

Reviewed By: mthrok

Differential Revision: D43807178

Pulled By: nateanl

fbshipit-source-id: 27c57d2efaed5519a12aa027967968895f357c67",Zhaoheng Ni,zni@meta.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,4,3,2023
db4898f3a3b622c445d188cd02b4cbb23c78bef5,"Refactor audio conversion (#3143)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3143

Similar to https://github.com/pytorch/audio/pull/3140,
only provide objects which are semantically related to the
operation performed by AudioConverter.

Reviewed By: xiaohui-zhang

Differential Revision: D43781012

fbshipit-source-id: 4795e20f56272af5cfda8a5f46083e60d1890c3e",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/audio_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.h']",False,4,3,2023
26acdbff7047cb1fc272121702947d9ed922d15c,"Simplify HW encoder object handling (#3138)

Summary:
hw_device_ctx and hw_frame_ctx assigned to an AVCodecContext
object are owned by libavformat, and get freed in [av_codec_free](https://ffmpeg.org/doxygen/4.1/group__lavc__core.html#gaf869d0829ed607cec3a4a02a1c7026b3)
(actually in [avcodec_close](https://ffmpeg.org/doxygen/4.1/libavcodec_2utils_8c_source.html#l01069)),
so we do not need to keep the reference around.

Pull Request resolved: https://github.com/pytorch/audio/pull/3138

Reviewed By: nateanl

Differential Revision: D43738009

Pulled By: mthrok

fbshipit-source-id: 8c1f4217fa7b21dce872d12be9245056f3fc7537",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",False,3,3,2023
41e3b93db0f2a9e226e7b7bd1cf7475fdeb4b058,"Fix HW accelerated encoder (#3140)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3140

https://github.com/pytorch/audio/pull/3120 introduced regression in GPU encoder.

This happened because previously source AVPixelFormat (expected channel order of
input tensor) and AVCodecContext (encoding format) in converter (module to copy
input tensor to buffer), even though converter does not need to konw about the
encoding format.

This commit fixes the issue and make sure that converter does not recieve
codec context.

Reviewed By: nateanl

Differential Revision: D43759162

fbshipit-source-id: f5f191cb54ecc82bd882aececdcae16921250261",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/video_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",False,3,3,2023
d359f8875fb0444ef315d985820d232430ac6421,"Skip playback tests on linux gpu machine (#3141)

Summary:
`playback` function was added in https://github.com/pytorch/audio/issues/3026, the function only supports MacOS, hence the tests should be skipped on other OS. The PR skips the tests on linux gpu machines on Circle CI.

Pull Request resolved: https://github.com/pytorch/audio/pull/3141

Reviewed By: xiaohui-zhang, mthrok

Differential Revision: D43760546

Pulled By: nateanl

fbshipit-source-id: 606907127feee28a66f61baca000a8ef708f8086",Zhaoheng Ni,zni@meta.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,3,3,2023
5fac7173ea18cbe54c519663ff368e2bab182a37,"Fix build (#3136)

Summary:
Follow-up https://github.com/pytorch/audio/issues/3130

Pull Request resolved: https://github.com/pytorch/audio/pull/3136

Reviewed By: hwangjeff

Differential Revision: D43732991

Pulled By: mthrok

fbshipit-source-id: 2e8cb56d96e22546645c82eca362b3c4dcf9c78f",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/CMakeLists.txt'],False,2,3,2023
1ed380953f733fc7973616a06e9576ad79fe6fb8,"Fix doc build (#3125)

Summary:
Fix build_doc job

https://app.circleci.com/pipelines/github/pytorch/audio/15217/workflows/ce50b317-a59e-4741-b8d2-59129420deb8

- build.ffmpeg.html might not exist when IPython notebook is processed. Changing to main doc URL.
- Fix bash cell syntax in HW tutorial
- Fix C++ doc
- Fix duplicated target name in streamwriter tutorial

Pull Request resolved: https://github.com/pytorch/audio/pull/3125

Reviewed By: xiaohui-zhang

Differential Revision: D43724078

Pulled By: mthrok

fbshipit-source-id: ea7d46ec5e377cf2fbd7c3798df57da73750ac5c",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'docs/source/hw_acceleration_tutorial.ipynb', 'docs/source/libtorchaudio.stream_reader.rst', 'examples/tutorials/streamwriter_advanced.py']",False,2,3,2023
9133f2a019d5f2fe0ea3bfe30926a6c396e93c6e,"Extract audio conversion into separate class (#3130)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3130

Similar to https://github.com/pytorch/audio/pull/3120
Adopt the generator style slicing conversion to audio encoding
process.

Reviewed By: nateanl

Differential Revision: D43685380

fbshipit-source-id: 3e95655783e5c5d768486f8af6e6b47b0072999b",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/audio_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.h']",False,2,3,2023
fbf05f2857313980e6e51d07bdd2f63a7ead7f77,"Fix PTS regression (#3131)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3131

In https://github.com/pytorch/audio/pull/3122, the intermediate `num_frames` variable
is removed.

PTS can be incremented the same way, but the timing was wrong in #3122.
This commit fixes it.

Reviewed By: xiaohui-zhang

Differential Revision: D43712046

fbshipit-source-id: 2fe0082969296f4f3964e62e55b5325fcd45f4f9",Moto Hira,moto@meta.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp']",False,2,3,2023
898db8c7ef7b81d3c77ee214f55cdad4a84dc951,"Update slicing conversion code (#3129)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3129

- Add step parameter to support audio slicing
- Rename to `SlicingTensorConverter` (`Generator` is too generic.)

Reviewed By: xiaohui-zhang

Differential Revision: D43704926

fbshipit-source-id: c4bf0ff766e0ae1b5d46b159a6367492ef68f9cd",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.h']",False,2,3,2023
b0faecb2e7660ade38b43e4eb1b5afeaf2c451b2,"Fix stylecheck in io (#3126)

Summary:
`Dict` is not used. Fix styecheck by removing the import of `Dict`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3126

Reviewed By: mthrok

Differential Revision: D43699410

Pulled By: nateanl

fbshipit-source-id: 8d6b5335124903453387c488f96f297d6fe3c819",Zhaoheng Ni,zni@meta.com,['torchaudio/io/_compat.py'],False,1,3,2023
fce6180cdadcc66c0cffd5313d0d8662992ef1f1,"Tweak OutputStream implementation (#3122)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3122

- Remove manual tracking of num_frames
- Remove unnecessary dispatch in AudioOutputStream

Reviewed By: nateanl

Differential Revision: D43685746

fbshipit-source-id: a7e62a81549fb62ad0caa3b741655eba3bc5e250",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp']",False,1,3,2023
0bf00d206018c1e75cbcdd29a7bc4a98b5666d69,"Extract image conversions into separate class (#3120)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3120

This commits extract image conversion ops into ImageTensorConverter class, and make it independent from OutputStream class.

ImageTensorConverter class implementes range-based for-loop interface, like

```
for (auto const& frame : ImageTensorConverter::convert(...)) {
    post_process_with_avframe(frame);
}
```

This allows to decouple encoder from image conversion.

Reviewed By: nateanl

Differential Revision: D43666296

fbshipit-source-id: 754efe677bc7695b3f138a6d076be2106e186b79",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_writer/converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_converter.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",True,1,3,2023
c9c8c7e17e7c13ca3785e5f40116845fdc3ed3d0,"Move I/O logging to C++ (#3123)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3123

Moving the I/O usage logging to C++, so that C++ usages are also covered.

Reviewed By: nateanl

Differential Revision: D43686567

fbshipit-source-id: ad357028dd69eedb8bc2a2482fe07e95757a3a62",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py']",False,1,3,2023
6a4a82008560f00225096b004371db4b19dc991a,"Fix windows tests (#3119)

Summary:
`sox` is not available on Windows machines. Add skip decorators to the sox related tests to skip running tests on Windows.

Pull Request resolved: https://github.com/pytorch/audio/pull/3119

Reviewed By: mthrok

Differential Revision: D43682754

Pulled By: nateanl

fbshipit-source-id: f69987dac8232a3569be83f096b32389bd8bda81",Zhaoheng Ni,zni@meta.com,"['test/torchaudio_unittest/backend/dispatcher/ffmpeg/info_test.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/load_test.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/save_test.py']",False,1,3,2023
af493e4eb2f3bb15835337025b18baccbcd6ffa4,"Remove redundant device arg from VideoOutputStream constructor (#3121)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3121

After careful review, it turned out device arg in VideoOutputStream
constructor and related helper functions can be replaced with
AVCodecContext::pix_fmt == AV_PIX_FMT_CUDA.

Reviewed By: xiaohui-zhang

Differential Revision: D43677801

fbshipit-source-id: f8f34f1aed46e223b44250d39cccc4cd26ecb458",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",False,1,3,2023
2381beecee76013a069902007d182367442cbe26,"Decouple image conversion and OutputStream class (#3113)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3113

Decouple the Tensor to AVFrame conversion process from encoding process.

Reviewed By: nateanl

Differential Revision: D43628942

fbshipit-source-id: e698f3150292567dbc23e7d6795ad58265f24780",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp'],False,28,2,2023
fd24af003cd4bfcfaee9acfd2245ede4985c54b4,"Use null filter in case no filter is used (#3109)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3109

Change the logic around StreamWriter preprocessing.
Currently, no preprocessing is expressed as `nullptr` to `unique_ptr<FilterGraph>`.

This commit changes it to `[a]null` filter, which is just a pass through.
This makes a code a bit simpler, and serves better preparation for adding
filters for CUDA process.

Reviewed By: xiaohui-zhang

Differential Revision: D43593321

fbshipit-source-id: 9ca71c2c8bf652384a0f56b4c41b32d908f61201",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp']",False,28,2,2023
be3bd1acc565e4c34b8e5cd12dff87743d1fe075,"Reduce code duplication in VideoOutputStream (#3108)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3108

- Introduce process_frame method
- De-dupe validation logic

Reviewed By: xiaohui-zhang

Differential Revision: D43632390

fbshipit-source-id: 76b7ca0beb725acf686269c877a62e1256921b28",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",False,28,2,2023
46fae2fe9ecd23039d9402cfaf2864a2c4312ad6,"Add SquimObjectiveBundle to prototype (#3103)

Summary:
Add pre-trained pipeline support for `SquimObjective` model. The pre-trained model is trained on DNS 2020 challenge dataset.

Pull Request resolved: https://github.com/pytorch/audio/pull/3103

Reviewed By: xiaohui-zhang, mthrok

Differential Revision: D43611794

Pulled By: nateanl

fbshipit-source-id: 0ac76a27e7027a43ffccb158385ddb2409b8526d",Zhaoheng Ni,zni@meta.com,"['README.md', 'docs/source/prototype.pipelines.rst', 'docs/source/refs.bib', 'test/integration_tests/prototype/squim_pipeline_test.py', 'test/torchaudio_unittest/prototype/squim_test.py', 'torchaudio/prototype/models/squim/objective.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/squim_pipeline.py']",False,27,2,2023
bc61f10948c019c33356270557d08d9fdfa8b5a2,"Move OutputStream init logic and simplify interface (#3105)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3105

Refactor the construction of Audio/VideoOutputStream

Reviewed By: nateanl

Differential Revision: D43613013

fbshipit-source-id: 0e112cb1bab2658be68a368099ed00ef318ea4f1",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",False,27,2,2023
5b0580ae9d1411d8a7f8c6b024c2fd33bbd2fa67,"Split Audio/VideoOutputStream source (#3106)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3106

Refactor Audio/VideoOutputStream.

Reviewed By: nateanl

Differential Revision: D43613008

fbshipit-source-id: 36c62fe00903066982573866d07de4e79b34240d",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/audio_output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/video_output_stream.h']",False,27,2,2023
5cac8de3555bf06c843af345181c2c39b2f3dc7d,"Extract Encoder from OutputStream (#3104)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3104

Continuation of StreamWriter refactoring

This commit extract Encoder (+muxer) from OutputStream

Reviewed By: nateanl

Differential Revision: D43610887

fbshipit-source-id: 30a9862b1aabd5af331ce3f33a5815df1decbad1",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_writer/encoder.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/encoder.h', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,27,2,2023
232310330e087a86423eebd61fc49cda84adc1df,"Refactor StreamWriter and extract encoding process (#3100)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3100

Refactor StreamWriter and move OutputStream to dedicated source, then
split them into separate audio/video class.

Reviewed By: nateanl

Differential Revision: D43587337

fbshipit-source-id: 0fdbd1f56a7200dc6849e95eb9678854f5d933b8",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/output_stream.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,27,2,2023
75fc9a464871d7ab7c5676b78c1254951dcf6104,"Fix unit tests for griffinlim and Spectrogram (#3099)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3099

Reviewed By: mthrok

Differential Revision: D43596866

Pulled By: nateanl

fbshipit-source-id: 43a139bf8ebdf3261414e2855aefc3b53df298ac",Zhaoheng Ni,zni@meta.com,"['test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/transforms/librosa_compatibility_test_impl.py']",False,25,2,2023
fd778091a8564478bf7906814151a12cfd76d78e,"Add Wav2Vec2DataModule in self_supervised_learning training recipe (#3081)

Summary:
Add `Wav2Vec2DataModule` in self_supervised_learning training recipe to support Wav2Vec2 pre-training.

Pull Request resolved: https://github.com/pytorch/audio/pull/3081

Reviewed By: mthrok

Differential Revision: D43579239

Pulled By: nateanl

fbshipit-source-id: 3e935eb9a18ef0259a58940ae466cbdc3baf8494",Vladislav Agafonov,vladagafonov@meta.com,"['examples/self_supervised_learning/data_modules/__init__.py', 'examples/self_supervised_learning/data_modules/_utils.py', 'examples/self_supervised_learning/data_modules/_wav2vec2_datamodule.py']",False,24,2,2023
c532f35cf087591ab0b0eccf28ec4b55ae0972d7,"Add wav2vec2 loss function in self_supervised_learning training recipe (#3090)

Summary:
Add wav2vec2 loss function in the self_supervised_learning training recipe to support Wav2Vec2 pre-training.

Pull Request resolved: https://github.com/pytorch/audio/pull/3090

Reviewed By: mthrok

Differential Revision: D43579220

Pulled By: nateanl

fbshipit-source-id: 4b52792b518ddc5b01c9660c90ceb3c4ad1f0237",Vladislav Agafonov,vladagafonov@meta.com,"['examples/self_supervised_learning/losses/__init__.py', 'examples/self_supervised_learning/losses/_wav2vec2_loss.py']",False,24,2,2023
b46628bac950e306fd4007511ff966970b0ddec1,"Cleanup ffmpeg bidings (#3095)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3095

Reviewed By: nateanl

Differential Revision: D43544998

Pulled By: mthrok

fbshipit-source-id: 4359cdbbdbee53084016a84129cb3d65900b0457",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/binding_utils.cpp', 'torchaudio/csrc/ffmpeg/binding_utils.h', 'torchaudio/csrc/ffmpeg/compat.cpp', 'torchaudio/csrc/ffmpeg/pybind/fileobj.cpp', 'torchaudio/csrc/ffmpeg/pybind/fileobj.h', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/utils.cpp', 'torchaudio/io/_compat.py']",False,24,2,2023
b012b452c8efc26e9c2974a663d12232fa9b8f48,"Bind StreamReader/Writer with PyBind11 (#3091)

Summary:
This commit is kind of clean up and preparation for future
development.

We plan to pass around more complicated objects among
StreamReader and StreamWriter, and TorchBind is not expressive enough
for defining intermediate object, so we use PyBind11 for binding
StreamWriter.

Pull Request resolved: https://github.com/pytorch/audio/pull/3091

Reviewed By: xiaohui-zhang

Differential Revision: D43515714

Pulled By: mthrok

fbshipit-source-id: 9097bb104bbf8c1536a5fab6f87447c08b10a7f2",moto,855818+mthrok@users.noreply.github.com,"['docs/source/libtorchaudio.stream_reader.rst', 'torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_binding.cpp', 'torchaudio/io/_compat.py', 'torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py']",False,24,2,2023
f6d1bc96b61c22987ca9b2969339fe61976f77e8,"Use autosummary for torchaudio.prototyoe.models documentation (#3084)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3084

Reviewed By: mthrok

Differential Revision: D43550150

Pulled By: nateanl

fbshipit-source-id: 5c5e3d9461e375be202493e3399ff38ce5cd7690",Zhaoheng Ni,zni@meta.com,"['docs/source/_templates/autosummary/model_class.rst', 'docs/source/_templates/autosummary/prototype_model_class.rst', 'docs/source/prototype.models.rst']",False,24,2,2023
c3310018fc936327e718b1341f6898bc1e08c6c2,"Replace c10::Dict with std::map in StreamReader/Writer (#3092)

Summary:
This commit is kind of clean up and preparation for future development.

We plan to pass around more complicated objects among StreamReader and StreamWriter, and TorchBind is not expressive enough for defining intermediate object, so we want to use PyBind11 for binding StreamReader/Writer.

PyBind11 converts Python dict into std::map, while TorchBind converts it into c10::Dict. Because of this descrepancy, conversion from c10::Dict to std::map have to happen in multiple places, and this makes the binding code thicker as it requires to wrapper methods.

Using std::map reduces the number of wrapper methods / conversions, because the same method can be bound for file-like object and the others.

Pull Request resolved: https://github.com/pytorch/audio/pull/3092

Reviewed By: nateanl

Differential Revision: D43524808

Pulled By: mthrok

fbshipit-source-id: f7467c66ccd37dbf4abc337bbb18ffaac21a0058",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/binding_utils.cpp', 'torchaudio/csrc/ffmpeg/binding_utils.h', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.h', 'torchaudio/csrc/ffmpeg/pybind/typedefs.cpp', 'torchaudio/csrc/ffmpeg/pybind/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_binding.cpp']",False,23,2,2023
1ed330b51f16f11c55524757da696a7d0e815c3a,"Add TCPGen context-biasing Conformer RNN-T (#2890)

Summary:
This commit adds the implementation of the tree-constrained pointer generator (TCPGen) for contextual biasing.

An example for Librispeech can be found in audio/examples/asr/librispeech_biasing.

Maintainer's note (mthrok):
It seems that TrieNode should be better typed as tuple, but changing the implementation from list to tuple
could cause some issue without running the code, so the code is not changed, though the annotation uses tuple.

Pull Request resolved: https://github.com/pytorch/audio/pull/2890

Reviewed By: nateanl

Differential Revision: D43171447

Pulled By: mthrok

fbshipit-source-id: 372bb077d997d720401dbf2dbfa131e6a958e37e",G. Sun,gs534@cam.ac.uk,"['examples/asr/librispeech_conformer_rnnt_biasing/README.md', 'examples/asr/librispeech_conformer_rnnt_biasing/blists/README.md', 'examples/asr/librispeech_conformer_rnnt_biasing/data_module.py', 'examples/asr/librispeech_conformer_rnnt_biasing/error_analysis/get_error_word_count.py', 'examples/asr/librispeech_conformer_rnnt_biasing/eval.py', 'examples/asr/librispeech_conformer_rnnt_biasing/global_stats_100.json', 'examples/asr/librispeech_conformer_rnnt_biasing/lightning.py', 'examples/asr/librispeech_conformer_rnnt_biasing/score.sh', 'examples/asr/librispeech_conformer_rnnt_biasing/train.py', 'examples/asr/librispeech_conformer_rnnt_biasing/train_spm.py', 'examples/asr/librispeech_conformer_rnnt_biasing/transforms.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/librispeech_biasing.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/rnnt.py', 'torchaudio/prototype/models/rnnt_decoder.py']",False,23,2,2023
d3c9295cfc0d1033955665a30b3a64a5aa73b280,"Remove Tensor binding from StreamReader (#3093)

Summary:
Remove the Tensor input support from StreamReader

Follow up of https://github.com/pytorch/audio/pull/3086

Pull Request resolved: https://github.com/pytorch/audio/pull/3093

Reviewed By: xiaohui-zhang

Differential Revision: D43526066

Pulled By: mthrok

fbshipit-source-id: 57ba4866c413649173e1c2c3b23ba7de3231b7bc",mthrok,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.cpp', 'torchaudio/io/_stream_reader.py']",False,23,2,2023
a26c2f2776f36681223b4b393acdae75f8cd6edc,"Deprecate the use of Tensor as a mean of passing byte string (#3086)

Summary:
The same functionality can be achieved with passing io.BytesIO to the constructor.

Pull Request resolved: https://github.com/pytorch/audio/pull/3086

Reviewed By: nateanl

Differential Revision: D43500360

Pulled By: mthrok

fbshipit-source-id: 2c6f37d100f50553b283c75c04fe57c8f9c07dc9",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.cpp'],False,23,2,2023
3b75b74f96199a9e162d7463b324ea966a830dd1,"Update CTCDecoder static build deprecation message (#3089)

Summary:
1. Fix spacing.
2. Move it to after successful import
3. Add link to the announcement issue

Pull Request resolved: https://github.com/pytorch/audio/pull/3089

Reviewed By: nateanl, xiaohui-zhang

Differential Revision: D43514075

Pulled By: mthrok

fbshipit-source-id: 3b2a24c65c63dab8c12c9c6aa1942a8354b2c0f1",moto,855818+mthrok@users.noreply.github.com,['torchaudio/models/decoder/_ctc_decoder.py'],False,23,2,2023
b0155938b9137296e3c15313e9036b52519c2bc6,"Rename SQUIM_OBJECTIVE model to SquimObjective (#3087)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3087

Reviewed By: xiaohui-zhang, mthrok

Differential Revision: D43509865

Pulled By: nateanl

fbshipit-source-id: 569cc2ee8edd9de0b7d255a1e1075ac812b26cc8",Zhaoheng Ni,zni@meta.com,"['torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/squim/__init__.py', 'torchaudio/prototype/models/squim/objective.py']",False,22,2,2023
b35a5fcff491ce8b87e26b6fb3f6d0b14595b35f,"Fix ConformerWav2Vec2PretrainModel (#3085)

Summary:
The negative sampling should be applied to unmasked features in masked indices, the PR fixes the logic in ConformerWav2Vec2PretrainModel.

Pull Request resolved: https://github.com/pytorch/audio/pull/3085

Reviewed By: mthrok

Differential Revision: D43488570

Pulled By: nateanl

fbshipit-source-id: 3820400d50b74216bb98ca6a40dc6a7acca01564",Zhaoheng Ni,zni@meta.com,['torchaudio/prototype/models/_conformer_wav2vec2.py'],False,22,2,2023
3267c7ed38088e67dd1bdb4095689d82747b0d75,"Add objective metric estimation model for speech enhancement (#3042)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3042

Reviewed By: mthrok

Differential Revision: D43405932

Pulled By: nateanl

fbshipit-source-id: 88f6dabae35565b699230e9909b8f68f4a57f5c7",Zhaoheng Ni,zni@meta.com,"['docs/source/prototype.models.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/prototype/squim_test.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/squim/__init__.py', 'torchaudio/prototype/models/squim/objective.py']",False,22,2,2023
6ab1325a55137b3a1bba59f8e88f9410f52eeaf2,"Fix contiguous error when backpropagating through lfilter (#3080)

Summary:
I encountered the following errors when using the filter with gradients being enabled.

```sh
Traceback (most recent call last):
  File ""/home/ycy/working/audio/test_backward.py"", line 20, in <module>
    loss.backward()
  File ""/home/ycy/miniconda3/envs/nightly/lib/python3.10/site-packages/torch/_tensor.py"", line 488, in backward
    torch.autograd.backward(
  File ""/home/ycy/miniconda3/envs/nightly/lib/python3.10/site-packages/torch/autograd/__init__.py"", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Expected input_signal_windows.is_contiguous() && a_coeff_flipped.is_contiguous() && padded_output_waveform.is_contiguous() to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
```
This can happen if the outputs from lfilter was used by other operations.

### How to reproduce
The following script can reproduce the error on the stable and nightly versions.

```python
import torch
import torch.nn.functional as F
from torchaudio.functional import lfilter

a = torch.rand(250, 26, requires_grad=True)
b = torch.ones(250, 26, requires_grad=True)
x = torch.rand(250, 1024, requires_grad=True)
w = torch.eye(1024).unsqueeze(1)

y = lfilter(x, a, b, False)
y = F.conv_transpose1d(
    y.t().unsqueeze(0),
    w,
    stride=256,
).squeeze()
print(y.shape)
target = torch.ones_like(y)
loss = torch.nn.functional.mse_loss(y, target)
loss.backward()
```

### Cause

The inner call of differentiable IIR in the backward pass needs to ensure the input is contiguous. Adding a `contiguous()` call solve the problem.

Pull Request resolved: https://github.com/pytorch/audio/pull/3080

Reviewed By: xiaohui-zhang

Differential Revision: D43466612

Pulled By: mthrok

fbshipit-source-id: 375e0a147988656da47ac8397f7de6eae512a655",Chin-Yun Yu,lolimaster.cs03@nctu.edu.tw,['torchaudio/csrc/lfilter.cpp'],False,21,2,2023
5af309d319aa17cf1ce487e8daaf535b96d1fc4e,"Make lengths optional for speed functions and modules (#3072)

Summary:
Makes lengths input optional for `torchaudio.functional.speed`, `torchaudio.transforms.Speed`, and `torchaudio.transforms.SpeedPerturbation`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3072

Reviewed By: nateanl, mthrok

Differential Revision: D43371406

Pulled By: hwangjeff

fbshipit-source-id: ecb38bcc2bfff5c5a396a37eff238b22238e795a",hwangjeff,jeffhwang@meta.com,"['test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'test/torchaudio_unittest/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,17,2,2023
e663095cd23822df4d32a92bff788f0e6699f558,"Add py3.11 to windows nightly conda (#3071)

Summary:
Same as: https://github.com/pytorch/vision/pull/7263

Pull Request resolved: https://github.com/pytorch/audio/pull/3071

Reviewed By: weiwangmeta

Differential Revision: D43377741

Pulled By: atalman

fbshipit-source-id: 0dbe0aaa10b9a4bad713563e98642b1a65e9ac07",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', 'packaging/build_conda.sh', 'packaging/pkg_helpers.bash']",False,17,2,2023
06b1cc9d5fc3281a1bf97bf3cc63536c20d7823c,"Add precodition check for contiguous emissions tensor (#3074)

Summary:
This PR adds a precondition check to the `CTCDecoder` that raises a helpful exception when called on a noncontiguous emissions tensor.

Currently, noncontiguous tensors can be passed into the CTCDecoder, which in turn passes the tensors to the backing Flashlight C++ library and results in undefined behavior, since Flashlight requires the tensors to be laid out in contiguous memory. The following code demonstrates the problem:

```
import torch
from torchaudio.models.decoder import ctc_decoder

tokens = ['a', '-', '|']
decoder = ctc_decoder(lexicon=None, tokens=tokens)

emissions = torch.rand(len(tokens), 2)  # N x T contiguous
emissions = emissions.t()  # T x N noncontiguous

batch = emissions.unsqueeze(0)
result = decoder(batch)  # undefined behavior!!!
```

I stumbled on the issue accidentally when I noticed the decoder wasn't giving the expected results on my input only to realize, finally, that the tensor I had passed in was noncontiguous. In my case, Flashlight was iterating over unrelated segments of memory where it had expected to find a contiguous tensor. A precondition check will hopefully save others from making the same mistake.

Pull Request resolved: https://github.com/pytorch/audio/pull/3074

Reviewed By: nateanl, xiaohui-zhang

Differential Revision: D43376011

Pulled By: mthrok

fbshipit-source-id: 7c95aa8016d8f9f2d65b5b816a859b28ea4629f5",Daniel Walker,dwalker@ibm.com,['torchaudio/models/decoder/_ctc_decoder.py'],False,17,2,2023
85f8fc544f38ddf194f80740ac70e3572f370fc2,"Add guards to prevent ffmpeg failures during dispatcher import (#3073)

Summary:
With the introduction of the backend dispatcher, importing torchaudio fails when ffmpeg is not available. This PR adds guards to resolve these failures.

Pull Request resolved: https://github.com/pytorch/audio/pull/3073

Reviewed By: NivekT, mthrok

Differential Revision: D43372870

Pulled By: hwangjeff

fbshipit-source-id: 7f6c2795430d7aeb742c2feb97984d5273f20aac",hwangjeff,jeffhwang@meta.com,"['torchaudio/_backend/utils.py', 'torchaudio/backend/__init__.py']",False,16,2,2023
2c9b3e59bd509f86c99db173a1fa8f81c8fb9a89,"Fix DDP training in HuBERT recipes (#3068)

Summary:
The `BucketizeBatchSampler` may return different iter_list in different node if `shuffle` is `True`, which will cause DPP training hang forever.
`shuffle` in `DistributedSampler` only happens in initialization, which means it will assign the same subset to replicas in all training epochs. The PR fixes the two above issues.

cc arlofaria

Pull Request resolved: https://github.com/pytorch/audio/pull/3068

Reviewed By: mthrok

Differential Revision: D43372110

Pulled By: nateanl

fbshipit-source-id: a162728406ae995e05d2a07cfc2444fb76cf345e",Zhaoheng Ni,zni@meta.com,"['examples/hubert/dataset/hubert_dataset.py', 'examples/hubert/lightning.py', 'examples/self_supervised_learning/data_modules/_hubert_datamodule.py', 'examples/self_supervised_learning/data_modules/_utils.py', 'examples/self_supervised_learning/train_hubert.py']",False,16,2,2023
11bdafc32b77f8550aa2bb8333670ae7a9089380,"Update WER results for CTC n-gram decoding (#3070)

Summary:
In https://github.com/pytorch/audio/issues/2873, layer normalization is applied to waveforms for SSL models trained on large scale datasets. The word error rate is significantly reduced after the change. The PR updates the results for the affected models.

Without the change in https://github.com/pytorch/audio/issues/2873, here is the WER result table:
|                                                                                            Model | dev-clean | dev-other | test-clean | test-other |
|:------------------------------------------------------------------------------------------------|-----------:|-----------:|-----------:|-----------:|
| [WAV2VEC2_ASR_LARGE_LV60K_10M](https://pytorch.org/audio/main/generated/torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_10M.html#torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_10M) |        10.59|        15.62|        9.58|        16.33|
| [WAV2VEC2_ASR_LARGE_LV60K_100H](https://pytorch.org/audio/main/generated/torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_100H.html#torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_100H) |        2.80|        6.01|        2.82|        6.34|
| [WAV2VEC2_ASR_LARGE_LV60K_960H](https://pytorch.org/audio/main/generated/torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_960H.html#torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_960H) |        2.36|        4.43|        2.41|        4.96|
| [HUBERT_ASR_LARGE](https://pytorch.org/audio/main/generated/torchaudio.pipelines.HUBERT_ASR_LARGE.html#torchaudio.pipelines.HUBERT_ASR_LARGE) |        1.85|        3.46|        2.09|        3.89|
| [HUBERT_ASR_XLARGE](https://pytorch.org/audio/main/generated/torchaudio.pipelines.HUBERT_ASR_XLARGE.html#torchaudio.pipelines.HUBERT_ASR_XLARGE) |         2.21|        3.40|        2.26|        4.05|

After applying layer normalization, here is the updated result:
|                                                                                            Model | dev-clean | dev-other | test-clean | test-other |
|:------------------------------------------------------------------------------------------------|-----------:|-----------:|-----------:|-----------:|
| [WAV2VEC2_ASR_LARGE_LV60K_10M](https://pytorch.org/audio/main/generated/torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_10M.html#torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_10M) |        6.77|        10.03|        6.87|        10.51|
| [WAV2VEC2_ASR_LARGE_LV60K_100H](https://pytorch.org/audio/main/generated/torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_100H.html#torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_100H) |        2.19|        4.55|        2.32|        4.64|
| [WAV2VEC2_ASR_LARGE_LV60K_960H](https://pytorch.org/audio/main/generated/torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_960H.html#torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_960H) |        1.78|        3.51|        2.03|        3.68|
| [HUBERT_ASR_LARGE](https://pytorch.org/audio/main/generated/torchaudio.pipelines.HUBERT_ASR_LARGE.html#torchaudio.pipelines.HUBERT_ASR_LARGE) |        1.77|        3.32|        2.03|        3.68|
| [HUBERT_ASR_XLARGE](https://pytorch.org/audio/main/generated/torchaudio.pipelines.HUBERT_ASR_XLARGE.html#torchaudio.pipelines.HUBERT_ASR_XLARGE) |         1.73|        2.72|        1.90|        3.16|

Pull Request resolved: https://github.com/pytorch/audio/pull/3070

Reviewed By: mthrok

Differential Revision: D43365313

Pulled By: nateanl

fbshipit-source-id: 34a60ad2e5eb1299da64ef88ff0208ec8ec76e91",Zhaoheng Ni,zni@meta.com,['examples/asr/librispeech_ctc_decoder/README.md'],False,16,2,2023
6b2086cf6f68510901a722d6544f5a0f3d88bcf6,"Add deprecation warning to decoder (#3055)

Summary:
Flashlight Text decoder is now available on PyPI and KenLM support is being added at
https://github.com/flashlight/text/pull/43

Once this work is merged, we can rely on the official distribution of Flashlight Text package, so we are adding deprecation warning.

Once the decoder is fully available, one can install it with

```
pip install flashlight-text
pip install git+https://github.com/kpu/kenlm.git
```

Pull Request resolved: https://github.com/pytorch/audio/pull/3055

Reviewed By: hwangjeff, nateanl

Differential Revision: D43239150

Pulled By: mthrok

fbshipit-source-id: 728cb208b8403100cd4ccd80c6295d454756b414",moto,855818+mthrok@users.noreply.github.com,['torchaudio/models/decoder/_ctc_decoder.py'],False,16,2,2023
b799fcd6b691e3131d388890c926c0a58d0a82ef,"Introduce I/O backend dispatcher (#3015)

Summary:
Adds I/O backend dispatcher that routes I/O requests to FFmpeg, SoX, or Soundfile backend, per library availability. It allows users to specify a backend mapped to a media library, i.e. one of `[""ffmpeg"", ""sox"", ""soundfile""]`, to use via keyword argument, with FFmpeg being the default. Environment variable `TORCHAUDIO_USE_BACKEND_DISPATCHER` gates enablement of the dispatcher; specifically, if `TORCHAUDIO_USE_BACKEND_DISPATCHER` is explicitly set to `1`, importing TorchAudio makes it accessible via `torchaudio.info`, `torchaudio.load`, and `torchaudio.save`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3015

Reviewed By: mthrok

Differential Revision: D43258649

Pulled By: hwangjeff

fbshipit-source-id: 8f12e4e56b9fa3f0814dd3fed3e1783ab23a53a1",hwangjeff,jeffhwang@meta.com,"['test/torchaudio_unittest/backend/dispatcher/__init__.py', 'test/torchaudio_unittest/backend/dispatcher/dispatcher_test.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/__init__.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/info_test.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/load_test.py', 'test/torchaudio_unittest/backend/dispatcher/ffmpeg/save_test.py', 'test/torchaudio_unittest/backend/dispatcher/smoke_test.py', 'test/torchaudio_unittest/backend/dispatcher/soundfile/__init__.py', 'test/torchaudio_unittest/backend/dispatcher/soundfile/common.py', 'test/torchaudio_unittest/backend/dispatcher/soundfile/info_test.py', 'test/torchaudio_unittest/backend/dispatcher/soundfile/load_test.py', 'test/torchaudio_unittest/backend/dispatcher/soundfile/save_test.py', 'test/torchaudio_unittest/backend/dispatcher/sox/__init__.py', 'test/torchaudio_unittest/backend/dispatcher/sox/common.py', 'test/torchaudio_unittest/backend/dispatcher/sox/info_test.py', 'test/torchaudio_unittest/backend/dispatcher/sox/load_test.py', 'test/torchaudio_unittest/backend/dispatcher/sox/roundtrip_test.py', 'test/torchaudio_unittest/backend/dispatcher/sox/save_test.py', 'test/torchaudio_unittest/backend/dispatcher/sox/smoke_test.py', 'torchaudio/__init__.py', 'torchaudio/_backend/__init__.py', 'torchaudio/_backend/utils.py', 'torchaudio/backend/__init__.py', 'torchaudio/backend/common.py', 'torchaudio/backend/soundfile_backend.py', 'torchaudio/backend/utils.py']",False,16,2,2023
9db4bdf19884e5d488fbc0e5f4640dd736246e5d,"Implement exp sigmoid (#3056)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3056

Task #2 from https://github.com/pytorch/audio/issues/2835

Reviewed By: mthrok

Differential Revision: D42854156

fbshipit-source-id: e1b3bd992c91fedc55f30a814e16efd7c51e0c80",Cole Li,col@meta.com,"['test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/dsp_utils.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py']",False,15,2,2023
a49edea5cf9bb652da42e5841e5092f9b69141d7,"Enable broadcasting for inputs to convolve (#3061)

Summary:
Relaxes input dimension matching constraint on `convolve` to enable broadcasting for inputs.

Pull Request resolved: https://github.com/pytorch/audio/pull/3061

Reviewed By: mthrok

Differential Revision: D43298078

Pulled By: hwangjeff

fbshipit-source-id: a6cc36674754523b88390fac0a05f06562921319",hwangjeff,jeffhwang@meta.com,"['test/torchaudio_unittest/functional/functional_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,15,2,2023
fb9326740078b8e159cad8abab40cddd3b7f1308,"Add FFmpeg compat save function (#3058)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3058

Adds FFmpeg-based save function.

Reviewed By: mthrok

Differential Revision: D43264858

fbshipit-source-id: ae3f89012bc2520f3de11af65348ba8f77f0acff",Jeff Hwang,jeffhwang@meta.com,['torchaudio/io/_compat.py'],False,15,2,2023
b9ef69d134801646438f5f6b1d895c57ccb6cc8e,"Update data augmentation tutorial to use new operators (#3062)

Summary:
Updates tutorial ""Audio Data Augmentation"" to use two of the newly introduced data augmentation operators in beta: `torchaudio.functional.fftconvolve` and `torchaudio.functional.add_noise`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3062

Reviewed By: mthrok

Differential Revision: D43298120

Pulled By: hwangjeff

fbshipit-source-id: 09ca736a5c67242568515d600b7d31eab32c2df1",hwangjeff,jeffhwang@meta.com,['examples/tutorials/audio_data_augmentation_tutorial.py'],False,15,2,2023
12e8cb976c027aecb0411657f705dd2d42aa4898,"Tweak docs around IO (#3064)

Summary:
* Mention context manager in StreamWriter
* Add FFmpeg as optional dependency

Pull Request resolved: https://github.com/pytorch/audio/pull/3064

Reviewed By: hwangjeff

Differential Revision: D43307818

Pulled By: mthrok

fbshipit-source-id: 86339d973aba85e090f520e08af65b5d736e3d18",moto,855818+mthrok@users.noreply.github.com,"['docs/source/installation.rst', 'torchaudio/io/_stream_writer.py']",False,15,2,2023
b0af1406677063ecc2d05f4c1620bee7041de3d9,"Adding RC triggers for all build jobs (#3057)

Summary:
Add triggers for RC branches and tags to all build workflows. This will ensure that the release-candidate builds will run with `CHANNEL=test`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3057

Reviewed By: atalman

Differential Revision: D43279657

Pulled By: osalpekar

fbshipit-source-id: 5abf3994b9b4a4897f53c540bd1db6c3d624b3e0",Omkar Salpekar,osalpekar@fb.com,"['.github/workflows/build-conda-m1.yml', '.github/workflows/build-wheels-m1.yml', '.github/workflows/build_conda_linux.yml', '.github/workflows/build_conda_macos.yml', '.github/workflows/build_wheels_linux.yml', '.github/workflows/build_wheels_macos.yml']",False,14,2,2023
ff01be0fac48e08878be60ff51610f24d39b86c8,"Update ssl example (#3060)

Summary:
- Rename the current `ssl` example to `self_supervised_learning`
- Add README to demonstrate how to run the recipe with hubert task

Pull Request resolved: https://github.com/pytorch/audio/pull/3060

Reviewed By: mthrok

Differential Revision: D43287868

Pulled By: nateanl

fbshipit-source-id: 10352682485ef147ca32f4c4c9f9cde995444aa0",Zhaoheng Ni,zni@meta.com,"['examples/self_supervised_learning/README.md', 'examples/self_supervised_learning/data_modules/__init__.py', 'examples/self_supervised_learning/data_modules/_hubert_datamodule.py', 'examples/self_supervised_learning/data_modules/_utils.py', 'examples/self_supervised_learning/lightning.py', 'examples/self_supervised_learning/losses/__init__.py', 'examples/self_supervised_learning/losses/_hubert_loss.py', 'examples/self_supervised_learning/lr_schedulers/__init__.py', 'examples/self_supervised_learning/lr_schedulers/_linear_decay.py', 'examples/self_supervised_learning/train_hubert.py', 'examples/ssl/lr_schedulers/__init__.py']",False,14,2,2023
73b29fc93b2de0b52573d2a966db633518aa1ae3,"Redirect build instruction to official doc (#3053)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3053

Reviewed By: nateanl

Differential Revision: D43238766

Pulled By: mthrok

fbshipit-source-id: 4f82878b1c97b0e6a35af75855849b86200e6061",moto,855818+mthrok@users.noreply.github.com,"['README.md', 'docs/source/build.windows.rst', 'docs/source/installation.rst', 'docs/source/pipelines.rst']",False,14,2,2023
8c5c9a9bbf1dc3da60a6b89069d1775fc347fca1,"Add simulate_rir_ism method for room impulse response simulation (#2880)

Summary:
replicate of https://github.com/pytorch/audio/issues/2644

Pull Request resolved: https://github.com/pytorch/audio/pull/2880

Reviewed By: mthrok

Differential Revision: D41633911

Pulled By: nateanl

fbshipit-source-id: 73cf145d75c389e996aafe96571ab86dc21f86e5",Zhaoheng Ni,zni@fb.com,"['.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh', 'CMakeLists.txt', 'docs/source/prototype.functional.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/prototype/functional/functional_cpu_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_cpu_test.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'tools/setup_helpers/extension.py', 'torchaudio/_extension/__init__.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/pybind/pybind.cpp', 'torchaudio/csrc/rir.cpp', 'torchaudio/csrc/utils.cpp', 'torchaudio/csrc/utils.h', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_rir.py']",False,14,2,2023
3f02b898ecfa27cbeced1282f1ac7b25466d3877,"Update hardware accelerated video processing tutorial (#3050)

Summary:
Par https://github.com/pytorch/audio/issues/3040 and https://github.com/pytorch/audio/issues/3041, it turned out Google Colab now has FFmpeg with GPU decoder/encoder preinstalled, and installing FFmpeg manually corrups the environment.

This commit updates the tutorial by extracting and moving the how-to-install part to installation/build section.

closes https://github.com/pytorch/audio/issues/3041
closes https://github.com/pytorch/audio/issues/3040

Pull Request resolved: https://github.com/pytorch/audio/pull/3050

Reviewed By: nateanl

Differential Revision: D43166054

Pulled By: mthrok

fbshipit-source-id: 32667f292a796344d5fcde86e8231e15ad904e58",moto,855818+mthrok@users.noreply.github.com,"['docs/source/build.ffmpeg.rst', 'docs/source/hw_acceleration_tutorial.ipynb', 'docs/source/index.rst']",False,11,2,2023
fadb5ae5f73ab67bdffaac096da1f217ee80fb80,"Add python 3.11 support for torchaudio and add workflow concurrency rule (#3039)

Summary:
So far Linux and MacOS were tested to work fine out of the box. This PR is created to verify this -- disabled windows jobs and configs for now.

Pull Request resolved: https://github.com/pytorch/audio/pull/3039

Reviewed By: osalpekar

Differential Revision: D43174745

Pulled By: weiwangmeta

fbshipit-source-id: 81766905256e03c5a01cb5448a350f5d409ca4b8",Wei Wang,weiwangmeta@meta.com,"['.circleci/config.yml', '.circleci/regenerate.py', '.github/workflows/build-conda-m1.yml', '.github/workflows/build-wheels-m1.yml', '.github/workflows/build_conda_linux.yml', '.github/workflows/build_conda_macos.yml', '.github/workflows/build_wheels_linux.yml', '.github/workflows/build_wheels_macos.yml']",False,10,2,2023
91b05e2ec78e44856d90f4258f91d56807227bac,"Follow-up on audio playback function (#3051)

Summary:
- Add documentation
- Tweak docsrting
- Fix import

Pull Request resolved: https://github.com/pytorch/audio/pull/3051

Reviewed By: weiwangmeta, atalman, nateanl

Differential Revision: D43166081

Pulled By: mthrok

fbshipit-source-id: 7d77aa34a6318a64824626cff8372f8b9aebf6f9",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/io_class.rst', 'docs/source/io.rst', 'torchaudio/io/__init__.py', 'torchaudio/io/_playback.py']",False,9,2,2023
70acff7aefd85a37ba6ba826ec06afc22747d7e9,"Follow-up fix policy set (#3046)

Summary:
Commit b4c66d1 broke all the CIs.
The new policy changes the timestamp of configuration files of third party libraries,
which triggers re-configuration which requires extra tools.

This commit fixes it by reverting the old behavior.
Also this adds guard for older cmake versions.

Pull Request resolved: https://github.com/pytorch/audio/pull/3046

Reviewed By: atalman

Differential Revision: D43133536

Pulled By: mthrok

fbshipit-source-id: 357055c8c1b53e593b8b7880f2045e13512c7a8f",moto,855818+mthrok@users.noreply.github.com,['CMakeLists.txt'],False,9,2,2023
05d597fa95d3b3b61a59cecc64006dd723e4890c,"Updated USE_ROCM detection (#3008)

Summary:
We don't need the presence of physical HW to compile with CUDA.

This is a follow up PR regarding `USE_ROCM` for issue https://github.com/pytorch/audio/issues/2979.

Pull Request resolved: https://github.com/pytorch/audio/pull/3008

Reviewed By: malfet

Differential Revision: D42708862

Pulled By: DanilBaibak

fbshipit-source-id: 90cedc80a2d180ca1e0912ad5b644398182417b8",DanilBaibak,danil.baibak@gmail.com,['tools/setup_helpers/extension.py'],False,9,2,2023
98b3ac17d6289fe6309014ddaaab78cbe1f15fea,"Update the guard mechanism for FFmpeg-related features (#3028)

Summary:
Instead of raising an error when lazy import happens, this method allows to import features, and raises an error when the feature is being used.

This makes it easy to adopt the same error mechanism across different modules. It is how it's done for sox-related features.

Pull Request resolved: https://github.com/pytorch/audio/pull/3028

Reviewed By: xiaohui-zhang

Differential Revision: D42966976

Pulled By: mthrok

fbshipit-source-id: 423dfe0b8a3970cd07f20e841c794c7f2809f993",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/_extension/__init__.py', 'torchaudio/_extension/utils.py', 'torchaudio/io/__init__.py', 'torchaudio/io/_playback.py', 'torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py', 'torchaudio/utils/ffmpeg_utils.py']",False,8,2,2023
a0f8af4b178535f8db985452c07ac7faba898c1b,"Build doc on GHA (#3043)

Summary:
The first step to migrate doc build to GHA.

Pull Request resolved: https://github.com/pytorch/audio/pull/3043

Reviewed By: xiaohui-zhang

Differential Revision: D43110816

Pulled By: mthrok

fbshipit-source-id: 91de5f3ac567188e7030f14c2827a202a1901f1a",moto,855818+mthrok@users.noreply.github.com,['.github/workflows/build_docs.yml'],False,8,2,2023
b4c66d1fc082573f3c463f21111bc886c3502bca,"Suppres warning about archive timestamp (#3044)

Summary:
Currently, for each third party library checked out with ExternalProject_Add, the following warning is shown.

This commit set the policy so that the warning is not shown.

```
CMake Warning (dev) at ci_env/lib/python3.10/site-packages/cmake/data/share/cmake-3.25/Modules/ExternalProject.cmake:3075 (message):
  The DOWNLOAD_EXTRACT_TIMESTAMP option was not given and policy CMP0135 is
  not set.  The policy's OLD behavior will be used.  When using a URL
  download, the timestamps of extracted files should preferably be that of
  the time of extraction, otherwise code that depends on the extracted
  contents might not be rebuilt if the URL changes.  The OLD behavior
  preserves the timestamps from the archive instead, but this is usually not
  what you want.  Update your project to the NEW behavior or specify the
  DOWNLOAD_EXTRACT_TIMESTAMP option with a value of true to avoid this
  robustness issue.
```

Pull Request resolved: https://github.com/pytorch/audio/pull/3044

Reviewed By: xiaohui-zhang

Differential Revision: D43110818

Pulled By: mthrok

fbshipit-source-id: d2e20c9fdbbeeedb5ad546fe32dbda28c5bdd431",moto,855818+mthrok@users.noreply.github.com,['CMakeLists.txt'],False,8,2,2023
de54d864b271a5dde42aa650c828de18ea37580a,"Switch to Nova MacOS Conda (#2908)

Summary:
Switch to Nova M1 Conda

Pull Request resolved: https://github.com/pytorch/audio/pull/2908

Reviewed By: seemethere, osalpekar

Differential Revision: D43093605

Pulled By: DanilBaibak

fbshipit-source-id: 9e44f26cfb87e277c3808ee59f50218b4629e86e",DanilBaibak,danil.baibak@gmail.com,"['.circleci/config.yml', '.circleci/regenerate.py', '.github/workflows/build-conda-m1.yml', '.github/workflows/build-m1-binaries.yml', '.github/workflows/build_conda_macos.yml']",False,8,2,2023
3c121a59a9669b96725dacf851bd6afb8c90a2fa,"Add installation / build instruction to doc (#3038)

Summary:
Add a section about installation/build

https://output.circle-artifacts.com/output/job/f121cd38-68f3-47a3-ac29-c7b0cfe94c77/artifacts/0/docs/installation.html
<img width=""1102"" alt=""Screenshot 2023-02-06 at 6 13 50 PM"" src=""https://user-images.githubusercontent.com/855818/217108551-622b117b-209e-4776-b5d6-d6934c8126a4.png"">

https://output.circle-artifacts.com/output/job/f121cd38-68f3-47a3-ac29-c7b0cfe94c77/artifacts/0/docs/build.html
<img width=""1072"" alt=""Screenshot 2023-02-06 at 6 13 57 PM"" src=""https://user-images.githubusercontent.com/855818/217108568-c125cdc2-9d6a-4c1d-a155-2cee40c9dac6.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/3038

Reviewed By: hwangjeff, nateanl

Differential Revision: D43083469

Pulled By: mthrok

fbshipit-source-id: e0b5b76dbf706552dd60ae26ea40ebc98627e3b0",moto,855818+mthrok@users.noreply.github.com,"['docs/source/build.jetson.rst', 'docs/source/build.linux.rst', 'docs/source/build.rst', 'docs/source/build.windows.rst', 'docs/source/index.rst', 'docs/source/installation.rst']",False,7,2,2023
2ead941e398712f0d90f41ba7b88325e04725ebe,"Add playback function (#3026)

Summary:
Allows user to play audio through the
device speaker.

Pull Request resolved: https://github.com/pytorch/audio/pull/3026

Test Plan:
Created a new test that mocks a call to the write audio chunk method from StreamWriter. To run the test:

`pytest test/torchaudio_unittest/io/_playback_test.py`

Reviewed By: mthrok

Differential Revision: D43082062

Pulled By: jazcarretao

fbshipit-source-id: 01a85b32ce925687a633d1208d15d54556e89dd8",juan.azcarreta.ortiz,juan.azcarreta.ortiz@audioanalytic.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/io/playback_test.py', 'torchaudio/io/__init__.py', 'torchaudio/io/_playback.py']",False,7,2,2023
9368f33b02a408420acbb081ddbcadb9199614b7,"Switch circleci jobs from cu116 to cu117 (#3034)

Summary:
Switch circleci jobs from cu116 to cu117

Pull Request resolved: https://github.com/pytorch/audio/pull/3034

Reviewed By: DanilBaibak

Differential Revision: D43042385

Pulled By: atalman

fbshipit-source-id: 636e3d86d66a6091d13d731238550d800e77ccc8",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/regenerate.py']",False,6,2,2023
b7e173faa2a8043ea061211b101fa0e6e87141dc,"Add rgb48le and CUDA p010 support (HDR/10bit) to StreamReader (#3023)

Summary:
This adds 2 10 bit pix formats one for CPU and one for CUDA. This allows for training on HDR/10bit video datasets.

Pull Request resolved: https://github.com/pytorch/audio/pull/3023

Test Plan:
```py
r = StreamReader(
    reader, format='hevc',
)
stream = r.add_video_stream(
    frames_per_chunk=-1,
    decoder=""hevc_cuvid"",
    hw_accel=""cuda"",
)
frame = next(r.stream())
```

```py
r = StreamReader(
    reader, format='hevc',
)
stream = r.add_video_stream(
    frames_per_chunk=-1,
    filter_desc=""format=rgb48le"",
)
frame = next(r.stream())
```

![audio-example](https://user-images.githubusercontent.com/909104/215696543-ed3dc5a3-3013-4a57-8b98-05aa4a5a9a7c.png)

Reviewed By: xiaohui-zhang

Differential Revision: D43019191

Pulled By: mthrok

fbshipit-source-id: fe4359e525b24c8b856dfdf3d2f8596871566350",Tristan Rice,rice@fn.lc,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp']",False,4,2,2023
4f2010542b923d02fea1bb073fead94a259a986c,"feat: cuda kernel for lfilter (#3018)

Summary:
close https://github.com/pytorch/audio/issues/1408 .

Pull Request resolved: https://github.com/pytorch/audio/pull/3018

Reviewed By: xiaohui-zhang

Differential Revision: D42961853

Pulled By: mthrok

fbshipit-source-id: b9f847986e0afe416e7817ce4790e42cc0f83ee1",Chin-Yun Yu,lolimaster.cs03@nctu.edu.tw,"['torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/iir_cuda.cu', 'torchaudio/csrc/iir_cuda.h', 'torchaudio/csrc/lfilter.cpp']",False,4,2,2023
6bdd3830208951d6020e3fea0c8fbf21871d3344,"Add Linux GPU unit tests on GHA (#3029)

Summary:
Add GitHub Action-based GPU test jobs.
- It seems that there is 2 hour upper cap so only running CUDA/GPU tests.
- Since Kaldi related features are not available, they are disabled.

Pull Request resolved: https://github.com/pytorch/audio/pull/3029

Reviewed By: hwangjeff

Differential Revision: D42983800

Pulled By: mthrok

fbshipit-source-id: 47fefe39c635d1c73ad6799ddacefd2666fe5403",moto,855818+mthrok@users.noreply.github.com,"['.github/workflows/unittest-linux-gpu.yml', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/models/wav2vec2/fairseq_integration_test.py']",False,3,2,2023
409c687fcadeb9be265c3e5b599cb0148f0b7dd3,"Fix signature mismatch on _fail_info_fileobj (#3032)

Summary:
If FFmpeg is not available, sox_io cannot fallback to it. In such case, we use a fallback function, just to raise an error with easy-to-understand message.

Turned out that the number of arguments this function receives is wrong.

This commit fixes it.

Pull Request resolved: https://github.com/pytorch/audio/pull/3032

Reviewed By: hwangjeff

Differential Revision: D42966930

Pulled By: mthrok

fbshipit-source-id: c2c969c7f8db4119ae965a715d65c10f6ac6087c",moto,855818+mthrok@users.noreply.github.com,['torchaudio/backend/sox_io_backend.py'],False,2,2,2023
c63e9eb8dd33302a6d23c422007f7cec6d6830f4,"Add depreaction warnings to file-like object support in sox_io (#3033)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/3033

Reviewed By: hwangjeff

Differential Revision: D42966938

Pulled By: mthrok

fbshipit-source-id: 4889735c244690889f02bf57212489ad333389f7",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/backend/sox_io_backend.py', 'torchaudio/sox_effects/sox_effects.py']",False,2,2,2023
b28f9b3460db76b9adb54f9b1b9969d6850dfdc0,"Switch CI to CUDA 11.7 from CUDA 11.6 (#3031)

Summary:
Remove cuda 11.6 from CI replace with 11.7
Following the Release readme here: https://github.com/pytorch/pytorch/blob/master/RELEASE.md#release-compatibility-matrix

Pull Request resolved: https://github.com/pytorch/audio/pull/3031

Reviewed By: mthrok

Differential Revision: D42937626

Pulled By: atalman

fbshipit-source-id: 7e01c56ec0eefbef9ad455d013fced9012febe82",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,1,2,2023
01ba0ac8b85b41df0a05a618ad996fbf86dc88e4,"Update prototype functional tests. (#3027)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3027

To support older NumPy, removing `numpy.typing`.

Reviewed By: nateanl

Differential Revision: D42924428

fbshipit-source-id: af1a370b5baf00c63a088f172dbc2190d414bdf1",Moto Hira,moto@meta.com,['test/torchaudio_unittest/prototype/functional/dsp_utils.py'],False,1,2,2023
4928721020cdf0430b94dce6eec3ac20778d63aa,"Cleaning up private methods (#3030)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3030

A part of StreamWriter refactoring

(Note: this ignores all push blocking failures!)

Reviewed By: hwangjeff

Differential Revision: D42905959

fbshipit-source-id: ba8add3ce549c70c3775640840e41ace06b0ef65",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,1,2,2023
f663cb2874f918e7663c0daa1d3a3ae8636349ad,"Add C++ documentation (#2994)

Summary:
Adding C++ documentation. (C++ APIs are categorized as prototype, though it's used by Python beta APIs.)

https://output.circle-artifacts.com/output/job/69654229-a99e-4b15-9ce0-7bc6bcf01101/artifacts/0/docs/libtorchaudio.html

<img width=""1202"" alt=""Screenshot 2023-01-31 at 11 48 47 AM"" src=""https://user-images.githubusercontent.com/855818/215828167-d23032f8-9e40-4413-b5b1-5cbd12d705e9.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2994

Reviewed By: hwangjeff

Differential Revision: D42876621

Pulled By: mthrok

fbshipit-source-id: d8b8d610b87ec766501baa88b7506368a9905a6a",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.gitignore', 'docs/Makefile', 'docs/requirements.txt', 'docs/source/Doxyfile', 'docs/source/_static/css/custom.css', 'docs/source/_templates/autosummary/io_class.rst', 'docs/source/_templates/layout.html', 'docs/source/conf.py', 'docs/source/index.rst', 'docs/source/libtorchaudio.rst', 'docs/source/libtorchaudio.stream_reader.rst', 'docs/source/libtorchaudio.stream_writer.rst', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,1,2,2023
60af60a8aefa4d4830231a3c2f9a57384493b953,"Drop python 3.7 support (#3020)

Summary:
https://github.com/pytorch/pytorch/pull/93155 Core has dropped python3.7

Pull Request resolved: https://github.com/pytorch/audio/pull/3020

Reviewed By: mthrok

Differential Revision: D42902346

Pulled By: weiwangmeta

fbshipit-source-id: 07ab1aff0e128c5960d87e5fa29e341310dea388",Wei Wang,weiwangmeta@meta.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.circleci/smoke_test/docker/Dockerfile', 'README.md', 'packaging/pkg_helpers.bash', 'packaging/vs2019/conda_build_config.yaml', 'pyproject.toml', 'setup.py', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/hifi_gan/hifi_gan_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py']",False,1,2,2023
0709cadc32b59fea82bbca8510e718ccb81cf816,"Remove unnecessary AVFrame allocation (#3021)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3021

When input format and encode format is different in StreamWriter, filter for format conversion is inserted.

A temporary AVFilter (`dst_frame`) is used for this case,
but FilterGraph handles the memory allocation,
so there is no need to perform allocation by ourselves.

This `dst_frame` is otherwise not used, so we do not have to allocate memory at all.
This commit removes the unnecessary memory allocation at all.

Reviewed By: xiaohui-zhang

Differential Revision: D42865042

fbshipit-source-id: 2673b06de1e905dc73a11e2ec1cc6ce7b525d451",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp'],False,31,1,2023
da9d1627ea7c266d01a91f6ee6a1533038e499c4,"Fix hybrid demucs tutorial for CUDA (#3017)

Summary:
Currently there will be a few errors when this tutorial is run with a CUDA device.

The reasons being:
- The source audio waveform is not properly moved to the GPU. The `to()` method is not in-place for Tensors, so we need to assign the return value of the method call to the variable (otherwise the Tensor would still be on the CPU).
- When performing further analysis and displaying of the output audio, we need to move them back from the GPU to the CPU. This is because some of the functions we call require the Tensor to be on the CPU (e.g. `stft()` and `bss_eval_sources()`).

Pull Request resolved: https://github.com/pytorch/audio/pull/3017

Reviewed By: mthrok

Differential Revision: D42828526

Pulled By: nateanl

fbshipit-source-id: c28bc855e79e3363a011f4a35a69aae1764e7762",Yan Li,eyeplum@gmail.com,['examples/tutorials/hybrid_demucs_tutorial.py'],False,30,1,2023
635d8cff38e1a418768c2cee2daab4062ced2902,"Add get_build_config ffmpeg utility function (#3014)

Summary:
We often need to look at which FFmpeg was found and linked when debugging an issue.

Version number is often not enough but there is no easy way to find where the library was found either.

This commit adds utility function that prints the build time configuration.

It helps to distinguish if the linked FFmpeg is the one from binary distribution built in CI or locally built.

Pull Request resolved: https://github.com/pytorch/audio/pull/3014

Reviewed By: hwangjeff

Differential Revision: D42794952

Pulled By: mthrok

fbshipit-source-id: 91ed358fde8cfe9d6d950f34742b1722e729cf4e",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/utils.cpp', 'torchaudio/utils/ffmpeg_utils.py']",False,30,1,2023
51aae466481c736eeeaf1f14b08d325ab964ab9b,"Replace torchaudio::ffmpeg with torchaudio::io (#3013)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3013

Namespace clean up before publishing the torchaudio C++ API as prototype.

Reviewed By: hwangjeff

Differential Revision: D42699903

fbshipit-source-id: 8a9eed0390dfa4a152124b42f2b927dbdd3e23d2",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.h', 'torchaudio/csrc/ffmpeg/pybind/typedefs.cpp', 'torchaudio/csrc/ffmpeg/pybind/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_binding.cpp', 'torchaudio/csrc/ffmpeg/utils.cpp']",False,27,1,2023
12f960b245fb5334272e0c3325efe8879ab46c30,"Switch to Nova Linux Conda build (#2899)

Summary:
Switch to Nova Linux Conda build.

Pull Request resolved: https://github.com/pytorch/audio/pull/2899

Reviewed By: seemethere, osalpekar, mthrok

Differential Revision: D42416835

Pulled By: DanilBaibak

fbshipit-source-id: 70886c4ff6f3243b80059be9385269cc0f2d4764",DanilBaibak,danil.baibak@gmail.com,"['.circleci/config.yml', '.circleci/regenerate.py', '.github/workflows/build_conda_linux.yml']",False,27,1,2023
b4cc0f331f2e550344855b1666478ea5ac2cf118,"Move data augmentation transforms out of prototype (#3009)

Summary:
Moves `AddNoise`, `Convolve`, `FFTConvolve`, `Speed`, `SpeedPerturbation`, `Deemphasis`, and `Preemphasis` out of `torchaudio.prototype.transforms` and into `torchaudio.transforms`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3009

Reviewed By: xiaohui-zhang, mthrok

Differential Revision: D42730322

Pulled By: hwangjeff

fbshipit-source-id: 43739ac31437150d3127e51eddc0f0bba5facb15",hwangjeff,jeffhwang@meta.com,"['docs/source/prototype.transforms.rst', 'docs/source/transforms.rst', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_cpu_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_cuda_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'test/torchaudio_unittest/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/prototype/transforms/__init__.py', 'torchaudio/prototype/transforms/_transforms.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",False,27,1,2023
7ea69e61762bf85b9ac8d09e03350bbab2b9d7af,"Abstract away AVFormatContext from StreamReader/Writer constructor (#3007)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3007

Simplify the construction of StreamReader/Writer in C++.

Currently these classes require client code to build AVFormatContext
manually. This is tedious and not user freindly.

Some client code actually uses the same helper function that
TorchAudio codebase uses.

This commit moves the helper logic inside of the constructor of
StreamReader/Writer, so that the signatures of these constructors
are easy to use and similar to Python interface.

Reviewed By: xiaohui-zhang

Differential Revision: D42662520

fbshipit-source-id: d95e5236810c48d7d9bd2d89c05d4f60a44b3ba1",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_wrapper.h']",False,26,1,2023
2f5fcf4f1cb2b3a500efb961126e341016d93f1d,"Remove function input parameters from data aug functional tests (#3011)

Summary:
Passing functions as test parameters causes issues on some platforms. This PR updates the functional tests to pass functions by name instead.

Pull Request resolved: https://github.com/pytorch/audio/pull/3011

Reviewed By: mthrok

Differential Revision: D42748106

Pulled By: hwangjeff

fbshipit-source-id: 4d81dabe4aff2293bc344a457a034a2d9af024e2",hwangjeff,jeffhwang@meta.com,"['test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py']",False,26,1,2023
aa760cafba48803cc363fd5ce8c2ee429bfd5761,"Deprecate sox initialization/shutdown public API functions (#3010)

Summary:
These functions are called part of sox initialization, thus it is no longer needed.

Pull Request resolved: https://github.com/pytorch/audio/pull/3010

Reviewed By: hwangjeff

Differential Revision: D42744478

Pulled By: mthrok

fbshipit-source-id: 17d715b328392397ec47d81a533a307aac22862d",moto,855818+mthrok@users.noreply.github.com,"['docs/source/sox_effects.rst', 'torchaudio/sox_effects/sox_effects.py']",False,26,1,2023
41b883145a81b98254794c1504600dd610fc81f6,"Move data augmentation functions out of prototype (#3001)

Summary:
Moves `add_noise`, `fftconvolve`, `convolve`, `speed`, `preemphasis`, and `deemphasis` out of `torchaudio.prototype.functional` and into `torchaudio.functional`.

Pull Request resolved: https://github.com/pytorch/audio/pull/3001

Reviewed By: mthrok

Differential Revision: D42688971

Pulled By: hwangjeff

fbshipit-source-id: 43280bd3ffeccddae57f1092ac45afb64dd426cc",hwangjeff,jeffhwang@meta.com,"['docs/source/functional.rst', 'docs/source/prototype.functional.rst', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py', 'torchaudio/prototype/functional/functional.py', 'torchaudio/prototype/transforms/_transforms.py']",False,24,1,2023
09e7d818d0b3a18417f02454a16825e420b468cf,"Tweak `USE_CUDA` detection (#3005)

Summary:
We don't need the presence of physical HW to compile with CUDA.

Likely one of the causes of  https://github.com/pytorch/audio/issues/2979 (i.e. in CircleCI builds USE_CUDA were defined by CI environment, so nobody ever checked the default, but this is not the case in Nova builds)

Pull Request resolved: https://github.com/pytorch/audio/pull/3005

Test Plan:
Check that `compute.cu` is mentioned in builds, for example see https://github.com/pytorch/audio/actions/runs/3990295262/jobs/6843771056#step:9:829
```
[193/202] /usr/local/cuda-11.6/bin/nvcc -forward-unknown-to-host-compiler -DINCLUDE_KALDI -DUSE_C10D_GLOO -DUSE_C10D_NCCL -DUSE_CUDA -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -Dlibtorchaudio_EXPORTS -I/__w/audio/audio/pytorch/audio -I/__w/audio/audio/pytorch/audio/third_party/kaldi/src -I/__w/audio/audio/pytorch/audio/third_party/kaldi/submodule/src -isystem=/__w/_temp/conda_environment_3990295262/lib/python3.7/site-packages/torch/include -isystem=/__w/_temp/conda_environment_3990295262/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem=/usr/local/cuda-11.6/include -DONNX_NAMESPACE=onnx_c2 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_50,code=compute_50 -Xcudafe --diag_suppress=cc_clobber_ignored,--diag_suppress=integer_sign_change,--diag_suppress=useless_using_declaration,--diag_suppress=set_but_not_used,--diag_suppress=field_without_dll_interface,--diag_suppress=base_class_has_different_dll_interface,--diag_suppress=dll_interface_conflict_none_assumed,--diag_suppress=dll_interface_conflict_dllexport_assumed,--diag_suppress=implicit_return_from_non_void_function,--diag_suppress=unsigned_compare_with_zero,--diag_suppress=declared_but_not_referenced,--diag_suppress=bad_friend_decl --expt-relaxed-constexpr --expt-extended-lambda -O3 -DNDEBUG -Xcompiler=-fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17 -MD -MT torchaudio/csrc/CMakeFiles/libtorchaudio.dir/rnnt/gpu/compute.cu.o -MF torchaudio/csrc/CMakeFiles/libtorchaudio.dir/rnnt/gpu/compute.cu.o.d -x cu -c /__w/audio/audio/pytorch/audio/torchaudio/csrc/rnnt/gpu/compute.cu -o torchaudio/csrc/CMakeFiles/libtorchaudio.dir/rnnt/gpu/compute.cu.o
```

Reviewed By: mthrok

Differential Revision: D42687455

Pulled By: malfet

fbshipit-source-id: c37ad58cc62439d1268865e9bf0bcb97079a529f",Nikita Shulga,nshulga@fb.com,['tools/setup_helpers/extension.py'],False,23,1,2023
54196fd3d44d84e2e407eba9f016b4f58942a987,"Merge pop_chunks methods (#3002)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/3002

This commit merges `pop_chunks` and `pop_chunks_with_metadata`.

In #2975 (D42526945 (https://github.com/pytorch/audio/commit/0dd59e0dda22eabf54fc95ad8050094df239bd39)), we updated StreamReader so that it returns PTS.
In that PR, we introduced `pop_chunks_with_metadata` method, so that
the original `pop_chunks` method returns the same type and we could
focus on the PTS logic in the code review.

The commit is landed, now we merge the two methods, so that the original
`pop_chunks` returns Tensor frames and metadata (PTS).

Reviewed By: xiaohui-zhang

Differential Revision: D42662321

fbshipit-source-id: 37ae088bc63fc516ea068698088925e8b31bc0a1",Moto Hira,moto@meta.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp']",False,23,1,2023
1f9b91041d2610c163a3931857cb71f3490f2912,"Update highlighting in doc (#3000)

Summary:
This change fixes the issue where syntax highlighting is broken up par word.

## Plain
Before
<img width=""243"" alt=""Screenshot 2023-01-20 at 1 28 48 PM"" src=""https://user-images.githubusercontent.com/855818/213778202-27ec8030-3f2f-4ef9-8210-bce7cfc3cb38.png"">
After
<img width=""244"" alt=""Screenshot 2023-01-20 at 1 29 01 PM"" src=""https://user-images.githubusercontent.com/855818/213778231-61c52825-d63a-4913-b10d-a65f3b2cfbbb.png"">

## In articles
Before
<img width=""786"" alt=""Screenshot 2023-01-20 at 1 34 12 PM"" src=""https://user-images.githubusercontent.com/855818/213779050-c21ba5e2-84b3-4935-bbab-6edcb7bc89ce.png"">
After
<img width=""783"" alt=""Screenshot 2023-01-20 at 1 34 17 PM"" src=""https://user-images.githubusercontent.com/855818/213779069-f1406422-27a4-41cf-8ccd-5058f80860bd.png"">

## In tables
Before
<img width=""813"" alt=""Screenshot 2023-01-20 at 1 27 35 PM"" src=""https://user-images.githubusercontent.com/855818/213778039-fede6f18-5a35-47f2-9e0b-a9be5716dc73.png"">
After
<img width=""813"" alt=""Screenshot 2023-01-20 at 1 27 51 PM"" src=""https://user-images.githubusercontent.com/855818/213778073-e26275a9-d380-4601-aa92-84af7aeab00f.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/3000

Reviewed By: xiaohui-zhang

Differential Revision: D42642522

Pulled By: mthrok

fbshipit-source-id: 6831bb90da005aff8d7f178ef768e967bc6d2640",moto,855818+mthrok@users.noreply.github.com,['docs/source/_static/css/custom.css'],False,23,1,2023
0dd59e0dda22eabf54fc95ad8050094df239bd39,"Make StreamReader return PTS (#2975)

Summary:
This commit makes `StreamReader` report PTS (presentation time stamp) of the returned chunk as well.

Example

```python
from torchaudio.io import StreamReader

s = StreamReader(...)
s.add_video_stream(...)
for (video_chunk, ) in s.stream():
    # video_chunk is Torch tensor type but has extra attribute of PTS
    print(video_chunk.pts)  # reports the PTS of the first frame of the video chunk.
```

For the backward compatibility, we introduce a `_ChunkTensor`, that is a composition
of Tensor and metadata, but works like a normal tensor in PyTorch operations.

The implementation of `_ChunkTensor` is based on [TrivialTensorViaComposition](https://github.com/albanD/subclass_zoo/blob/0eeb1d68fb59879029c610bc407f2997ae43ba0a/trivial_tensors.py#L83).

It was also suggested to attach metadata directly to Tensor object,
but the possibility to have the collision on torchaudio's metadata and new attributes introduced in
PyTorch cannot be ignored, so we use Tensor subclass implementation.

If any unexpected issue arise from metadata attribute name collision, client code can
fetch the bare Tensor and continue.

Pull Request resolved: https://github.com/pytorch/audio/pull/2975

Reviewed By: hwangjeff

Differential Revision: D42526945

Pulled By: mthrok

fbshipit-source-id: b4e9422e914ff328421b975120460f3001268f35",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/io_class.rst', 'test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h', 'torchaudio/io/__init__.py', 'torchaudio/io/_compat.py', 'torchaudio/io/_stream_reader.py']",False,22,1,2023
de628226ddfdb94bab8ad81d7f1d65b3d232af7d,"Document StreamReader/Writer C++ code (#2997)

Summary:
Extraction from https://github.com/pytorch/audio/issues/2994

Add docstrings to C++ StreamReader/Writer.

Pull Request resolved: https://github.com/pytorch/audio/pull/2997

Reviewed By: nateanl

Differential Revision: D42628016

Pulled By: mthrok

fbshipit-source-id: b22c43b80997af4a9087142340c67bed28e54917",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h']",False,20,1,2023
bcfa9eed5d96ccf4c302c0594af77e103c482555,"Fix error message (#2999)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2999

Reviewed By: hwangjeff

Differential Revision: D42637618

Pulled By: mthrok

fbshipit-source-id: 35a7976c316e3b3899ae9c2202f132f1a960b736",moto,855818+mthrok@users.noreply.github.com,['torchaudio/models/wav2vec2/components.py'],False,20,1,2023
de9473a4fc815c0fa9c5250eb255f9fdf161bf6d,"Move drain method to private (#2996)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2996

Reviewed By: nateanl

Differential Revision: D42624655

Pulled By: mthrok

fbshipit-source-id: 8273cbfa529fbc2bd28adc9c63ceb9453838baa4",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h'],False,20,1,2023
6a5efe6c00a4e4f10e83b662ccf46b30ae920bec,"Remove unused/redundant things (#2995)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2995

Reviewed By: nateanl

Differential Revision: D42624676

Pulled By: mthrok

fbshipit-source-id: 10fbdaada06ae78e5fa2253eb3331c93c032eeb3",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/stream_reader/typedefs.h'],False,20,1,2023
2eaefe2745bff1a898394f9f447c011bc50daedc,"Add modularized SSL training recipe (#2876)

Summary:
TorchAudio currently has one training recipe for HuBET + LibriSpeech pre-training. It may not suit well when users want to use customized dataset, or use a new training objective (such as contrastive loss in Wav2Vec2). The PR addresses the issue by providing a modularized training recipe for audio self-supervised learning. Users can inject customized model module, loss function, optimizer, lr scheduler, and datamodule for training a SSL model.

Pull Request resolved: https://github.com/pytorch/audio/pull/2876

Reviewed By: hwangjeff

Differential Revision: D42617414

Pulled By: nateanl

fbshipit-source-id: 6413df45a9d106ed1d5ff830bf628c54368c5792",Zhaoheng Ni,zni@fb.com,"['examples/ssl/data_modules/__init__.py', 'examples/ssl/data_modules/_hubert_datamodule.py', 'examples/ssl/data_modules/_utils.py', 'examples/ssl/lightning.py', 'examples/ssl/losses/__init__.py', 'examples/ssl/losses/_hubert_loss.py', 'examples/ssl/lr_schedulers/__init__.py', 'examples/ssl/lr_schedulers/_linear_decay.py', 'examples/ssl/train_hubert.py']",False,19,1,2023
c6a52355e86b7b030a26f52f6812f1ced53396af,"Simplify train step in Conformer RNN-T LibriSpeech recipe (#2981)

Summary:
In the Conformer RNN-T LibriSpeech recipe, there's no need to perform manual optimization. This PR modifies the recipe to use automatic optimization instead.

Pull Request resolved: https://github.com/pytorch/audio/pull/2981

Reviewed By: mthrok

Differential Revision: D42507228

Pulled By: hwangjeff

fbshipit-source-id: 9712add951eba356e39f7e8c8dc3bf584ba48309",hwangjeff,jeffhwang@meta.com,"['examples/asr/librispeech_conformer_rnnt/lightning.py', 'examples/asr/librispeech_conformer_rnnt/train.py']",False,19,1,2023
bb077284ae5e382ae1a570b0532ca15de3baae5c,"Make lengths optional for additive noise operators (#2977)

Summary:
For greater flexibility, this PR makes argument `lengths` optional for `add_noise` and `AddNoise`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2977

Reviewed By: nateanl

Differential Revision: D42484211

Pulled By: hwangjeff

fbshipit-source-id: 54757dcc73df194bb98c1d9d42a2f43f3027b190",hwangjeff,jeffhwang@meta.com,"['test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'torchaudio/prototype/functional/functional.py', 'torchaudio/prototype/transforms/_transforms.py']",False,19,1,2023
51731bf956a8c830e7f3c7a87e148ec264af90f2,"Fix buffer flushing mechanism

Summary:
When buffered data are cleared from ChunkedBuffer,
the `num_buffered_frames` variable was not updated.

This commit fixes that.

Reviewed By: xiaohui-zhang

Differential Revision: D42538519

fbshipit-source-id: a24a9afcebebd8956d977f05e9c2f0b603d060d1",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp'],False,17,1,2023
b983c6650ca5effeb57afd5dee65b17b2464f7d6,"Fix mel spectrogram visualization in TTS tutorial (#2989)

Summary:
The mel spectrograms in the TTS tutorial are upside down. The PR fixes it by using `origin=""lower""` in imshow.

Pull Request resolved: https://github.com/pytorch/audio/pull/2989

Reviewed By: mthrok

Differential Revision: D42538349

Pulled By: nateanl

fbshipit-source-id: 4388103a49bdfabf1705c1f979d44ecedd5c910a",Zhaoheng Ni,zni@meta.com,['examples/tutorials/tacotron2_pipeline_tutorial.py'],False,17,1,2023
e259f156ffe33e64eccd64d3aa2402d54d979384,"Refactor buffer common utils (#2988)

Summary:
Split `convert_video` into memory allocation function and write function.

Also put all the buffer implementations into detail namespace.

Pull Request resolved: https://github.com/pytorch/audio/pull/2988

Reviewed By: xiaohui-zhang

Differential Revision: D42536769

Pulled By: mthrok

fbshipit-source-id: 36fbf437d4bfd521322846161ae08a48c782c540",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp']",False,16,1,2023
f9d38796338f1ddf896660db249949926315d9ec,"Fixes examples/source_separation for WSJ0_2mix dataset (#2987)

Summary:
The `examples/source_separation` scripts use inconsistent keyword to indicate the WSJ0_2mix dataset. This PR does the following.

1. Use `wsj0mix` consistently as keyword indicating the WSJ0_2mix dataset
2. Corrects `args.data_dir` to `args.root_dir` in eval.py
3. Modify the parameters of `pytorch_lightning.Trainer` according to latest version (use `accelerator=""gpu""` and `devices=args.num_devices`, instead of just `gpus=args.num_devices`)

Pull Request resolved: https://github.com/pytorch/audio/pull/2987

Reviewed By: xiaohui-zhang

Differential Revision: D42536992

Pulled By: nateanl

fbshipit-source-id: 10a80263ad7054b1629d8fa023676b607e633d76",Robin Scheibler,robin.scheibler@linecorp.com,"['examples/source_separation/eval.py', 'examples/source_separation/lightning_train.py']",False,16,1,2023
52b6bc3bdd1a7de5eaf80c386b21079b94c9d51c,"Refactor chunked buffer implementation (#2984)

Summary:
So that the number of Tensor frames stored in buffers is always a multiple of frames_per_chunk.

This makes it easy to store PTS values in aligned manner.

Pull Request resolved: https://github.com/pytorch/audio/pull/2984

Reviewed By: nateanl

Differential Revision: D42526670

Pulled By: mthrok

fbshipit-source-id: d83ee914b7e50de3b51758069b0e0b6b3ebe2e54",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp']",False,16,1,2023
3ecf78d6262acce45a15ca6a4decfc50943feb9e,"Set filter graph #threads to 1 (#2985)

Summary:
FilterGraph supports multi threading, and by default, the number of threads is determined automatically.

Rather than an automatic behavior, which is unpredictable, it is better to fix the number of threads to 1.

Follow-up: Add an interface to adjust it.

Similar to https://github.com/pytorch/audio/pull/2949.

Pull Request resolved: https://github.com/pytorch/audio/pull/2985

Reviewed By: nateanl

Differential Revision: D42526958

Pulled By: mthrok

fbshipit-source-id: c4f7f95317e93a39378107636a3ca30f6ddfe466",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/filter_graph.cpp'],False,16,1,2023
9b7b64e42fb6d88473ad9361210999bbfead3d6f,"Add pre-trained pipelines for XLS-R models (#2978)

Summary:
The PR adds three `Wav2Vec2Bundle ` pipeline objects for XLS-R models:
- WAV2VEC2_XLSR_300M
- WAV2VEC2_XLSR_1B
- WAV2VEC2_XLSR_2B

All three models use layer normalization in the feature extraction layers, hence `_normalize_waveform` is set to `True`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2978

Reviewed By: hwangjeff

Differential Revision: D42501491

Pulled By: nateanl

fbshipit-source-id: 2429ec880cc14798034843381e458e1b4664dac3",Zhaoheng Ni,zni@meta.com,"['docs/source/pipelines.rst', 'docs/source/refs.bib', 'test/integration_tests/wav2vec2_pipeline_test.py', 'torchaudio/pipelines/__init__.py', 'torchaudio/pipelines/_wav2vec2/impl.py']",False,15,1,2023
82ded7e7eadb266d953f2db19943a946f91057a0,"Fix CI tests on gpu machines (#2982)

Summary:
XLS-R tests are supposed to be skipped on gpu machines, but they are forced to run in [_skipIf](https://github.com/pytorch/audio/blob/main/test/torchaudio_unittest/common_utils/case_utils.py#L143-L145) decorator. This PR skips the XLS-R tests if the machine is CI and CUDA is available.

Pull Request resolved: https://github.com/pytorch/audio/pull/2982

Reviewed By: xiaohui-zhang

Differential Revision: D42520292

Pulled By: nateanl

fbshipit-source-id: c6ee4d4a801245226c26d9cd13e039e8d910add2",Zhaoheng Ni,zni@meta.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'test/torchaudio_unittest/models/wav2vec2/fairseq_integration_test.py', 'test/torchaudio_unittest/models/wav2vec2/huggingface_intergration_test.py']",False,14,1,2023
55575a53de6900b1550ae49c50392a4cb5058adf,"Add mel spectrogram visualization to Streaming ASR tutorial (#2974)

Summary:
Per the suggestion by nateanl, adding the visualization of feature fed to ASR.

<img width=""688"" alt=""Screen Shot 2023-01-12 at 8 19 59 PM"" src=""https://user-images.githubusercontent.com/855818/212215190-23be7553-4c04-40d9-944e-3ee2ff69c49b.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2974

Reviewed By: nateanl

Differential Revision: D42484088

Pulled By: mthrok

fbshipit-source-id: 2c839492869416554eac04aa06cd12078db21bd7",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/online_asr_tutorial.py'],False,13,1,2023
a5664ca9c3ad9116ccb26befdf620cd9c71a6952,"Add XLS-R models (#2959)

Summary:
XLSR (cross-lingual speech representation) are a set of cross-lingual self-supervised learning models for generating cross-lingual speech representation. It was first proposed in https://arxiv.org/pdf/2006.13979.pdf which is trained on 53 languages (so-called XLSR-53). This PR supports more XLS-R models from https://arxiv.org/pdf/2111.09296.pdf that have more parameters (300M, 1B, 2B) and are trained on 128 languages.

Pull Request resolved: https://github.com/pytorch/audio/pull/2959

Reviewed By: mthrok

Differential Revision: D42397643

Pulled By: nateanl

fbshipit-source-id: 23e8e51a7cde0a226db4f4028db7df8f02b986ce",Zhaoheng Ni,zni@fb.com,"['docs/source/_templates/autosummary/model_class.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/assets/wav2vec2/fairseq/xlsr_1b.json', 'test/torchaudio_unittest/assets/wav2vec2/fairseq/xlsr_2b.json', 'test/torchaudio_unittest/assets/wav2vec2/fairseq/xlsr_300m.json', 'test/torchaudio_unittest/assets/wav2vec2/huggingface/wav2vec2-xls-r-1b.json', 'test/torchaudio_unittest/assets/wav2vec2/huggingface/wav2vec2-xls-r-2b.json', 'test/torchaudio_unittest/assets/wav2vec2/huggingface/wav2vec2-xls-r-300m.json', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/models/wav2vec2/fairseq_integration_test.py', 'test/torchaudio_unittest/models/wav2vec2/huggingface_intergration_test.py', 'torchaudio/models/__init__.py', 'torchaudio/models/wav2vec2/__init__.py', 'torchaudio/models/wav2vec2/model.py']",False,13,1,2023
5dfe0b22e5c6b0ff9a1c7a526ba4a10df66a425d,"Refactor extension modules initialization (#2968)

Summary:
* Refactor _extension module so that
  * the implementation of initialization logic and its execution are separated.
    * logic goes to `_extension.utils`
    * the execution is at `_extension.__init__`
    * global variables are defined and modified in `__init__`.
* Replace `is_sox_available()` with `_extension._SOX_INITIALIZED`
* Replace `is_kaldi_available()` with `_extension._IS_KALDI_AVAILABLE`
* Move `requies_sox()` and `requires_kaldi()` to break the circular dependency among `_extension` and `_internal.module_utils`.
* Merge the sox-related initialization logic in `_extension.utils` module.

Pull Request resolved: https://github.com/pytorch/audio/pull/2968

Reviewed By: hwangjeff

Differential Revision: D42387251

Pulled By: mthrok

fbshipit-source-id: 0c3245dfab53f9bc1b8a83ec2622eb88ec96673f",mthrok,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/common_utils/case_utils.py', 'torchaudio/_extension/__init__.py', 'torchaudio/_extension/utils.py', 'torchaudio/_internal/module_utils.py', 'torchaudio/backend/soundfile_backend.py', 'torchaudio/backend/sox_io_backend.py', 'torchaudio/backend/utils.py', 'torchaudio/functional/functional.py', 'torchaudio/io/__init__.py', 'torchaudio/sox_effects/__init__.py', 'torchaudio/sox_effects/sox_effects.py', 'torchaudio/utils/__init__.py', 'torchaudio/utils/sox_utils.py']",False,12,1,2023
32d46f94d078f2b4328a1ccac3804cf2c8e241fb,"Add query methods to FilterGraph (#2976)

Summary:
This commit add methods to query output configuration from FilterGraph object.
* time_base -> required to compute PTS of output frame
* sample_rate, num_channels -> required to compute PTS and pre allocate buffers for audio.

Pull Request resolved: https://github.com/pytorch/audio/pull/2976

Reviewed By: xiaohui-zhang

Differential Revision: D42466744

Pulled By: mthrok

fbshipit-source-id: dd27109819bfb1fbe37b8233dd6a5e4224fe3f6c",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h']",False,12,1,2023
22788a8f6b7a5ff6d9601d02510ed34e51c9b99a,"Add `buffer_chunk_size=-1` option (#2969)

Summary:
This commit adds `buffer_chunk_size=-1`, which does not drop buffered frames.

Pull Request resolved: https://github.com/pytorch/audio/pull/2969

Reviewed By: xiaohui-zhang

Differential Revision: D42403467

Pulled By: mthrok

fbshipit-source-id: a0847e6878874ce7e4b0ec3f56e5fbb8ebdb5992",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/io/_stream_reader.py']",False,12,1,2023
d1cc1da6a4d6cb2fa44eda457c141aa2ac73e11a,"Update C++ standard to 17 (#2973)

Summary:
Following the change in PyTorch core.

https://github.com/pytorch/pytorch/commit/87e4a087784c805312a2b48bb063d2400df26c5e

Pull Request resolved: https://github.com/pytorch/audio/pull/2973

Reviewed By: xiaohui-zhang

Differential Revision: D42462709

Pulled By: mthrok

fbshipit-source-id: 60c2aa3d63fe25d8e0b7aa476404e7a55d6eb87f",moto,855818+mthrok@users.noreply.github.com,['CMakeLists.txt'],False,12,1,2023
7e7b60c185b989f9e85f40bf162a28b92efa12b7,"add CUDA 11.8 builds (#2951)

Summary:
CC atalman

Pull Request resolved: https://github.com/pytorch/audio/pull/2951

Reviewed By: mthrok

Differential Revision: D42459205

Pulled By: atalman

fbshipit-source-id: b2d7c5604ba1f3bb4d9a45a052ac41054acd52dd",pbialecki,piotr.bialecki@hotmail.de,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.circleci/unittest/windows/scripts/install.sh', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",False,11,1,2023
1717edaa8cddf5068df97e30404d85654f0b55f4,"Update the handling of videos without PTS values (#2970)

Summary:
filter graph does not fallback to `best_effort_timestamp`, thus applying filters (like changing fps) on videos without PTS values failed.

This commit changes the behavior by overwriting the PTS values with best_effort_timestamp.

Pull Request resolved: https://github.com/pytorch/audio/pull/2970

Reviewed By: YosuaMichael

Differential Revision: D42425771

Pulled By: mthrok

fbshipit-source-id: 7b7a033ea2ad89bb49d6e1663d35d377dab2aae9",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp']",False,10,1,2023
e1cddb46398fb3054ec24589604cfe0739854267,"Fix fill_buffer method (#2971)

Summary:
* Add missing docsrtings
* Add default values

Pull Request resolved: https://github.com/pytorch/audio/pull/2971

Reviewed By: xiaohui-zhang

Differential Revision: D42425796

Pulled By: mthrok

fbshipit-source-id: a6a946875142a54424c059bbfbab1908a1564bd3",moto,855818+mthrok@users.noreply.github.com,['torchaudio/io/_stream_reader.py'],False,10,1,2023
4a037b03915c4f6f81407e697fb11a7e7ace27fa,"Fix document for MelScale and InverseMelScale (#2967)

Summary:
`InverseMelScale` is missing from the nightly documentation webpage. `MelScale` is better in Feature Extractions section. This PR moves both documents into Feature Extractions section.

Pull Request resolved: https://github.com/pytorch/audio/pull/2967

Reviewed By: mthrok

Differential Revision: D42387886

Pulled By: nateanl

fbshipit-source-id: cdac020887817ea2530bfb26e8ed414ae4761420",Zhaoheng Ni,zni@fb.com,['docs/source/transforms.rst'],True,6,1,2023
b6d147ad101f18ef980d0016c1d2aa7ce5e8105c,"Add utility functions to fetch available formats/devices/codecs/protocols. (#2958)

Summary:
This commit adds utility functions that fetch the available/supported formats/devices/codecs.

These functions are mostly same with commands like `ffmpeg -decoders`. But the use of `ffmpeg` CLI can report different resutls if there are multiple installation of FFmpegs. Or, the CLI might not be available.

Pull Request resolved: https://github.com/pytorch/audio/pull/2958

Reviewed By: hwangjeff

Differential Revision: D42371640

Pulled By: mthrok

fbshipit-source-id: 96a96183815a126cb1adc97ab7754aef216fff6f",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/utils/ffmpeg_utils_test.py', 'torchaudio/csrc/ffmpeg/utils.cpp', 'torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py', 'torchaudio/utils/ffmpeg_utils.py']",False,6,1,2023
21504e4290adccc8c8f80ffa121fbab257378858,"Fix style issue (#2966)

Summary:
Introduced in hotfix https://github.com/pytorch/audio/issues/2964

Pull Request resolved: https://github.com/pytorch/audio/pull/2966

Reviewed By: carolineechen

Differential Revision: D42385913

Pulled By: mthrok

fbshipit-source-id: 6c42dbfbb914b0329c09a1bca591f11cf2e3c1a6",moto,855818+mthrok@users.noreply.github.com,['torchaudio/_internal/module_utils.py'],False,6,1,2023
01f29d73f0e3e2a4868557ddf43b9de9dd3b745f,"Refactor common buffer utility header (#2962)

Summary:
Put the helper functions in unnamed namespace.

Pull Request resolved: https://github.com/pytorch/audio/pull/2962

Reviewed By: carolineechen

Differential Revision: D42378781

Pulled By: mthrok

fbshipit-source-id: 74daf613f8b78f95141ae4e7c4682d8d0e97f72e",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h']",False,6,1,2023
b4d55fa1caf2c697b1687afe5b36128441ef39c2,"Fix kaldi plug-in detection (#2964)

Summary:
Follow-up of f70b970ab

Pull Request resolved: https://github.com/pytorch/audio/pull/2964

Reviewed By: xiaohui-zhang

Differential Revision: D42380451

Pulled By: mthrok

fbshipit-source-id: 0569a32be576042ab419b363e694fe7d2db1feb0",moto,855818+mthrok@users.noreply.github.com,['torchaudio/_internal/module_utils.py'],False,6,1,2023
d6dbe03f4073749bf2cfd950df58ed4ad8f19341,"Reduce the sample rate of some tests (#2963)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2963

Phaser batch consistency test takes longer than the rest.
Change the sample rate from 44100 to 8000.

Reviewed By: hwangjeff

Differential Revision: D42379064

fbshipit-source-id: 2005b833c696bb3c2bb1d21c38c39e6163d81d53",Moto Hira,moto@meta.com,['test/torchaudio_unittest/functional/batch_consistency_test.py'],False,6,1,2023
5e75c8e803e623481e2e76ba93444301d498be54,"Rename generator to vocoder in HiFiGAN model and factory functions (#2955)

Summary:
The generator part of HiFiGAN model is a vocoder which converts mel spectrogram to waveform. It makes more sense to name it as vocoder for better understanding.

Pull Request resolved: https://github.com/pytorch/audio/pull/2955

Reviewed By: carolineechen

Differential Revision: D42348864

Pulled By: nateanl

fbshipit-source-id: c45a2f8d8d205ee381178ae5d37e9790a257e1aa",Zhaoheng Ni,zni@fb.com,"['docs/source/prototype.models.rst', 'test/torchaudio_unittest/prototype/hifi_gan/hifi_gan_test_impl.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/hifi_gan.py', 'torchaudio/prototype/pipelines/hifigan_pipeline.py']",False,5,1,2023
5428e28399af90494baeef08bf9523909e3d13cb,"Fix filtering function fallback mechanism (#2953)

Summary:
lfilter, overdrive have faster implementation written in C++. If they are not available, torchaudio is supposed to fall back on Python-based implementation.

The original fallback mechanism relied on error type and messages from PyTorch core, which has been changed.

This commit updates it for more proper fallback mechanism.

Pull Request resolved: https://github.com/pytorch/audio/pull/2953

Reviewed By: hwangjeff

Differential Revision: D42344893

Pulled By: mthrok

fbshipit-source-id: 18ce5c1aa1c69d0d2ab469b0b0c36c0221f5ccfd",moto,855818+mthrok@users.noreply.github.com,['torchaudio/functional/filtering.py'],False,5,1,2023
f70b970ab11694c035db0062df6b60f2550c1d43,"Use PyBind for binding utilities (#2956)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2956

Merge utility binding

This commit updates the utility binding, so that we can use `is_module_available()`
for checking the existence of extension modules.

To ensure the existence of module, this commit migrates the binding of utility functions
to PyBind11.

Going forward, we should use TorchBind for ops that we want to support TorchScript,
otherwise default to PyBind11. (PyBind has advantage of not copying strings.)

Reviewed By: hwangjeff

Differential Revision: D42355992

fbshipit-source-id: 4c71d65b24a0882a38a80dc097d45ba72b4c4a6b",Moto Hira,moto@meta.com,"['torchaudio/_extension.py', 'torchaudio/csrc/pybind/pybind.cpp', 'torchaudio/csrc/utils.cpp']",False,5,1,2023
54e5c859433c27abedeaacf789afdf1bc659b750,"Add HiFiGAN bundle (#2921)

Summary:
Closes [T138011314](https://www.internalfb.com/intern/tasks/?t=138011314)
## Description
- Add  bundle `HIFIGAN_GENERATOR_V3_LJSPEECH` to prototypes. The bundle contains pre-trained HiFiGAN generator weights from the [original HiFiGAN publication](https://github.com/jik876/hifi-gan#pretrained-model), converted slightly to fit our model
- Add tests
  - unit tests checking that vocoder and mel-transform implementations in the bundle give the same results as the original ones. Part of the original HiFiGAN code is ported to this repo to enable these tests
  - integration test checking that waveform reconstructed from mel spectrogram by the bundle is close enough to the original
- Add docs

Pull Request resolved: https://github.com/pytorch/audio/pull/2921

Reviewed By: nateanl, mthrok

Differential Revision: D42034761

Pulled By: sgrigory

fbshipit-source-id: 8b0dadeed510b3c9371d6aa2c46ec7d8378f6048",Grigory Sizov,grigorysizov@fb.com,"['docs/source/prototype.pipelines.rst', 'test/integration_tests/prototype/hifi_gan_pipeline_test.py', 'test/torchaudio_unittest/prototype/hifi_gan/hifi_gan_test_impl.py', 'test/torchaudio_unittest/prototype/hifi_gan/original/README.md', 'test/torchaudio_unittest/prototype/hifi_gan/original/env.py', 'test/torchaudio_unittest/prototype/hifi_gan/original/meldataset.py', 'test/torchaudio_unittest/prototype/hifi_gan/original/models.py', 'test/torchaudio_unittest/prototype/hifi_gan/original/utils.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/hifigan_pipeline.py']",False,5,1,2023
bf085b1ff7c1d254fcfdc3059ea03aa5bd955262,"Make fill_buffer a public API and move the impl to C++ (#2954)

Summary:
Currently, when iterating media data with StreamReader, using the for-loop is the only way with public API.

This does not support usecases like ""Fetch one chunk after seek"" well.

```python
s = StreamReader
s.add_audio_stream(...)
s.seek(10)
chunk = None
for chunk, in s.stream():
    break
```

This commit make the `fill_buffer` used in iterative method public API so that one acn do

```python
s.seek(10)
s.fill_buffer()
chunk, = s.pop_chunks()
```

 ---

Also this commit moves the implementation to C++ so that it reduces the number of FFI boundary crossing.
This improves the performance when the iteration is longer.

AVI (generated with `ffmpeg -hide_banner -f lavfi -t ${duration} -i testsrc ""${file}.avi""`)

| Video Duration [sec] | Original [msec] | Fill Buffer C++ | One Go  (reference) |
|----------------------|----------|-----------------|--------|
|                    1 |       18 |            18.4 |   16.6 |
|                    5 |       44 |            42.6 |   35.1 |
|                   10 |     75.3 |            74.4 |   60.9 |
|                   30 |      200 |             195 |    158 |
|                   60 |      423 |             382 |    343 |

MP4 (generated with `ffmpeg -hide_banner -f lavfi -t ${duration} -i testsrc ""${file}.mp4""`)

| Video Duration [sec] | Original [msec] | Fill Buffer C++ | One Go |
|----------------------|-----------------|-----------------|--------|
|                    1 |            18.7 |            18.1 |   10.3 |
|                    5 |            42.2 |            40.6 |   25.2 |
|                   10 |            73.9 |            71.8 |   43.6 |
|                   30 |             202 |             194 |    116 |
|                   60 |             396 |             386 |    227 |
* Original (Python implementation)

```python
r = StreamReader(src)
r.add_video_stream(1, decoder_option={""threads"": ""1""})
for chunk, in r.stream():
    pass
```

* This (C++)

```python
r = StreamReader(src)
r.add_video_stream(1, decoder_option={""threads"": ""1""})
for chunk, in r.stream():
    pass
```

* Using `process_all_packets` (process all in one go)

```python
r = StreamReader(src)
r.add_video_stream(1, decoder_option={""threads"": ""1""})
r.process_all_packets()
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2954

Reviewed By: carolineechen

Differential Revision: D42349446

Pulled By: mthrok

fbshipit-source-id: 9e4e37923e46299c3f43f4ad17a2a2b938b2b197",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/io/_stream_reader.py']",False,4,1,2023
7f778fc9a798c09ef93dbcd40b12582b390c8e41,"Add multithread options to docstring and default to single thread (#2949)

Summary:
One can pass ""threads"" and ""thread_type"" to `decoder_option` of StreamReaader to change the multithreading configuration.

These affects the timing that decoder starts emitting the decoded frames. i.e. how many packets at minimum have to be processed before the first frame is decoded.

Overall, multithreading in decoder does not improve the performance.
(One possible reason is because the design of StreamReader, ""decode few frames then fetch them"", does not suited to saturate the decoder with incoming packets.)

num_threads=1 seems to exhibit overall good performance/resource balance.

![Decoding time over threading](https://user-images.githubusercontent.com/855818/210380632-1ab72608-76aa-4445-808a-50cef215dbac.png)
![Decoding time over threading (1)](https://user-images.githubusercontent.com/855818/210380639-ec5574b0-9087-4f22-84a4-a2c0ee632dd9.png)
(Tested on 320x240 25 FPPS, YUV420P videos generated with `ffmpeg -f lavfi -t ""${duration}"" -i testsrc -pix_fmt ""yuv420p""`)

For this reason, we default to single thread execution in StreamReader.
closes https://github.com/pytorch/audio/issues/2855

Follow-up: Apply similar change to encoder option in StreamWriter.

Pull Request resolved: https://github.com/pytorch/audio/pull/2949

Reviewed By: carolineechen

Differential Revision: D42343951

Pulled By: mthrok

fbshipit-source-id: aea234717d37918f99fc24f575dbcfe7dcae1e80",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/io/_stream_reader.py']",False,4,1,2023
d5b5aba6d115913c5d4869423b582d047c3f75bf,"Use CCache if available (#2866)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2866

Reviewed By: carolineechen

Differential Revision: D42349474

Pulled By: mthrok

fbshipit-source-id: 31455184031fff52719ef829e40bb1e09e11b0e7",moto,855818+mthrok@users.noreply.github.com,['CMakeLists.txt'],False,4,1,2023
10787feeda9daff67c975379c8eb6de710819032,"Guard invocation of cuda_version (#2952)

Summary:
Currently, importing TorchAudio triggers a check of the CUDA version it was compiled with, which in turn calls `torch.ops.torchaudio.cuda_version()`. This function is available only if `libtorchaudio` is available; developers, however, may want to import TorchAudio regardless of its availability. To allow for such usage, this PR adds code that bypasses the check if `libtorchaudio` is not available.

Pull Request resolved: https://github.com/pytorch/audio/pull/2952

Reviewed By: mthrok

Differential Revision: D42336396

Pulled By: hwangjeff

fbshipit-source-id: 465353cf46b218c0bcdf51ca5cf0b83c93185f39",hwangjeff,jeffhwang@meta.com,['torchaudio/_extension.py'],False,4,1,2023
c2b62ae8de76d050751679155dc3df1438f85998,"Add preemphasis and deemphasis transforms (#2935)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2935

Reviewed By: mthrok

Differential Revision: D42302275

Pulled By: hwangjeff

fbshipit-source-id: d995d335bf17d63d3c1dda77d8ef596570853638",Jeff Hwang,iamjeffhwang@gmail.com,"['docs/source/prototype.transforms.rst', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'torchaudio/prototype/transforms/__init__.py', 'torchaudio/prototype/transforms/_transforms.py']",False,4,1,2023
d0dca11546567bc96886e9965224e4e6681170ba,"Refactor YUV handling functions (#2946)

Summary:
* Split `convert_[yuv420p|nv12|nv12_cuda]` functions into allocation
and data write functions.
* Merge the `get_[interlaced|planar]_image_buffer` functions into
`get_buffer` and `get_image_buffer`.
* Disassemble `convert_XXX_image` helper functions.

Pull Request resolved: https://github.com/pytorch/audio/pull/2946

Reviewed By: nateanl

Differential Revision: D42287501

Pulled By: mthrok

fbshipit-source-id: b8dd0d52fd563a112a16887b643bf497f77dfb80",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.h']",False,30,12,2022
276dcd690a023470742aa00dd67035cb3fb303a0,"Throw RuntimeError if path not found in LibriMix dataset (#2944)

Summary:
The `root` path can be confusing to users without reading the document. The PR adds runtime error for a better understanding.

Pull Request resolved: https://github.com/pytorch/audio/pull/2944

Reviewed By: mthrok

Differential Revision: D42281034

Pulled By: nateanl

fbshipit-source-id: 6e5f4bfb118583d678d6b7a2565ef263fe8e4a5a",Zhaoheng Ni,zni@fb.com,['torchaudio/datasets/librimix.py'],False,30,12,2022
cc0d1e0b00ffc8f6cd6952a7b2ae54f0604c044e,"Refactor and optimize yuv420p and nv12 processing (#2945)

Summary:
This commit refactors and optimizes functions that converts AVFrames of `yuv420p` and `nv12` into PyTorch's Tensor.
The performance is improved about 30%.

1. Reduce the number of intermediate Tensors allocated.
2. Replace 2 calls to `repeat_interleave` with `F::interpolate`.

 * (`F::interpolate` is about 5x faster than `repeat_interleave`. )
    <details><summary>code</summary>

    ```bash
    #!/usr/bin/env bash

    set -e

    python -c """"""
    import torch
    import torch.nn.functional as F

    a = torch.arange(49, dtype=torch.uint8).reshape(7, 7).clone()
    val1 = a.repeat_interleave(2, -1).repeat_interleave(2, -2)
    val2 = F.interpolate(a.view((1, 1, 7, 7, 1)), size=[14, 14, 1], mode=\""nearest\"")
    print(torch.sum(torch.abs(val1 - val2[0, 0, :, :, 0])))
    """"""

    python3 -m timeit \
            --setup """"""
    import torch

    a = torch.arange(49, dtype=torch.uint8).reshape(7, 7).clone()
    """""" \
            """"""
    a.repeat_interleave(2, -1).repeat_interleave(2, -2)
    """"""

    python3 -m timeit \
            --setup """"""
    import torch
    import torch.nn.functional as F

    a = torch.arange(49, dtype=torch.uint8).reshape(7, 7).clone()
    """""" \
            """"""
    F.interpolate(a.view((1, 1, 7, 7, 1)), size=[14, 14, 1], mode=\""nearest\"")
    """"""
    ```

    </details>

    ```
    tensor(0)
    10000 loops, best of 5: 38.3 usec per loop
    50000 loops, best of 5: 7.1 usec per loop
    ```

## Benchmark Result

<details><summary>code</summary>

```bash
#!/usr/bin/env bash

set -e

mkdir -p tmp

for ext in avi mp4; do
    for duration in 1 5 10 30 60; do
        printf ""Testing ${ext} ${duration} [sec]\n""

        test_data=""tmp/test_${duration}.${ext}""
        if [ ! -f ""${test_data}"" ]; then
            printf ""Generating test data\n""
            ffmpeg -hide_banner -f lavfi -t ${duration} -i testsrc ""${test_data}"" > /dev/null 2>&1
        fi

        python -m timeit \
               --setup=""from torchaudio.io import StreamReader"" \
               """"""
r = StreamReader(\""${test_data}\"")
r.add_basic_video_stream(frames_per_chunk=-1, format=\""yuv420p\"")
r.process_all_packets()
r.pop_chunks()
""""""
    done
done
```

</details>

![Time to decode AVI file](https://user-images.githubusercontent.com/855818/210008881-8cc83f18-0e51-46e3-afe9-a5ff5dff041e.png)

<details><summary>raw data</summary>

Video Type - AVI
Duration | Before | After
-- | -- | --
1 | 10.3 | 6.29
5 | 44.3 | 28.3
10 | 89.3 | 56.9
30 | 265 | 185
60 | 555 | 353
</details>

![Time to decode MP4 file](https://user-images.githubusercontent.com/855818/210008891-c4546c52-43d7-49d0-8eff-d866ad627129.png)

<details><summary>raw data</summary>

Video Type - MP4
Duration | Before | After
-- | -- | --
1 | 15.3 | 10.5
5 | 62.1 | 43.2
10 | 124 | 83.8
30 | 380 | 252
60 | 721 | 511
</details>

Pull Request resolved: https://github.com/pytorch/audio/pull/2945

Reviewed By: carolineechen

Differential Revision: D42283269

Pulled By: mthrok

fbshipit-source-id: 59840f943ff516b69ab8ad35fed7104c48a0bf0c",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp']",False,30,12,2022
9f57951af2bf1128e199a958a68bff4cdb730b68,"Add subtractive synthesis tutorial (#2934)

Summary:
Artifact: [subtractive_synthesis_tutorial](https://output.circle-artifacts.com/output/job/4c1ce33f-834d-48e0-ba89-2e91acdcb572/artifacts/0/docs/tutorials/subtractive_synthesis_tutorial.html)

Pull Request resolved: https://github.com/pytorch/audio/pull/2934

Reviewed By: carolineechen

Differential Revision: D42284945

Pulled By: mthrok

fbshipit-source-id: d255b8e8e2a601a19bc879f9e1c38edbeebaf9b3",moto,855818+mthrok@users.noreply.github.com,"['docs/source/index.rst', 'examples/tutorials/subtractive_synthesis_tutorial.py']",False,30,12,2022
09468c99146bc35cb29c8d6b8c9aee1bce0c4882,"Fix confusing wording in the documentation (#2937)

Summary:
I have spent 2 hours because I read the documentation wrongly and trying to figure out why the I couldn't read the data from the dataset. The initial phrase was very confusing.

Pull Request resolved: https://github.com/pytorch/audio/pull/2937

Reviewed By: mthrok

Differential Revision: D42280738

Pulled By: nateanl

fbshipit-source-id: a48b9bc27d44ca8106bd56f805294a5a0e3ede1b",TruscaPetre,37754402+TruscaPetre@users.noreply.github.com,['torchaudio/datasets/librimix.py'],False,29,12,2022
7b5317b3e983e8c5d41a95a8ac78951f52017a1a,"Refactor CMake modules (#2930)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2930

Reviewed By: carolineechen, nateanl

Differential Revision: D42280966

Pulled By: mthrok

fbshipit-source-id: f9d5f1dc7c1a62d932fb2020aafb63734f2bf405",moto,855818+mthrok@users.noreply.github.com,"['CMakeLists.txt', 'cmake/TorchAudioHelper.cmake', 'third_party/flashlight-text/CMakeLists.txt', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/CMakeLists.txt', 'torchaudio/csrc/sox/CMakeLists.txt']",False,29,12,2022
5ee34516083bcc4ad879dc696eee3b6129bc323c,"Refactor buffer helper functions (#2943)

Summary:
* move helper functions to `detail` namespace.
* move helper functions out of `buffer.h`

Pull Request resolved: https://github.com/pytorch/audio/pull/2943

Reviewed By: carolineechen

Differential Revision: D42271652

Pulled By: mthrok

fbshipit-source-id: abbfc8e8bac97d4eeb34221d4c20763477bd982e",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/common.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp']",False,29,12,2022
456512457d06fe7067d23ff735dbbe247b80874b,"Refactor a part of convert_image (#2940)

Summary:
Refactor the two helper functions that convert AVFrame to torch::Tensor into separate buffer allocation and data copy.

Pull Request resolved: https://github.com/pytorch/audio/pull/2940

Reviewed By: carolineechen

Differential Revision: D42247915

Pulled By: mthrok

fbshipit-source-id: 2f504d48674088205e6039e8aadd8856b3fe5eee",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/stream_reader/buffer.cpp'],False,28,12,2022
4699ef212b27b00899628f71defdb41d3b3e3a83,"Refactor Buffer implementation in StreamReader (#2939)

Summary:
The `Buffer` class is responsible for converting `AVFrame` into `torch::Tensor` and storing the frames in accordance to `frames_per_chunk` and `buffer_chunk_size`.

There are four operating modes of Buffer; [audio|video] x [chunked|unchunked]. Audio and video have a separate class implementations, but the behavior of chunked/unchunked depends on `frames_per_chunk<0` or not.

Chunked mode is where frames should be returned by chunk of a unit number frames, while unchunked mode is where frames are returned as-is.

When frames are accumulated, in chunked mode, old frames are dropped, while in unchunked mode all the frames are retained.

Currently, the underlying buffer implementations are the same `std::dequeu<torch::Tensor>`. As we plan to make chunked-mode behavior more efficient by changing the underlying buffer container, it will be easier if the unchuked-mode behavior is kept as-is as a separate class.

This commit makes the following changes.

* Change `Buffer` class into pure virtual class (interface).
* Split `AudioBuffer` into` UnchunkedAudioBuffer` and `ChunkedAudioBuffer`.
* Split `VideoBuffer` into` UnchunkedVideoBuffer` and `ChunkedVideoBuffer`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2939

Reviewed By: carolineechen

Differential Revision: D42247509

Pulled By: mthrok

fbshipit-source-id: 7363e442a5b2db5dcbaaf0ffbfa702e088726d1b",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/chunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer/unchunked_buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp']",False,27,12,2022
69e8dbb21d66120a72c9e0b076c017dde1a0da74,"Add filter_waveform (#2928)

Summary:
This commit adds ""filter_waveform"" prototype function.

This function can apply non-stationary filters across the time.
It also performs cropping at the end to compensate the delay introduced by filtering.
The figure bellow illustrates this.

See [subtractive_synthesis_tutorial](https://output.circle-artifacts.com/output/job/5233fda9-dadb-4710-9389-7e8ac20a062f/artifacts/0/docs/tutorials/subtractive_synthesis_tutorial.html) for example usages.

![figure](https://download.pytorch.org/torchaudio/doc-assets/filter_waveform.png)

Pull Request resolved: https://github.com/pytorch/audio/pull/2928

Reviewed By: carolineechen

Differential Revision: D42199955

Pulled By: mthrok

fbshipit-source-id: e822510ab8df98393919bea33768f288f4d661b2",moto,855818+mthrok@users.noreply.github.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py']",False,22,12,2022
1706a72fa5762a1666896457426d6aa703b7f609,"Extract libsox integration from libtorchaudio (#2929)

Summary:
This commit makes the following changes to the C++ library organization
- Move sox-related feature implementations from `libtorchaudio` to `libtorchaudio_sox`.
- Remove C++ implementation of `is_sox_available` and `is_ffmpeg_available` as it is now sufficient to check the existence of `libtorchaudio_sox` and `libtorchaudio_ffmpeg` to check the availability. This makes `libtorchaudio_sox` and `libtorchaudio_ffmpeg` independent from `libtorchaudio`.
- Move PyBind11-based bindings (`_torchaudio_sox`, `_torchaudio_ffmpeg`) into `torchaudio.lib` so that the built library structure is less cluttered.

Background:
Originally, when the `libsox` was the only C++ extension and `libtorchaudio` was supposed to contain all the C++ code.
The things are different now. We have a bunch of C++ extensions and we need to make the code/build structure more modular.

The new `libtorchaudio_sox` contains the implementations and `_torchaudio_sox` contains the PyBin11-based bindings.

Pull Request resolved: https://github.com/pytorch/audio/pull/2929

Reviewed By: hwangjeff

Differential Revision: D42159594

Pulled By: mthrok

fbshipit-source-id: 1a0fbca9e4143137f6363fc001b2378ce6029aa7",moto,855818+mthrok@users.noreply.github.com,"['cmake/TorchAudioHelper.cmake', 'test/torchaudio_unittest/backend/sox_io/load_test.py', 'tools/setup_helpers/extension.py', 'torchaudio/_extension.py', 'torchaudio/_internal/module_utils.py', 'torchaudio/backend/sox_io_backend.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/pybind/pybind.cpp', 'torchaudio/csrc/sox/pybind/pybind.cpp', 'torchaudio/csrc/utils.cpp', 'torchaudio/csrc/utils.h', 'torchaudio/io/_compat.py', 'torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py', 'torchaudio/models/decoder/_ctc_decoder.py', 'torchaudio/sox_effects/sox_effects.py']",False,21,12,2022
c6bc65fd8c16e7d89887397f9e196cbdedf89a1b,"Fallback to best_effort_timestamp in case of invalid PTS (#2916)

Summary:
If the input video has invalid PTS, the current precise seek fails except when seeking into t=0.

This commit updates the discard mechanism to fallback to `best_effort_timestamp` in such cases.

`best_effort_timestamp` is just the number of frames went through decoder starting from the beginning of the file.

This means if the input file is very long, but seeking towards the end of the file, the StreamReader still decodes all the frames.

For videos with valid PTS, `best_effort_timestamp` should be same as `pts`. [[src](https://ffmpeg.org/doxygen/4.1/decode_8c.html#a8d86329cf58a4adbd24ac840d47730cf)]

Pull Request resolved: https://github.com/pytorch/audio/pull/2916

Reviewed By: YosuaMichael

Differential Revision: D42170204

Pulled By: mthrok

fbshipit-source-id: 80c04dc376e0f427d41eb9feb44c251a1648a998",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/assets/RATRACE_wave_f_nm_np1_fr_goo_37.avi', 'test/torchaudio_unittest/assets/README.md', 'test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp']",False,20,12,2022
5807078c3c49deab4fbd06089f46f7a1201ac42f,"Split extract_archive into dedicated functions. (#2927)

Summary:
`extra_archive` in `datasets.utils` does not distinguish the input type, and blindly treats it as tar, then zip in case of failure.

This is an anti-pattern. All the dataset implementations know which archive type the downloaded files are.

This commit splits extract_archive function into dedicated functions, and make each dataset use the correct one.

Pull Request resolved: https://github.com/pytorch/audio/pull/2927

Reviewed By: carolineechen

Differential Revision: D42154069

Pulled By: mthrok

fbshipit-source-id: bc46cc2af26aa086ef49aa1f9a94b6dedb55f85e",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/datasets/cmuarctic.py', 'torchaudio/datasets/dr_vctk.py', 'torchaudio/datasets/gtzan.py', 'torchaudio/datasets/librilight_limited.py', 'torchaudio/datasets/librispeech.py', 'torchaudio/datasets/libritts.py', 'torchaudio/datasets/ljspeech.py', 'torchaudio/datasets/musdb_hq.py', 'torchaudio/datasets/quesst14.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/tedlium.py', 'torchaudio/datasets/utils.py', 'torchaudio/datasets/vctk.py', 'torchaudio/datasets/voxceleb1.py', 'torchaudio/datasets/yesno.py']",False,19,12,2022
d744f33f6902e585846dd19440efdf43536ce109,"Remove deprecated/unused functions from datasets.utils (#2926)

Summary:
`stream_url`, `download_url` and `validate_file` are not used and not listed in documentation (`download_url` is marked as deprecated) so remove them.

This will also fix the failing bandit workflow.

Pull Request resolved: https://github.com/pytorch/audio/pull/2926

Reviewed By: carolineechen

Differential Revision: D42153484

Pulled By: mthrok

fbshipit-source-id: 0fccdc7b7e0e40db8046e12f46eb68de57d838ca",moto,855818+mthrok@users.noreply.github.com,['torchaudio/datasets/utils.py'],False,19,12,2022
9c4f71a62adcfb1556a0bdd352cd4ed95c15b69d,"Add filter design tutorial (#2894)

Summary:
Adds filter design tutorial, which demonstrates `sinc_impulse_response` and `frequency_impulse_response`.

Example:
 - [filter_design_tutorial](https://output.circle-artifacts.com/output/job/bd22c615-9215-4b17-a52c-b171a47f646c/artifacts/0/docs/tutorials/filter_design_tutorial.html)

Pull Request resolved: https://github.com/pytorch/audio/pull/2894

Reviewed By: xiaohui-zhang

Differential Revision: D42117658

Pulled By: mthrok

fbshipit-source-id: f7dd04980e8557bb6f0e0ec26ac2c7f53314ea16",moto,855818+mthrok@users.noreply.github.com,"['docs/source/index.rst', 'examples/tutorials/filter_design_tutorial.py']",False,17,12,2022
e6bebe6af06109af30c2f728c3d4ed8fc8902dcd,"Rename resampling_method options (#2922)

Summary:
resolves https://github.com/pytorch/audio/issues/2891

Rename `resampling_method` options to more accurately describe what is happening. Previously the methods were set to `sinc_interpolation` and `kaiser_window`, which can be confusing as both options actually use sinc interpolation methodology, but differ in the window function used. As a result, rename `sinc_interpolation` to `sinc_interp_hann` and `kaiser_window` to `sinc_interp_kaiser`. Using an old option will throw a warning, and those options will be deprecated in 2 released. The numerical behavior is unchanged.

Pull Request resolved: https://github.com/pytorch/audio/pull/2922

Reviewed By: mthrok

Differential Revision: D42083619

Pulled By: carolineechen

fbshipit-source-id: 9a9a7ea2d2daeadc02d53dddfd26afe249459e70",Caroline Chen,carolinechen@fb.com,"['examples/tutorials/audio_resampling_tutorial.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'test/torchaudio_unittest/transforms/transforms_test.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,16,12,2022
3cf266a3146232441a1ccd664ff9252c6a1d9fd2,"Bump version to match PyTorch (#2924)

Summary:
Updating the version to 2.0.0 to match PyTorch core

Pull Request resolved: https://github.com/pytorch/audio/pull/2924

Reviewed By: carolineechen

Differential Revision: D42098238

Pulled By: mthrok

fbshipit-source-id: 19cb290e493293d1db4211f9bfcdcdffa3e96e45",moto,855818+mthrok@users.noreply.github.com,['version.txt'],False,16,12,2022
f0986b6044c43ac2cb17afb42352fadd43c5deb2,"Update version matrix for 0.13.1 release (#2923)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2923

Reviewed By: carolineechen

Differential Revision: D42090164

Pulled By: mthrok

fbshipit-source-id: 4816d9922cc54f42ad2137a3bba1a61f3be68f57",moto,855818+mthrok@users.noreply.github.com,['README.md'],False,16,12,2022
0be8423deb9c3546894f9082f8f7bdea265afa7b,"Switch to Nova MacOS Wheel (#2907)

Summary:
Switch to Nova MacOS and M1 Wheels. This PR is a step in migrating from CircleCI to the Nova workflow.

- [x] Disable the CircleCI builds for MacOS Wheel.
- [x] Disable the CircleCI builds for M1 Wheel.
- [x] Enable the Nova workflow for MacOS Wheel.
- [x] Enable the Nova workflow for M1 Wheel.

Pull Request resolved: https://github.com/pytorch/audio/pull/2907

Reviewed By: osalpekar, mthrok

Differential Revision: D42040965

Pulled By: DanilBaibak

fbshipit-source-id: b87f028cf5686bf97265109591fb0a8c1190324c",DanilBaibak,danil.baibak@gmail.com,"['.circleci/config.yml', '.circleci/regenerate.py', '.github/workflows/build-m1-binaries.yml', '.github/workflows/build-wheels-m1.yml', '.github/workflows/build_wheels_macos.yml']",False,15,12,2022
392481f07412101c21959fc1ed0298b449d9912e,"Return version from cuda version check (#2919)

Summary:
Return version from cuda version check so that we can display it in the test details

Pull Request resolved: https://github.com/pytorch/audio/pull/2919

Reviewed By: mthrok

Differential Revision: D42001252

Pulled By: atalman

fbshipit-source-id: 0d8fc3812a13fe098cdf8e0f3df7b66161ba3f95",atalman,atalman@fb.com,['torchaudio/_extension.py'],False,13,12,2022
ad596b37ac7d5187e49b85f0d16d7c175c129748,"Switch to nova Linux Wheel build (#2896)

Summary:
Switch to Nova Linux Wheel build.

- [x] Disable the CircleCI builds for Linux Wheel.
- [x] Enable the Nova workflow for Linux Wheel.

~The Linux Wheel Python3.8 build has been kept because it is a dependency for the `docstring_parameters_sync` job.~ As Omkar pointed out, Docstring Parameters Sync also runs on GHA (https://github.com/pytorch/audio/actions/runs/3638187635/jobs/6140090209). So, we completely switched to the Nova Linux Wheel build.

Pull Request resolved: https://github.com/pytorch/audio/pull/2896

Reviewed By: mthrok

Differential Revision: D41994993

Pulled By: DanilBaibak

fbshipit-source-id: 2bafdbe1b62ef8fa194ce96f4d4667a3ed3dc44f",DanilBaibak,danil.baibak@gmail.com,"['.circleci/config.yml', '.circleci/regenerate.py', '.github/workflows/build_wheels_linux.yml']",False,13,12,2022
cbd35438b3f55e10b82f32cd4543c8ea34f3b77a,"Update precise seek behavior for t=0 (#2915)

Summary:
It was reported that when videos with invalid PTS values are fed to StreamReader, StreamReader returns only the last frame.

https://github.com/pytorch/vision/blob/677fc939b21a8893f07db4c1f90482b648b6573f/test/assets/videos/RATRACE_wave_f_nm_np1_fr_goo_37.avi

```
import torchaudio

src = ""RATRACE_wave_f_nm_np1_fr_goo_37.avi""

streamer = torchaudio.io.StreamReader(src=src)
streamer.add_basic_video_stream(frames_per_chunk=-1)
streamer.process_all_packets()
video, = streamer.pop_chunks()

print(video.size(0))  # prints 1, but there are more than 70 frames
```

The reason why all the frames are not returned is due to invalid PTS values. All the frames's PTS values are `-9223372036854775808` so the internal mechanism discards them.

The reason why the last frame is output is because when entering drain mode, the discard value of -1 is used, which is interpreted as no discard.

For the second issue, the discard behavior should be consistent across regular decoding and drain mode.

For the first issue, although the normal behavior is not guaranteed for such invalid input, we can support the case where one reads video from start (or when one seeks into t=0)

 ---

This commits make the following changes to address the above two.

1. Define the discard_before_pts attribtue on StreamProcessor, so that StreamProcessor is aware of the discard behavior without being told by StreamReader, and its behavior is consistent between regular decoding and drain.

   This gets rid of the discard_before_pts computation that is currently happening at the every time a frame is processed, so this should improve the peformance a bit.

2. Change the meaning of discard_before_pts, so that when it's 0, no discard happens. With this change, the negative value is not necessary so we put it a UB status.

Note:
   Even with those changes seeking videos with invalid PTS is not plausible, client codes can implement a fallback which decodes frames first and discard undesired ones.

Pull Request resolved: https://github.com/pytorch/audio/pull/2915

Reviewed By: nateanl

Differential Revision: D41957784

Pulled By: mthrok

fbshipit-source-id: 2dafdbada5aa33bfc81c986306f80642ba6277df",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h']",False,12,12,2022
123c7319d2e3e7dd9e1b22a4b1c562bd3a82e3b9,"Update PR labels (#2912)

Summary:
replace ""example"" primary label with ""tutorial"" and ""recipe""

cc pytorch/team-audio-core

Pull Request resolved: https://github.com/pytorch/audio/pull/2912

Reviewed By: nateanl, mthrok

Differential Revision: D41897772

Pulled By: carolineechen

fbshipit-source-id: e20540c6f302b5dcc56663a2c074b14a48e4d3e1",Caroline Chen,carolinechen@fb.com,['.github/process_commit.py'],False,11,12,2022
54a664b94cf9fff03ff1769f8abcbd6955924e16,"Fix type of arguments in torchaudio.io classes (#2913)

Summary:
The `src` or `dst` argument can be `str` or `file-like object`. Setting it to `str` in type annotation will confuse users that it only accepts `str` type.

Pull Request resolved: https://github.com/pytorch/audio/pull/2913

Reviewed By: mthrok

Differential Revision: D41896668

Pulled By: nateanl

fbshipit-source-id: 1446a9f84186a0376cdbe4c61817fae4d5eaaab4",Zhaoheng Ni,zni@fb.com,"['torchaudio/io/_compat.py', 'torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py']",False,10,12,2022
9912e54df0522915f0f15dd637636327301b9d75,"Update model documentation structure (#2902)

Summary:
Currently, the documentation page for `torchaudio.models` have separate sections for model definitions and factory functions.

The relationships between models and factory functions are not immediately clear.

This commit moves the list of factory functions to the list of models.

After:
 - https://output.circle-artifacts.com/output/job/242a9521-7460-4043-895b-9995bf5093b5/artifacts/0/docs/generated/torchaudio.models.Wav2Vec2Model.html

<img width=""1171"" alt=""Screen Shot 2022-12-08 at 8 41 03 PM"" src=""https://user-images.githubusercontent.com/855818/206603743-74a6e368-c3cf-4b87-b854-518a95893f06.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2902

Reviewed By: carolineechen

Differential Revision: D41897800

Pulled By: mthrok

fbshipit-source-id: a3c01d28d80e755596a9bc37c951960eb84870b9",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/model_class.rst', 'docs/source/models.rst', 'torchaudio/models/_hdemucs.py', 'torchaudio/models/conv_tasnet.py', 'torchaudio/models/rnnt.py', 'torchaudio/models/wav2vec2/model.py']",False,10,12,2022
901628126abf6af4f61f6a08d0db7ed22c86fbb1,"Fix integration test for WAV2VEC2_ASR_LARGE_LV60K_10M (#2910)

Summary:
After https://github.com/pytorch/audio/issues/2873, the pre-trained Wav2Vec2 models with larger datasets can get better performances. The PR fixes the integration test of bundle `WAV2VEC2_ASR_LARGE_LV60K_10M` which predicts the word `CURIOUSITY` to `CURIOUSSITY` before but now to `CURIOUSITY` correctly.

Pull Request resolved: https://github.com/pytorch/audio/pull/2910

Reviewed By: mthrok

Differential Revision: D41881919

Pulled By: nateanl

fbshipit-source-id: 236fd00b983a5205c731f3efa31033a6b8257cab",Zhaoheng Ni,zni@fb.com,['test/integration_tests/wav2vec2_pipeline_test.py'],False,9,12,2022
eb8b1bda79ffef2ff219bb85f7445f5ad95e2c74,"Update author and maintainer info (#2911)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2911

Reviewed By: carolineechen

Differential Revision: D41887854

Pulled By: mthrok

fbshipit-source-id: eb91773ec67b4cda2d70733df450956d83742509",moto,855818+mthrok@users.noreply.github.com,['setup.py'],False,9,12,2022
90c456def12ce58219568d692537eed663b12bef,"Fix duplicated memory allocation in StreamWriter (#2906)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2906

The correct way to create AVFormatContext* for output is to pass an address of an uninitialized *AVFormatContext struct to `avformat_alloc_output_context2` function.

The current code pre-allocates AVFormatContext* with `avformat_alloc_context`, then this allocated object is lost inside of `avformat_alloc_output_context2`.

Reviewed By: xiaohui-zhang

Differential Revision: D41865685

fbshipit-source-id: 9a9dc83b5acfe9b450f191fe716c85ebb5a5d842",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_writer/stream_writer_wrapper.cpp'],False,9,12,2022
3518df48fbfe0fc0057777dca39534a3373a5010,"Fix wrong frame allocation in StreamWriter (#2905)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2905

In StreamWriter, if the tensor format is different from the encoding format, then a FilterGraph object is automatically inserted to convert the format.

The FilterGraph object operates on AVFrames. The input AVFrame must be allocated by us, but the output AVFrames is filled by FilterGraph, thus no need to allocate it.

Now the output AVFrame is used as input to encoder regardless of whether FilterGraph was inserted. Thus the output AVFrame has to be manually allocated by us when FilterGraph is not used.

The current code flips this condition and incorrectly allocates AVFrame when FilterGraph is present and does not allocate otherwise.

This commit fix that.

Reviewed By: xiaohui-zhang

Differential Revision: D41866198

fbshipit-source-id: 40799c147dc8166a979ecfb58ed8e502539a6aed",Moto Hira,moto@meta.com,['torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp'],False,9,12,2022
ccda545c1f81d39692c93c8af33f80a86c1932df,"Toggle on/off ffmpeg test if needed (#2901)

Summary:
Toggle on/off ffmpeg test if needed
By default it ON, hence should not affect any current tests.
To toggle ON no change required.
To toggle OFF use:
```
smoke_test.py --no-ffmpeg
```

To be used when calling from builder currently. Since we do not install ffmpeg currently.

Pull Request resolved: https://github.com/pytorch/audio/pull/2901

Reviewed By: carolineechen, mthrok

Differential Revision: D41874976

Pulled By: atalman

fbshipit-source-id: c57b19f37c63a1f476f93a5211550e980e67d9c7",atalman,atalman@fb.com,['test/smoke_test/smoke_test.py'],False,9,12,2022
41d007b422b713e38150f87f4adbd6ab91d0ca9d,"Follow up on WavLM bundles (#2895)

Summary:
Addressed mthrok's comments in https://github.com/pytorch/audio/pull/2833:
- Moved model type from `_params` directly into the bundle definition. For now I defined model type as ""WavLM"" for WavLM bundles and ""Wav2Vec2"" for everything else. We can also distinguish between different Wav2Vec2 falvours - Hubert, VoxPopuli etc, but at the moment this won't imply any functional differences, so I didn't do it
- Expanded the title underline to match the title length

Pull Request resolved: https://github.com/pytorch/audio/pull/2895

Reviewed By: nateanl, mthrok

Differential Revision: D41799875

Pulled By: sgrigory

fbshipit-source-id: 0730d4f91ed60e900643bb74d6cccdd7aa5d7b39",Grigory Sizov,grigorysizov@fb.com,"['docs/source/models.rst', 'docs/source/pipelines.rst', 'torchaudio/models/wav2vec2/model.py', 'torchaudio/pipelines/_wav2vec2/impl.py']",False,8,12,2022
88927e843bfa49045e48bc45390b77e41ce53e21,"Fix docs warnings for conformer w2v2 (#2900)

Summary:
cc mthrok

Pull Request resolved: https://github.com/pytorch/audio/pull/2900

Reviewed By: mthrok

Differential Revision: D41839924

Pulled By: carolineechen

fbshipit-source-id: ba3ada7d04a86d99e08c9044de05a1c48b05d036",Caroline Chen,carolinechen@fb.com,['torchaudio/prototype/models/_conformer_wav2vec2.py'],False,8,12,2022
b5e4663a7971a3a6e86f749cacde5ff626400d32,"Add HiFi GAN Generator to prototypes (#2860)

Summary:
Part 1 of [T138011314](https://www.internalfb.com/intern/tasks/?t=138011314)

This PR ports the generator part of [HiFi GAN](https://arxiv.org/abs/2010.05646v2) from [the original implementation](https://github.com/jik876/hifi-gan/blob/4769534d45265d52a904b850da5a622601885777/models.py#L75)

Adds tests:
- Smoke tests for architectures V1, V2, V3
- Check that output shapes are correct
- Check that the model is torchscriptable and scripting doesn't change the output
- Check that our code's output matches the original implementation. Here I clone the original repo inside `/tmp` and import necessary objects from inside the test function.  On test teardown I restore `PATH`, but don't remove the cloned code, so that it can be reused on subsequent runs - let me know if removing it would be a better practice

There are no quantization tests, because the model consists mainly of `Conv1d` and `ConvTransposed1d`, and they are [not supported by dynamic quantization](https://pytorch.org/docs/stable/quantization.html)

Pull Request resolved: https://github.com/pytorch/audio/pull/2860

Reviewed By: nateanl

Differential Revision: D41433416

Pulled By: sgrigory

fbshipit-source-id: f135c560df20f5138f01e3efdd182621edabb4f5",Grigory Sizov,grigorysizov@fb.com,"['docs/source/prototype.models.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/prototype/hifi_gan/__init__.py', 'test/torchaudio_unittest/prototype/hifi_gan/hifi_gan_cpu_test.py', 'test/torchaudio_unittest/prototype/hifi_gan/hifi_gan_gpu_test.py', 'test/torchaudio_unittest/prototype/hifi_gan/hifi_gan_test_impl.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/hifi_gan.py']",False,8,12,2022
ba683bd15720eca413d0988301ac13cfa2a2413f,"Add feature badges to preemphasis and deemphasis functions (#2892)

Summary:
Adds feature badges to preemphasis and deemphasis functions

Pull Request resolved: https://github.com/pytorch/audio/pull/2892

Reviewed By: carolineechen

Differential Revision: D41830782

Pulled By: hwangjeff

fbshipit-source-id: 487ce9afa8dc8fe321aa9e02cc88bb1453985d39",hwangjeff,jeffhwang@meta.com,['torchaudio/prototype/functional/functional.py'],False,8,12,2022
29ecf7e8b11841ccf625831ad11e3680c0abf226,"Add additive noise transform (#2889)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2889

Reviewed By: xiaohui-zhang

Differential Revision: D41760084

Pulled By: hwangjeff

fbshipit-source-id: d2f5253e1fae7e7aafa9fa6043c6a7045c5b33a0",hwangjeff,jeffhwang@meta.com,"['docs/source/prototype.transforms.rst', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'torchaudio/prototype/transforms/__init__.py', 'torchaudio/prototype/transforms/_transforms.py']",False,7,12,2022
45c7d05ad3a0ac938762be938a58b3bd60388006,"Introduce MUSAN dataset (#2888)

Summary:
Introduces the MUSAN dataset (https://www.openslr.org/17/), which contains music, speech, and noise recordings.

Pull Request resolved: https://github.com/pytorch/audio/pull/2888

Reviewed By: xiaohui-zhang

Differential Revision: D41762164

Pulled By: hwangjeff

fbshipit-source-id: 14d5baaa4d40f065dd5d99bf7f2e0a73aa6c31a9",hwangjeff,jeffhwang@meta.com,"['docs/source/index.rst', 'docs/source/prototype.datasets.rst', 'docs/source/prototype.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/prototype/datasets/__init__.py', 'test/torchaudio_unittest/prototype/datasets/musan_test.py', 'torchaudio/prototype/datasets/__init__.py', 'torchaudio/prototype/datasets/musan.py']",False,7,12,2022
e97f3a327c2e51eae56cd6886c19475bcd6d6839,"Upgrade nightly wheels to ROCm5.3 (#2853)

Summary:
Dependent on PR https://github.com/pytorch/pytorch/pull/89101

Pull Request resolved: https://github.com/pytorch/audio/pull/2853

Reviewed By: atalman, osalpekar

Differential Revision: D41737634

Pulled By: malfet

fbshipit-source-id: 715a97a2da8ef309cea78d971b47c07463495683",Jithun Nair,jithun.nair@amd.com,"['.circleci/config.yml', '.circleci/regenerate.py']",False,7,12,2022
d234498c2755bc3040bfdb01e06ab458b25d59c1,"Add frequency_impulse_response (#2879)

Summary:
This commit adds `frequency_impulse_response` function, which generates filter from desired frequency response.

[Example](https://output.circle-artifacts.com/output/job/5233fda9-dadb-4710-9389-7e8ac20a062f/artifacts/0/docs/tutorials/filter_design_tutorial.html#frequency-sampling)

Pull Request resolved: https://github.com/pytorch/audio/pull/2879

Reviewed By: hwangjeff

Differential Revision: D41767787

Pulled By: mthrok

fbshipit-source-id: 6d5e44c6390e8cf3028994a1b1de590ff3aaf6c2",moto,855818+mthrok@users.noreply.github.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/dsp_utils.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py']",False,6,12,2022
d8a5a11db64b1670fd0dd8f8e5e80327edbe466d,"Fix _init_hubert_pretrain_model (#2886)

Summary:
address https://github.com/pytorch/audio/issues/2885

In `_init_hubert_pretrain_model ` method which initialize the hubert pretrain models, `kaiming_normal_` should be applied on `ConvLayerBlock` instead of `LayerNorm` layer. This PR fixes it and adds more unit tests.

Pull Request resolved: https://github.com/pytorch/audio/pull/2886

Reviewed By: hwangjeff

Differential Revision: D41713801

Pulled By: nateanl

fbshipit-source-id: ed199baf7504d06bbf2d31c522ae708a75426a2d",Zhaoheng Ni,zni@fb.com,"['test/torchaudio_unittest/models/wav2vec2/model_test.py', 'torchaudio/models/wav2vec2/model.py']",False,4,12,2022
55e9978a68067f7f3b70ece667e25a12ed032a06,"Add pre-emphasis and de-emphasis functions (#2871)

Summary:
Adds pre-emphasis and de-emphasis functions.

Pull Request resolved: https://github.com/pytorch/audio/pull/2871

Reviewed By: carolineechen

Differential Revision: D41651097

Pulled By: hwangjeff

fbshipit-source-id: 7a3cf6ce68b6ce1b9ae315ddd8bd8ed71acccdf1",hwangjeff,jeffhwang@meta.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/functional.py']",False,2,12,2022
c28073cc652dcab83204ee0a5714be941909e16a,"Add speed and speed perturbation functions and transforms (#2829)

Summary:
Adds functions and transforms for speed and speed perturbation (https://www.isca-speech.org/archive/interspeech_2015/ko15_interspeech.html).

Pull Request resolved: https://github.com/pytorch/audio/pull/2829

Reviewed By: xiaohui-zhang

Differential Revision: D41285114

Pulled By: hwangjeff

fbshipit-source-id: 114740507698e01f35d4beb2c568a2479e847506",hwangjeff,jeffhwang@meta.com,"['docs/source/prototype.functional.rst', 'docs/source/prototype.transforms.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/functional.py', 'torchaudio/prototype/transforms/__init__.py', 'torchaudio/prototype/transforms/_transforms.py']",False,30,11,2022
aca61bc0b310b7d63dfb2654dc76aafc25543136,"Add layer normalization to wav2vec2 large+ pretrained models (#2873)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2873

The original fairseq implementation had an extra layer normalization
preprocessings for large/xlarge models.

https://github.com/facebookresearch/fairseq/blob/fcca32258c8e8bcc9f9890bf4714fa2f96b6b3e1/fairseq/data/audio/hubert_dataset.py#L355-L357

This commit modifies the pre-trained model bundle to include this
preprocessing to the impacted pre-trained models listed bellow.
For the sake of keeping the interface identical to the other models,
since the additional preprocessing is rather simple, the returned
pre-trained model instance is modified ot include the preprocess,
instead of adding a method for preprocessing.

- WAV2VEC2_LARGE_LV60K
- WAV2VEC2_ASR_LARGE_LV60K_10M
- WAV2VEC2_ASR_LARGE_LV60K_100H
- WAV2VEC2_ASR_LARGE_LV60K_960H
- WAV2VEC2_XLSR53
- HUBERT_LARGE
- HUBERT_XLARGE
- HUBERT_ASR_LARGE
- HUBERT_ASR_XLARGE
- WAVLM_LARGE

Reviewed By: nateanl

Differential Revision: D41520183

fbshipit-source-id: 83d72fe692e8b9fc25df144deb4ca946fcd09615",Andreas Floros,andreasfloros@meta.com,['torchaudio/pipelines/_wav2vec2/impl.py'],False,30,11,2022
fc0720b404d35970add203344f7ef0aa76a24a4e,"Add sinc_impulse_response op (#2875)

Summary:
This commit adds `sinc_impulse_response`, which generates windowed-sinc low-pass filters for given cutoff frequencies.

Example usage:
 - [Filter Design Tutorial](https://output.circle-artifacts.com/output/job/c0085baa-5345-4aeb-bd44-448034caa9e1/artifacts/0/docs/tutorials/filter_design_tutorial.html)

Pull Request resolved: https://github.com/pytorch/audio/pull/2875

Reviewed By: carolineechen

Differential Revision: D41586631

Pulled By: mthrok

fbshipit-source-id: a9991dbe5b137b0b4679228ec37072a1da7e50bb",moto,855818+mthrok@users.noreply.github.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/dsp_utils.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py']",False,29,11,2022
19e1a84dba2fbbd5c3d3b771ed9b6a813f5452e7,"Add logging to StreamReader/Writer (#2878)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2878

Reviewed By: carolineechen

Differential Revision: D41587081

Pulled By: mthrok

fbshipit-source-id: da7f3647083a3566ce94070ce2bd30bf99e1db76",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/io/_stream_reader.py', 'torchaudio/io/_stream_writer.py']",False,29,11,2022
1a003c3fc21f476b5fb0aa2215426c914f229729,"Add additive synthesis tutorial (#2877)

Summary:
This commit adds the tutorial for additive synthesis, using torchaudio's prototype DSP ops.

[Review here](https://output.circle-artifacts.com/output/job/3dc83322-832a-4272-9c13-df752c97b660/artifacts/0/docs/tutorials/additive_synthesis_tutorial.html)

Pull Request resolved: https://github.com/pytorch/audio/pull/2877

Reviewed By: carolineechen

Differential Revision: D41585425

Pulled By: mthrok

fbshipit-source-id: b81283b90e4779c8054fd030a1d8c3d39d676bbd",moto,855818+mthrok@users.noreply.github.com,"['docs/source/index.rst', 'examples/tutorials/additive_synthesis_tutorial.py']",False,29,11,2022
7a05622efa87bd80e370fc5192c8c44aa7d06d2e,"Extend fftconvolve to support broadcast-able shapes (#2874)

Summary:
Currently, fftconvolve only accepts the tensors for the exact same leading dimensions.
This commit loosens the restriction to allow shapes that are broadcast-able.

This makes the fftconvolve operation more efficient for cases like signal filtering where one operand (waveform) is larger than the other (filter kernel) and the same filter kernels are applied across channels and batches.

Pull Request resolved: https://github.com/pytorch/audio/pull/2874

Reviewed By: carolineechen

Differential Revision: D41581588

Pulled By: mthrok

fbshipit-source-id: c0117e11b979fb53236cc307a970a461b0e50134",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_impl.py', 'torchaudio/prototype/functional/functional.py', 'torchaudio/prototype/transforms/_transforms.py']",False,29,11,2022
8bde6a543ba00adf2f7e330fbfebd624c876ab4d,"Add conformer wav2vec2 pretrain model (#2827)

Summary:
modeled after [paper](https://arxiv.org/pdf/2110.07313.pdf) and internal flow f288347302

internal comparison tests: D40080919

Pull Request resolved: https://github.com/pytorch/audio/pull/2827

Reviewed By: nateanl

Differential Revision: D41569046

Pulled By: carolineechen

fbshipit-source-id: 43c5313074af05972d93da55b2029c746b75c380",Caroline Chen,carolinechen@fb.com,"['docs/source/prototype.models.rst', 'test/torchaudio_unittest/prototype/conformer_wav2vec2_test.py', 'test/torchaudio_unittest/prototype/ssl_model_test.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/_conformer_wav2vec2.py']",False,29,11,2022
b0795ebe753f860efb71e8409c58a000210b43b4,"Add aux_num_out to emformer_hubert_model (#2868)

Summary:
- layer_norm in `EmformerEncoder` is set as default in emformer_hubert_model, change the type to be non-optional.
- add `aux_num_out` to emformer_hubert_model to support fine-tuning model.
- update unit tests.

Pull Request resolved: https://github.com/pytorch/audio/pull/2868

Reviewed By: carolineechen

Differential Revision: D41451311

Pulled By: nateanl

fbshipit-source-id: 5fa0f19255e4f01e001d62f8689e36f134030083",Zhaoheng Ni,zni@fb.com,"['test/torchaudio_unittest/prototype/ssl_model_test.py', 'torchaudio/prototype/models/_emformer_hubert.py']",False,28,11,2022
52e89756f003f03a7373f4a5ea07116f9e07fa73,"Add oscillator tutorial (#2862)

Summary:
This commits add tutorial for oscillator_bank and adsr_envelope, which will be a basis for DDSP.

 - [Review here](https://output.circle-artifacts.com/output/job/cf1d3001-88e5-418b-8cf8-ae22b4445dba/artifacts/0/docs/tutorials/oscillator_tutorial.html)

Pull Request resolved: https://github.com/pytorch/audio/pull/2862

Reviewed By: carolineechen

Differential Revision: D41559503

Pulled By: mthrok

fbshipit-source-id: 3f1689186db7d246de14f228fc2f91bf37db98cd",moto,855818+mthrok@users.noreply.github.com,"['docs/source/index.rst', 'examples/tutorials/oscillator_tutorial.py']",False,28,11,2022
3882c3955edd4b6d04ea1549cf5e3758ea9ab547,"Add extend_pitch (#2863)

Summary:
Add `extend_pitch` function that can be used for augmenting fundamental frequencies with its harmonic overtones or inharmonic partials. it can be use for amplitude as well.

For example usages, see https://output.circle-artifacts.com/output/job/4ad0c29a-d75a-4244-baad-f5499f11d94b/artifacts/0/docs/tutorials/synthesis_tutorial.html

Part of https://github.com/pytorch/audio/issues/2835
Extracted from https://github.com/pytorch/audio/issues/2808

Pull Request resolved: https://github.com/pytorch/audio/pull/2863

Reviewed By: carolineechen

Differential Revision: D41543880

Pulled By: mthrok

fbshipit-source-id: 4f20e55770b0b3bee825ec07c73f9ec7cb181109",moto,855818+mthrok@users.noreply.github.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py']",False,28,11,2022
8ba323bbf8e30e838ce0f6278412f0decd44c520,"Add torchscript test to oscillator_bank (#2864)

Summary:
Missing from https://github.com/pytorch/audio/issues/2848

Pull Request resolved: https://github.com/pytorch/audio/pull/2864

Reviewed By: carolineechen

Differential Revision: D41413381

Pulled By: mthrok

fbshipit-source-id: 4377ed4a59504c6ade9ee6f42938a2bc3f04fb73",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/_dsp.py']",False,19,11,2022
92b6847ee50be39743ac65ea9cf455ac319840e7,"Add emformer hubert model architecture (#2836)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2836

Reviewed By: carolineechen

Differential Revision: D41208630

Pulled By: nateanl

fbshipit-source-id: 625e1651f0b8a6e20876409739cf7084cb7c748b",Zhaoheng Ni,zni@fb.com,"['docs/source/prototype.models.rst', 'test/torchaudio_unittest/prototype/conformer_wav2vec2_test.py', 'test/torchaudio_unittest/prototype/ssl_model_test.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/_emformer_hubert.py']",False,18,11,2022
13063f9b55bd05bbc7c014fcf90e4bfa145a8c07,"Update decoder doc (#2865)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2865

Reviewed By: carolineechen

Differential Revision: D41403756

Pulled By: mthrok

fbshipit-source-id: d193caa90e786f08f28e4cc2df4b4fb77aa8f592",moto,855818+mthrok@users.noreply.github.com,['torchaudio/io/_stream_reader.py'],False,18,11,2022
2bfb86480355e4231ec9d780ab39b7e4dbd0358f,"Add logging to MelSpectrogram and Spectrogram (#2861)

Summary:
Adds API usage logging to MelSpectrogram and Spectrogram.

Pull Request resolved: https://github.com/pytorch/audio/pull/2861

Reviewed By: carolineechen

Differential Revision: D41384080

Pulled By: hwangjeff

fbshipit-source-id: caf4b0fa6e4cc3954384bfdd08a183b90d07d974",hwangjeff,jeffhwang@meta.com,['torchaudio/transforms/_transforms.py'],False,17,11,2022
793ff00b96db579e65a20a61fd14b05f23e301c1,"Add adsr_envelope (#2859)

Summary:
Add adsr_envelope op, which generates ADSR envelope

* Supports generation of the envelope on GPU
* Supports optional Hold
* Supports polynomial decay

<image src='https://download.pytorch.org/torchaudio/doc-assets/adsr_examples.png'>

Pull Request resolved: https://github.com/pytorch/audio/pull/2859

Reviewed By: nateanl

Differential Revision: D41379601

Pulled By: mthrok

fbshipit-source-id: 3717a6e0360d2a24913c2a836c57c5edec1d7b31",moto,855818+mthrok@users.noreply.github.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py']",False,17,11,2022
d912dcd74e94877afbb501144b7702317fd53d1d,"fix import bug in global_stats.py (#2858)

Summary:
This code was added by
https://github.com/pytorch/audio/commit/4d0095a528412cfec2a549204fc01d9ebb15df7a

Seems that the original code had a typo?

Pull Request resolved: https://github.com/pytorch/audio/pull/2858

Test Plan:
```
// the import of `mustc` now succeeds, previously crashed
python examples/asr/emformer_rnnt/global_stats.py --model-type librispeech --dataset-path /home/vasiliy/local/librispeech/
```

Reviewed By: carolineechen

Differential Revision: D41355663

Pulled By: nateanl

fbshipit-source-id: 92507e529d41b984b9dd400ad24a55d130372b7d",vasiliy,vasiliy@fb.com,['examples/asr/emformer_rnnt/global_stats.py'],False,17,11,2022
e502b10c83e17ad22f68b50365862ff8bef2dec8,"Add oscillator_bank (#2848)

Summary:
This commit adds `oscillator_bank` op, which is the core of (differential) digital signal processing ops.
The implementation itself is pretty simple, sum instantaneous frequencies, take sin and multiply with amplitudes.

Following the magenta implementation, amplitudes for frequency range outside of [-Nyquist, Nyquist] \
are suppressed.

The differentiability is tested within frequency range of [- Nyquist, Nyquist], and amplitude range of [-5, 5], which should be enough.

For example usages:
 - https://output.circle-artifacts.com/output/job/129f3e21-41ce-406b-bc6b-833efb3c3141/artifacts/0/docs/tutorials/oscillator_tutorial.html
 - https://output.circle-artifacts.com/output/job/129f3e21-41ce-406b-bc6b-833efb3c3141/artifacts/0/docs/tutorials/synthesis_tutorial.html

Part of https://github.com/pytorch/audio/issues/2835
Extracted from https://github.com/pytorch/audio/issues/2808

Pull Request resolved: https://github.com/pytorch/audio/pull/2848

Reviewed By: carolineechen

Differential Revision: D41353075

Pulled By: mthrok

fbshipit-source-id: 80e60772fb555760f2396f7df40458803c280225",moto,855818+mthrok@users.noreply.github.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/dsp_utils.py', 'test/torchaudio_unittest/prototype/functional/functional_cpu_test.py', 'test/torchaudio_unittest/prototype/functional/functional_cuda_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/_dsp.py']",False,17,11,2022
e062110b286ba0673d773588d70a8d41994086f2,"Enable mixed precision training for hubert_pretrain_model (#2854)

Summary:
address https://github.com/pytorch/audio/issues/2847

In mixed precision training, the dtype of `mask_embedding` is **not** converted to fp16 automatically. This PR addresses the issue by changing the dtype of `mask_embedding` to `x` to enable mixed precision training.

Pull Request resolved: https://github.com/pytorch/audio/pull/2854

Reviewed By: carolineechen

Differential Revision: D41343486

Pulled By: nateanl

fbshipit-source-id: 4a5cbb429ff8ba5d3c439a3d5acb5094f66bf705",Zhaoheng Ni,zni@fb.com,"['examples/hubert/lightning.py', 'torchaudio/models/wav2vec2/components.py']",False,16,11,2022
40ff642e0d6c273684330e7d84e63be0267846e1,"Fix hubert fine-tuning recipe (#2851)

Summary:
- `_get_fileids_paths` in `LibriLightLimited` dataset was changed dataset in https://github.com/pytorch/audio/issues/2653, the absolute path becomes relative paths. This PR fixes the usage in hubert fine-tuning recipe to get correct audio paths.
- model options should be `hubert_pretrain_large` and `hubert_pretrain_xlarge` instead of `hubert_large` and `hubert_xlarge`.
- The input dimension of CTC linear layer varies depending on the model architecture, update it in lightning module.

cc simpleoier

Pull Request resolved: https://github.com/pytorch/audio/pull/2851

Reviewed By: carolineechen

Differential Revision: D41327998

Pulled By: nateanl

fbshipit-source-id: f92248ee84ec860b4e4dbef880c5794b338e1e2d",Zhaoheng Ni,zni@fb.com,"['examples/hubert/dataset/hubert_dataset.py', 'examples/hubert/lightning.py', 'torchaudio/datasets/librilight_limited.py']",False,16,11,2022
26f62dc5beab1ec9d36250c396726c4085ab36c2,"Add WavLM bundles (#2833)

Summary:
Closes T136364380, follow-up to https://github.com/pytorch/audio/issues/2822

- Added ""base"", ""base+"", and ""large"" bundles for WavLM
- Expanded `wav2vec2_pipeline_test.py` to include the new bundles
- Added the new bundles to docs in `pipelines.rst`

Pull Request resolved: https://github.com/pytorch/audio/pull/2833

Reviewed By: nateanl

Differential Revision: D41194796

Pulled By: sgrigory

fbshipit-source-id: bf8e96c05b6a81ac5c5a014c46adeeac12685328",Grigory Sizov,grigorysizov@fb.com,"['docs/source/pipelines.rst', 'test/integration_tests/wav2vec2_pipeline_test.py', 'torchaudio/pipelines/__init__.py', 'torchaudio/pipelines/_wav2vec2/impl.py']",False,15,11,2022
2d1da45c8417f410e98641fd38eb51cff835d125,"Use BetterTransfomer in WavLM Self-Attention (#2842)

Summary:
Closes T137506059

Replaces functional multi-head attention in `WavLMSelfAttention` with a module `torch.nn.MultiheadAttention`. The reason is that the latter uses native CPU/CUDA implementation ([BetterTransfomer](https://pytorch.org/blog/a-better-transformer-for-fast-transformer-encoder-inference/)) under certain conditions, and can achieve significant speedup. It also simplifies the code in `WavLMSelfAttention`

Note: the definition of `bias` parameter in `WavLMSelfAttention.forward` has changed slightly, because in `torch.nn.MultiheadAttention` there is no parameter controlling presence of bias for projections of `k`, `v`, and `q` independently. In WavLM we only use `bias=True`, so it won't have any effect for users of WavLM or tests

Pull Request resolved: https://github.com/pytorch/audio/pull/2842

Reviewed By: nateanl

Differential Revision: D41186166

Pulled By: sgrigory

fbshipit-source-id: e791c68106ad89f96c1abf046de699cb8ec7b595",Grigory Sizov,grigorysizov@fb.com,"['torchaudio/models/wav2vec2/utils/import_huggingface.py', 'torchaudio/models/wav2vec2/wavlm_attention.py']",False,15,11,2022
d73f4688ceea5eca24f43677f6d298f04ca25b29,"Add logo (#2802)

Summary:
* Add the new official torchaudio logo to documentation/README.
* Add a page for download logo.

https://output.circle-artifacts.com/output/job/e9eb1292-7c10-4fef-adc3-ad568802aa59/artifacts/0/docs/index.html

<img width=""1068"" alt=""Screen Shot 2022-11-14 at 10 30 27 AM"" src=""https://user-images.githubusercontent.com/855818/201738349-9e248f15-dce2-4931-9066-aa898a53d6ad.png"">

https://output.circle-artifacts.com/output/job/e9eb1292-7c10-4fef-adc3-ad568802aa59/artifacts/0/docs/logo.html

<img width=""617"" alt=""Screen Shot 2022-11-14 at 10 30 47 AM"" src=""https://user-images.githubusercontent.com/855818/201738420-ad0fda2f-f310-4802-851c-bbdf6c84c045.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2802

Reviewed By: carolineechen

Differential Revision: D41295277

Pulled By: mthrok

fbshipit-source-id: 6615d00799c9611f875e8485459d800e350b3486",moto,855818+mthrok@users.noreply.github.com,"['README.md', 'docs/source/_static/img/logo.png', 'docs/source/index.rst', 'docs/source/logo.rst']",False,15,11,2022
01eda13c5841c62cc08cbe3c3191e37301d97145,"Remove LTS from README (#2844)

Summary:
Removing LTS mention and packages from README as it is discontinued.

Pull Request resolved: https://github.com/pytorch/audio/pull/2844

Reviewed By: hwangjeff, xiaohui-zhang

Differential Revision: D41200886

Pulled By: mthrok

fbshipit-source-id: 0da0afe68df51826075ce945cf0cf1de901e1c8f",moto,855818+mthrok@users.noreply.github.com,['README.md'],False,14,11,2022
7819f3f67c1624684013be75ba3243e28e535356,"Move bark spectrogram to prototype (#2843)

Summary:
follow up to https://github.com/pytorch/audio/issues/2823
- move bark spectrogram to prototype
- decrease autograd test tolerance (passing on circle ci)
- add diagram for bark fbanks

cc jdariasl

Pull Request resolved: https://github.com/pytorch/audio/pull/2843

Reviewed By: nateanl

Differential Revision: D41199522

Pulled By: carolineechen

fbshipit-source-id: 8e6c2e20fb7b14f39477683b3c6ed8356359a213",Caroline Chen,carolinechen@fb.com,"['docs/source/functional.rst', 'docs/source/prototype.functional.rst', 'docs/source/prototype.transforms.rst', 'docs/source/transforms.rst', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'test/torchaudio_unittest/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/transforms/transforms_test.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/functional.py', 'torchaudio/prototype/transforms/__init__.py', 'torchaudio/prototype/transforms/_transforms.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",False,14,11,2022
6e334a469bd7dae28625c8f8b9bb911eb8154e8f,"Fix initialization in hubert_pretrain_model (#2846)

Summary:
address https://github.com/pytorch/audio/issues/2845

Pull Request resolved: https://github.com/pytorch/audio/pull/2846

Reviewed By: carolineechen

Differential Revision: D41251624

Pulled By: nateanl

fbshipit-source-id: 1a363d2314d6a452f35c109b9730da64ada5a2fd",Zhaoheng Ni,zni@fb.com,['torchaudio/models/wav2vec2/components.py'],False,13,11,2022
eabf1a1324e476f9b3d54c68c0c475455edb6e3a,"Add nova workflow for MacOS and Linux (#2800)

Summary:
Added missed build workflows for MacOS and Linux:

- [x] Linux conda
- [x] MacOS conda

This does not change the existing builds/uploads in CircleCI, and should not break any existing jobs/workflows. This is just to add back workflows for the MacOS and Linux conda builds with Nova.

We will create a workflow (most likely in test-infra) that does this comparison between the binaries to ensure there is parity between the binaries before we start uploading with Nova.

Pull Request resolved: https://github.com/pytorch/audio/pull/2800

Reviewed By: osalpekar

Differential Revision: D41181467

Pulled By: DanilBaibak

fbshipit-source-id: a5c5d4dcfdd778b4045203f6016c20fb42daa01b",DanilBaibak,danil.baibak@gmail.com,"['.github/workflows/build_conda_linux.yml', '.github/workflows/build_conda_macos.yml', '.github/workflows/build_wheels_linux.yml', '.github/workflows/build_wheels_macos.yml']",False,11,11,2022
4e309734d9cf3f5b5cd7e75cb4f2feb0a0bb0920,"Fix the handling of discard_before_pts (#2841)

Summary:
Currently `discard_before_pts=-1` is used to indicate no AVFrame should be skipped. It was reported that some corrupted video can have constant negative pts value.

It is technically UB for such corrupted data, but still all the AVFrame should be decoded as long as `seek` is not used.

This commit changes the decoder so that it processes AVFrame if `discard_before_pts==-1` disregard of AVFrame::pts value.

Pull Request resolved: https://github.com/pytorch/audio/pull/2841

Reviewed By: hwangjeff

Differential Revision: D41174442

Pulled By: mthrok

fbshipit-source-id: e9d2fab4b0e2bc47146eda8e1dd377a74c087590",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h']",False,10,11,2022
15f76b0b1fa496aee4ed90d8b5553670fc9bb6a3,"[Nova] Add M1 Wheels Build (#2839)

Summary:
Adding Nova Reusable Workflow for M1 Wheels Build. Once this has been running well for a while, we can replace the old `build-m1-binaries.yml` workflow.

Pull Request resolved: https://github.com/pytorch/audio/pull/2839

Reviewed By: DanilBaibak

Differential Revision: D41195316

Pulled By: osalpekar

fbshipit-source-id: f3754043f384b1645e5fcfaebf465f6839f72461",Omkar Salpekar,osalpekar@fb.com,['.github/workflows/build-wheels-m1.yml'],False,10,11,2022
04f92297106121cd26cd0730013a2907e6f9f046,"[Nova] Add M1 Conda Builds (#2840)

Summary:
Adding Nova Reusable Workflow for M1 Conda Build. Once this has been running well for a while, we can replace the old `build-m1-binaries.yml` workflow.

Pull Request resolved: https://github.com/pytorch/audio/pull/2840

Reviewed By: DanilBaibak

Differential Revision: D41195298

Pulled By: osalpekar

fbshipit-source-id: 14591b96e998aa43fa57e8e5b0b09d0ce4f4092e",Omkar Salpekar,osalpekar@fb.com,['.github/workflows/build-conda-m1.yml'],True,10,11,2022
b326bc49b1f323ccbd9bda24c9ed225507f2f08d,"BarkSpectrogram (#2823)

Summary:
I have added BarkScale transform, which can transform a regular Spectrogram into a BarkSpectrograms similar to MelScale. ahmed-fau opened this requirement in December 2021 with the number (https://github.com/pytorch/audio/issues/2103). The new functionality includes three different well-known approximations of the Bark scale.

Pull Request resolved: https://github.com/pytorch/audio/pull/2823

Reviewed By: nateanl

Differential Revision: D41162100

Pulled By: carolineechen

fbshipit-source-id: b2670c4972e49c9ef424da5d5982576f7a4df831",Julián D. Arias-Londoño,julian.arias@upm.es,"['docs/source/functional.rst', 'docs/source/transforms.rst', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'test/torchaudio_unittest/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/transforms/transforms_test.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",False,10,11,2022
74f9a894fcd4e7d635919803b364e47577a2b6e8,"Add conformer w2v2 model architecture (#2826)

Summary:
internal comparison tests: D40080919

follow up PR for pretrained models https://github.com/pytorch/audio/issues/2827

Pull Request resolved: https://github.com/pytorch/audio/pull/2826

Reviewed By: nateanl

Differential Revision: D41160061

Pulled By: carolineechen

fbshipit-source-id: f3c478b28c235af53d1d8e21b573c53684a63ac4",Caroline Chen,carolinechen@fb.com,"['docs/source/prototype.models.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/prototype/conformer_wav2vec2_test.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/_conformer_wav2vec2.py']",False,10,11,2022
bd76d3d71690ffe7b19c6f71d53fc6dd0fb3caa5,"Add WavLM model (#2822)

Summary:
Closes T136364380

Added [WavLM Model](https://github.com/microsoft/UniSpeech/tree/main/WavLM):
- Added `WavLMSelfAttention` class (from [original implementation](https://github.com/microsoft/UniSpeech/blob/2e9dde8bf815a5f5fd958e3435e5641f59f96928/WavLM/modules.py)) and adjusted existing Encoder and Transformer classes to be compatible with it
- Added factory functions `wavlm_model`, `wavlm_base`, `wavlm_large` to `models/wav2vec2/model.py`
- Added bundles for base and large models to pipelines. **TODO**: pre-trained model weights are not yet uploaded to `download.pytorch.org`, permissions not granted yet.

## Tests
- Expanded HuggingFace integration tests to cover WavLM. For there tests, added JSON configs for base and large models from HF ([base](https://huggingface.co/microsoft/wavlm-base/blob/main/config.json), [large](https://huggingface.co/microsoft/wavlm-large/blob/main/config.json)) into test assets
- Expanded TorchScript and quantization tests to cover WavLM

## Comments
There are a few workarounds I had to introduce:
- Quantization tests for WavLM were breaking down at [`torch.cat`](https://github.com/pytorch/audio/pull/2822/files#diff-6f1486901c94320ec0610a460dc674638fab9d104a61564ff7b59353a8b8547cR466) ~~until I excluded the arguments of `torch.cat` from quantization [here](https://github.com/pytorch/audio/pull/2822/files#diff-6f1486901c94320ec0610a460dc674638fab9d104a61564ff7b59353a8b8547cR368-R369). I haven't found a better way to fix it, let me know if there is one~~ The reason for this seems to be that quantization replaces `.bias` and `.weight` attributes of a `Linear` module with methods. Since we are using weights and biases directly, the code was break. The final solution suggested by nateanl was to define attention weights and biases directly in `WavLMSelfAttention`, skipping the `Linear` layers
- ~~WavLM uses position embedding in the first layer of encoder, but not in the subsequent ones.  So [UniSpeech](https://github.com/microsoft/UniSpeech/blob/2e9dde8bf815a5f5fd958e3435e5641f59f96928/WavLM/modules.py#L342) and [HF](https://github.com/huggingface/transformers/blob/b047472650cba259621549ac27b18fd2066ce18e/src/transformers/models/wavlm/modeling_wavlm.py#L441-L442) implementations only create this embedding module in the layers where it's used. However, we can't do this here because it breaks TorchScript. So as a solution I add a dummy `Identity` module to `WavLMSelfAttention` when the actual embedding is not needed: [here](https://github.com/pytorch/audio/pull/2822/files#diff-6f1486901c94320ec0610a460dc674638fab9d104a61564ff7b59353a8b8547cR361-R368).~~ Thanks nateanl for resolving this!
- I had to add dummy `position_bias` and `key_padding_mask` arguments to `SelfAttention.forward` to make TorchScript tests pass. Since both `SelfAttention` and `WavLMSelfAttention` are called from `EncoderLayer`, they need to have compatible signatures. Having a variable number of arguments with `**kwargs` or checking object class doesn't seem to work with TorchScript, so I instead made both types of attention accept `position_bias` and `key_padding_mask` arguments.

Nit: do we still need to specify `__all__` if there are no wildcard imports in `__init__.py`, e.g. in `torchaudio/models/__init__.py`?

Pull Request resolved: https://github.com/pytorch/audio/pull/2822

Reviewed By: nateanl

Differential Revision: D41121855

Pulled By: sgrigory

fbshipit-source-id: 9f4f787e5810010de4e74cb704063a26c66767d7",Grigory Sizov,grigorysizov@fb.com,"['docs/source/refs.bib', 'test/torchaudio_unittest/assets/wav2vec2/huggingface/wavlm-base.json', 'test/torchaudio_unittest/assets/wav2vec2/huggingface/wavlm-large.json', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/models/wav2vec2/huggingface_intergration_test.py', 'test/torchaudio_unittest/models/wav2vec2/model_test.py', 'torchaudio/models/__init__.py', 'torchaudio/models/wav2vec2/__init__.py', 'torchaudio/models/wav2vec2/components.py', 'torchaudio/models/wav2vec2/model.py', 'torchaudio/models/wav2vec2/utils/import_huggingface.py', 'torchaudio/models/wav2vec2/wavlm_attention.py']",False,9,11,2022
5e2507f5152894b412439bf214033495e3ca20b2,"[Nova] Added build wheels workflow for MacOS (#2782)

Summary:
Added build wheels workflow for MacOS.

This does not change the existing builds/uploads in CircleCI, and should not break any existing jobs/workflows. This is just to add back workflows to build the MacOS Wheels with Nova.

We will create a workflow (most likely in test-infra) that does this comparison between the binaries to ensure there is parity between the binaries before we start uploading with Nova.

Pull Request resolved: https://github.com/pytorch/audio/pull/2782

Reviewed By: osalpekar

Differential Revision: D41091271

Pulled By: DanilBaibak

fbshipit-source-id: 906bcfecb26b5268a05163fa339909707f7de494",DanilBaibak,danil.baibak@gmail.com,['.github/workflows/build_wheels_macos.yml'],False,9,11,2022
ca478823c1d40c2d9b5ebf1908ed2f87ddf8a894,"Enable log probs input for rnnt loss (#2798)

Summary:
Add `fused_log_softmax` argument (default/current behavior = True) to rnnt loss.

If setting it to `False`, call `log_softmax` on the logits prior to passing it in to the rnnt loss function.

The following should produce the same output:
```
rnnt_loss(logits, targets, logit_lengths, target_lengths, fused_log_softmax=True)
```

```
log_probs = torch.nn.functional.log_softmax(logits, dim=-1)
rnnt_loss(log_probs, targets, logit_lengths, target_lengths, fused_log_softmax=False)
```

testing -- unit tests + get same results on the conformer rnnt recipe

Pull Request resolved: https://github.com/pytorch/audio/pull/2798

Reviewed By: xiaohui-zhang

Differential Revision: D41083523

Pulled By: carolineechen

fbshipit-source-id: e15442ceed1f461bbf06b724aa0561ff8827ad61",Caroline Chen,carolinechen@fb.com,"['test/torchaudio_unittest/common_utils/rnnt_utils.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'torchaudio/csrc/rnnt/autograd.cpp', 'torchaudio/csrc/rnnt/compute.cpp', 'torchaudio/csrc/rnnt/compute.h', 'torchaudio/csrc/rnnt/cpu/compute.cpp', 'torchaudio/csrc/rnnt/cpu/cpu_kernels.h', 'torchaudio/csrc/rnnt/gpu/compute.cu', 'torchaudio/csrc/rnnt/gpu/gpu_kernels.cuh', 'torchaudio/csrc/rnnt/gpu/gpu_transducer.h', 'torchaudio/csrc/rnnt/gpu/kernels.h', 'torchaudio/csrc/rnnt/options.h', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,8,11,2022
2d99fee29efac7fcd09f679ed6f7f3379eaac512,"Add convolution transforms (#2811)

Summary:
Adds `torch.nn.Module`-based implementations for convolution and FFT convolution.

Pull Request resolved: https://github.com/pytorch/audio/pull/2811

Reviewed By: carolineechen

Differential Revision: D40881937

Pulled By: hwangjeff

fbshipit-source-id: bfe8969e6178ad4f58981efd4b2720ac006be8de",hwangjeff,jeffhwang@meta.com,"['docs/source/index.rst', 'docs/source/prototype.rst', 'docs/source/prototype.transforms.rst', 'test/torchaudio_unittest/prototype/transforms/__init__.py', 'test/torchaudio_unittest/prototype/transforms/autograd_cpu_test.py', 'test/torchaudio_unittest/prototype/transforms/autograd_cuda_test.py', 'test/torchaudio_unittest/prototype/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_cpu_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_cuda_test.py', 'test/torchaudio_unittest/prototype/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/prototype/transforms/transforms_cpu_test.py', 'test/torchaudio_unittest/prototype/transforms/transforms_cuda_test.py', 'test/torchaudio_unittest/prototype/transforms/transforms_test_impl.py', 'torchaudio/prototype/functional/functional.py', 'torchaudio/prototype/transforms/__init__.py', 'torchaudio/prototype/transforms/_transforms.py']",False,8,11,2022
6bd3851289e2bfc3eb57e9582999415f21e7af52,"Fix decimal FPS handling StreamWriter (#2831)

Summary:
StreamWriter assumed that frame rate is always expressed as 1/something, which is a reasonable assumption.

This commit fixes it by properly computing time_base from frame rate.

Address https://github.com/pytorch/audio/issues/2830

Pull Request resolved: https://github.com/pytorch/audio/pull/2831

Reviewed By: carolineechen

Differential Revision: D41036084

Pulled By: mthrok

fbshipit-source-id: 805881d4cb221ab2c002563aefb986e30fb91609",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp']",False,4,11,2022
7a1d53172482b325db5bbd5a03228796975a0024,"Update favicon (#2825)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2825

Reviewed By: carolineechen

Differential Revision: D40954522

Pulled By: mthrok

fbshipit-source-id: 433fb856a74a340af4d49e5c65a6270f0b00c835",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_static/img/favicon.ico', 'docs/source/conf.py']",False,3,11,2022
8abf952a7253a3bfabd058331b01f2bef418a1c8,"packaging: Specify otool / install_name_tool (#2828)

Summary:
Makes it specific to which version of otool and install_name_tool we actually prefer since using the one from conda can produce inconsistent results

Fixes https://github.com/pytorch/audio/issues/2806

Signed-off-by: Eli Uriegas <eliuriegas@meta.com>

Pull Request resolved: https://github.com/pytorch/audio/pull/2828

Reviewed By: malfet, mthrok

Differential Revision: D40960633

Pulled By: seemethere

fbshipit-source-id: 5010c06578f1efc4fe314f9a3ff47f18e14ad156",Eli Uriegas,eliuriegas@meta.com,"['.github/workflows/build-m1-binaries.yml', 'packaging/ffmpeg/build.sh']",True,2,11,2022
513eca3a8ee894fafdb3e983453d1b07e156fd9d,"Remove redundant PyTorch logo assets (#2824)

Summary:
PyTorch logo is included in pytorch doc theme, (and cannot be changed without custom CSS) so no need to have them here.

Pull Request resolved: https://github.com/pytorch/audio/pull/2824

Reviewed By: carolineechen

Differential Revision: D40954564

Pulled By: mthrok

fbshipit-source-id: 5e9a91fddcc92c141baf1996f721c09c037fb003",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_static/img/pytorch-logo-dark.png', 'docs/source/_static/img/pytorch-logo-dark.svg', 'docs/source/_static/img/pytorch-logo-flame.png', 'docs/source/conf.py']",False,2,11,2022
01814fe1906ca6554a23a86330e84e7bd0d602c0,"Remove hdemucs init from prototype (#2817)

Summary:
Now that hybrid demucs is officially released as beta, remove it's temp prototype initialization support

Pull Request resolved: https://github.com/pytorch/audio/pull/2817

Reviewed By: mthrok

Differential Revision: D40908696

Pulled By: carolineechen

fbshipit-source-id: bc87a4b7aeb27db00e10bdce91cd71688cb08769",Caroline Chen,carolinechen@fb.com,['torchaudio/prototype/models/hdemucs/__init__.py'],False,2,11,2022
ce2ae984a19d6c52c1ee3d799834f42d4d38490c,"Add links to training recipes (#2812)

Summary:
<img width=""756"" alt=""Screen Shot 2022-11-01 at 3 32 58 PM"" src=""https://user-images.githubusercontent.com/855818/199173348-f463ae71-438c-4dad-a481-b65522a8e52f.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2812

Reviewed By: carolineechen

Differential Revision: D40919942

Pulled By: mthrok

fbshipit-source-id: 18e5a709c262fb0b15ada0d303f1d0dee033beb1",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/layout.html', 'docs/source/index.rst']",False,2,11,2022
87eca36dc95de85b5769c2b4857c3361e80c9ed4,"Make buffer size configurable in ffmpeg file object operations and set size in backend (#2810)

Summary:
Partly addresses https://github.com/pytorch/audio/issues/2686 and https://github.com/pytorch/audio/issues/2356.

Currently, when the buffer used for file object decoding is insufficiently large, `torchaudio.load` returns a shorter waveform than expected. To deal with this, the user is expected to increase the buffer size via `torchaudio.utils.sox_utils.get_buffer_size`, but this does not influence the buffer used by the FFMpeg fallback. To fix this, this PR introduces changes that apply the buffer size set for the SoX backend to FFMpeg.

As a follow-up, we should see whether it's possible to programmatically detect that the buffer's too small and flag it to the user.

Pull Request resolved: https://github.com/pytorch/audio/pull/2810

Reviewed By: mthrok

Differential Revision: D40906978

Pulled By: hwangjeff

fbshipit-source-id: 256fe1da8b21610b05bea9a0e043f484f9ea2e76",hwangjeff,jeffhwang@meta.com,"['torchaudio/backend/sox_io_backend.py', 'torchaudio/io/_compat.py']",False,2,11,2022
6318c81f09c844d5c091affea386d54318887855,"Fix convolve mode docstring (#2809)

Summary:
Argument `mode` in `convolve` and `fftconvolve` is expected to be a string, but the docstrings incorrectly say bool. This PR fixes the docstrings accordingly.

Pull Request resolved: https://github.com/pytorch/audio/pull/2809

Reviewed By: nateanl

Differential Revision: D40854464

Pulled By: hwangjeff

fbshipit-source-id: 75b339ba34715723c93b91e7d48be2ed28bee115",hwangjeff,jeffhwang@meta.com,['torchaudio/prototype/functional/functional.py'],True,1,11,2022
60f29ca00c55486cc7126f7d8bfc91bcb5157127,"Add precise seek (#2737)

Summary:
cc mthrok

Implements precise seek and seek to any frame in torchaudio

Pull Request resolved: https://github.com/pytorch/audio/pull/2737

Reviewed By: mthrok

Differential Revision: D40546716

Pulled By: jdsgomes

fbshipit-source-id: d37da7f55977337eb16a3c4df44ce8c3c102698e",Joao Gomes,jdsgomes@fb.com,"['test/torchaudio_unittest/assets/nasa_13013.avi', 'test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.cpp', 'torchaudio/io/_stream_reader.py']",False,31,10,2022
82d92da55b22c3956f8e390d37bf41245df41622,"Udpate version matrix for 0.13 release (#2804)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2804

Reviewed By: nateanl

Differential Revision: D40813412

Pulled By: carolineechen

fbshipit-source-id: 8270bf17851b7424f51ecb8dbcbc2e1076efe333",Caroline Chen,carolinechen@fb.com,['README.md'],False,29,10,2022
86d596d37d0e591d34c86375d516243c21a8ce8e,"Introduce argument 'mode' for convolution functions (#2801)

Summary:
Introduces argument 'mode' for convolution functions, following SciPy's convention.

Pull Request resolved: https://github.com/pytorch/audio/pull/2801

Reviewed By: nateanl

Differential Revision: D40805405

Pulled By: hwangjeff

fbshipit-source-id: 8f0006ffe9e3945b4b17f44c4cfa1adb265c20ef",hwangjeff,jeffhwang@meta.com,"['test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/functional.py']",False,28,10,2022
e6bd346e1db1c844196b5ba27ca3c0ca38d8a332,"Refactor tutorial index (#2767)

Summary:
This commit re-organizes the tutorials.

1. Put all the tutorials in the left bar and make the section **folded by default**.
2. Add pytorch/tutorials-like cards in index
3. Move feature classifications to a dedicated page.

https://output.circle-artifacts.com/output/job/1f1a04a5-137e-428d-9da4-c46f59eeffa4/artifacts/0/docs/index.html

<img width=""1073"" alt=""Screen Shot 2022-10-28 at 7 34 29 AM"" src=""https://user-images.githubusercontent.com/855818/198410686-3ef40ad2-c9c9-443c-800e-6e51e1b6a491.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2767

Reviewed By: carolineechen

Differential Revision: D40627547

Pulled By: mthrok

fbshipit-source-id: 098b825f242e91919126014abdab27852304ae64",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_static/css/custom.css', 'docs/source/_templates/layout.html', 'docs/source/conf.py', 'docs/source/custom_directives.py', 'docs/source/feature_classifications.rst', 'docs/source/index.rst', 'docs/source/tutorials.io.rst']",False,28,10,2022
436efb8e9ea1b7100d316e58d4c48866fda3916d,"Add back docstring for MelSpectrogram param onesided (#2799)

Summary:
Adds back docstring for `MelSpectrogram` initializer param `onesided`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2799

Reviewed By: mthrok

Differential Revision: D40742691

Pulled By: hwangjeff

fbshipit-source-id: 7e8088fefaafe7df57bb626b8b4e9ce5317bf3a7",hwangjeff,jeffhwang@meta.com,['torchaudio/transforms/_transforms.py'],True,27,10,2022
546e699ac2bd3e7939d5b4af17de42fdade9696b,"Deprecate 'onesided' init param for MelSpectrogram (#2797)

Summary:
Initializer parameter `onesided` isn't relevant to `MelSpectrogram` — it should always be `True`. In fact, the module already assumes `onesided == True` in the filterbank it generates and fails in its forward pass when `onesided == False`. Accordingly, this PR makes param `onesided` optional and adds a deprecation warning that's fired when the param is provided.

Pull Request resolved: https://github.com/pytorch/audio/pull/2797

Reviewed By: carolineechen, xiaohui-zhang

Differential Revision: D40731238

Pulled By: hwangjeff

fbshipit-source-id: 6eea8eb9d4a85a805162e03ad91682a1946f92cd",hwangjeff,jeffhwang@meta.com,"['test/torchaudio_unittest/transforms/transforms_test.py', 'torchaudio/transforms/_transforms.py']",False,26,10,2022
9e1999ae9d3b444d5230aed9aa28c4c69b90f89e,"Refactor StreamProcessor interface (#2791)

Summary:
StreamProcessor is constructed on top of AVStream object, and attach streams defined by client code.

This commit refactor the constructor and add_stream method signature so that `add_stream`'s signature is centered around the parameters required for filter construction.

Pull Request resolved: https://github.com/pytorch/audio/pull/2791

Reviewed By: xiaohui-zhang

Differential Revision: D40667979

Pulled By: mthrok

fbshipit-source-id: 42220832f09a7895ede3cddf969d57feeb4ef7ec",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp']",False,26,10,2022
17a2b93b7e57ed123217136eb788c1904ea9ae27,"Fix issue with the missing video frame in StreamWriter (#2789)

Summary:
Addresses https://github.com/pytorch/audio/issues/2790.

Previously AVPacket objects had duration==0.

`av_interleaved_write_frame` function was inferring the duration of packets by
comparing them against the next ones but It could not infer the duration of
the last packet, as there is no subsequent frame, thus was omitting it from the final data.

This commit fixes it by explicitly setting packet duration = 1 (one frame)
only for video. (audio AVPacket contains multiple samples, so it's different.
To ensure the correctness for audio, the tests were added.)

Pull Request resolved: https://github.com/pytorch/audio/pull/2789

Reviewed By: xiaohui-zhang

Differential Revision: D40627439

Pulled By: mthrok

fbshipit-source-id: 4d0d827bff518c017b115445e03bdf0bf1e68320",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp']",False,25,10,2022
9cc592839898a8836f43fc37705312164fc65bdb,"Remove archive file in gh-pages branch (#2786)

Summary:
The motivation of generating `artifact.tar.gz` in the `build_docs` job is to easily use it for adding documentation in each stable release. But it is committed into `gh-pages` branch which causes the git repository very huge (see https://github.com/pytorch/audio/issues/2783). This PR removes the tar file from the commit.

Pull Request resolved: https://github.com/pytorch/audio/pull/2786

Reviewed By: carolineechen

Differential Revision: D40591152

Pulled By: nateanl

fbshipit-source-id: 47df60c2ec7bcdcc40e2b6078219b9397e6bfed1",Zhaoheng Ni,zni@fb.com,['.circleci/build_docs/commit_docs.sh'],False,21,10,2022
7d7ae0a1b0df87ce8ac123cd8b97ade6b15bac2f,"Fix doc in torchaudio.backend (#2781)

Summary:
address https://github.com/pytorch/audio/issues/2780

Pull Request resolved: https://github.com/pytorch/audio/pull/2781

Reviewed By: carolineechen, mthrok

Differential Revision: D40556794

Pulled By: nateanl

fbshipit-source-id: b24912489d41e5663b4b4dcfb8be743fb962097e",Zhaoheng Ni,zni@fb.com,['docs/source/backend.rst'],True,20,10,2022
e77b8f909154d0361afe9a3420a17fc41e74e9d6,"Bump version to 0.14 (#2779)

Summary:
Bump version to 0.14

Pull Request resolved: https://github.com/pytorch/audio/pull/2779

Reviewed By: carolineechen

Differential Revision: D40523034

Pulled By: atalman

fbshipit-source-id: 325e6ffcac4763a7d83ba600c2c3d9eadae03c31",atalman,atalman@fb.com,['version.txt'],False,19,10,2022
342553861b97ba66bb9522e7ca5931aae52eb08a,"Add iemocap variants (#2778)

Summary:
add ability to load only improvised or only scripted utterances.

Pull Request resolved: https://github.com/pytorch/audio/pull/2778

Reviewed By: nateanl

Differential Revision: D40511865

Pulled By: carolineechen

fbshipit-source-id: e1fe3908ac2aa306ad30c242ddd25762b2268539",Caroline Chen,carolinechen@fb.com,"['test/torchaudio_unittest/datasets/iemocap_test.py', 'torchaudio/datasets/iemocap.py']",False,19,10,2022
9135b544f343007025db7db007ecd13666de896b,"[Nova] Clean commit for Enabling Nova Linux Wheels Workflows (#2719)

Summary:
Creating this fresh PR since we're reverting the older commit that removed build configs from the CircleCI file. This does not change the existing builds/uploads in CircleCI, and should not break any existing jobs/workflows. This is just to add back workflows to build the Linux Wheels with Nova, upload them to GH artifacts (NOT to the actual nightly channels), and ensure that they produce the same binaries as CircleCI. TO CLARIFY: this does not upload anything to nightly channels, so this PR has not effect on any existing jobs or distributed binaries.

We will create a workflow (most likely in test-infra) that does this comparison between the binaries to ensure there is parity between the binaries before we start uploading with Nova.

Pull Request resolved: https://github.com/pytorch/audio/pull/2719

Reviewed By: hwangjeff, weiwangmeta

Differential Revision: D39866440

Pulled By: osalpekar

fbshipit-source-id: 9ebf0402214fcd97cc519801276d85d336617410",Omkar Salpekar,osalpekar@fb.com,['.github/workflows/build_wheels_linux.yml'],True,19,10,2022
0262313c4a86bde64e735fa4e70abb0e5de31299,"[Nova] New GHA Workflow for Docstring Sync (#2720)

Summary:
Create a standalone GitHub Actions workflow for Docstring Sync. This job (https://app.circleci.com/pipelines/github/pytorch/audio/12625/workflows/96223ad2-0fcd-4dae-a045-d530aaf9b55c/jobs/907466) currently depends on linux wheels builds, which creates a dependency that makes the migration to Nova trickier. This PR creates a fresh standalone workflow for this job that is triggered per-PR and before nightly/release cuts.

Pull Request resolved: https://github.com/pytorch/audio/pull/2720

Reviewed By: izaitsevfb, seemethere

Differential Revision: D39863574

Pulled By: osalpekar

fbshipit-source-id: 8599dc006693242278857a3dedeb4fddc1eed14b",Omkar Salpekar,osalpekar@fb.com,['.github/workflows/docstring_parameters_sync.yml'],False,19,10,2022
26606848ed73250579b75e481c082ba0fa2cfebc,"Add notes on file structure in Voxceleb1 based datasets (#2776)

Summary:
The file structure of VoxCeleb1 is as follows:
```
root/
└── wav/
    └── speaker_id folders
```
Users who use [Kaldi](https://github.com/kaldi-asr/kaldi/blob/f6f4ccaf213f0fe8b26e633a7dc0c802150626a0/egs/voxceleb/v1/local/make_voxceleb1_v2.pl) to get the VoxCeleb1 dataset have ""dev"" and ""test"" folders above ""wav"" folder. However, in the file lists like https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt or https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/iden_split.txt there is not such differentiation. It's not necessary to put the extracted files into separate folders.

This PR adds notes in `VoxCeleb1Identification` and `VoxCeleb1Verification` datasets to inform the file structure to users.

Pull Request resolved: https://github.com/pytorch/audio/pull/2776

Reviewed By: carolineechen

Differential Revision: D40483707

Pulled By: nateanl

fbshipit-source-id: ccd1780a72a5b53f0300c2466c3073a293ad7b8d",Zhaoheng Ni,zni@fb.com,['torchaudio/datasets/voxceleb1.py'],False,19,10,2022
e947175dacc74fa97829e167fe024cee92a7225f,"Update download path for speechcommands (#2777)

Summary:
previous download link for v0.02 did not download the entire dataset, but only the training dataset, resulting in issues when trying to access the testing or validation data.

Pull Request resolved: https://github.com/pytorch/audio/pull/2777

Reviewed By: nateanl

Differential Revision: D40480605

Pulled By: carolineechen

fbshipit-source-id: a594506b4ccfb548a7d5043b716c58463480c103",Caroline Chen,carolinechen@fb.com,['torchaudio/datasets/speechcommands.py'],False,19,10,2022
e8ae0ad22d5136e8252e4e9f5fe6dc38522dc880,"Add file_name to the returned item in Snips dataset (#2775)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2775

Reviewed By: carolineechen

Differential Revision: D40481144

Pulled By: nateanl

fbshipit-source-id: 5d0fb2478767704603a3ec28d74160e7892d4d0e",Zhaoheng Ni,zni@fb.com,"['test/torchaudio_unittest/datasets/snips_test.py', 'torchaudio/datasets/snips.py']",False,19,10,2022
0c8dfe9675c4f5e1eb280952037cf482033963ac,"Update description of HDemucs pipelines (#2774)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2774

Reviewed By: carolineechen

Differential Revision: D40445274

Pulled By: nateanl

fbshipit-source-id: 6388323a5fa5c548a86829cb3f7cafee5382d18d",nateanl,zni@fb.com,['torchaudio/pipelines/_source_separation_pipeline.py'],False,18,10,2022
8f187354971e45438b080d18555c8a7b55379cbf,"Update resampling tutorial (#2773)

Summary:
* Refactor benchmark script
* Rename `time` variable to avoid (potential) conflicting with time module
* Fix `beta` parameter in benchmark (it was not used previously)
* Use `timeit` module for benchmark
* Add plot
* Move the comment on result at the end
* Add link to an explanation of aliasing

https://output.circle-artifacts.com/output/job/20b57d2f-3614-4161-a18e-e0c1a537739c/artifacts/0/docs/tutorials/audio_resampling_tutorial.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2773

Reviewed By: carolineechen

Differential Revision: D40421337

Pulled By: mthrok

fbshipit-source-id: b402f84d4517695daeca75fb84ad876ef9354b3a",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/audio_resampling_tutorial.py'],False,17,10,2022
5239583e855ea031bcd34c6b7cb658a80325b8ed,"Fix leaking matplotlib figure (#2771)

Summary:
In StreamWriter basic usage tutorial, matplotlib is used to generate raster images of waveforms, and the figure used is left unshown in the resulting tutorial with the use of ``sphinx_gallery_defer_figures`` command.

It turned out that this figure is shown in the next code block executed by Sphinx Gallery, and the figure is placed in totally unrelated place. https://pytorch.org/audio/main/tutorials/audio_feature_extractions_tutorial.html

<img width=""951"" alt=""Screen Shot 2022-10-14 at 10 06 58 PM"" src=""https://user-images.githubusercontent.com/855818/195855124-ecd9be49-5085-4acd-9a93-608d9d1ee9ce.png"">

This commit fixes it by closing the figure.

Pull Request resolved: https://github.com/pytorch/audio/pull/2771

Reviewed By: nateanl

Differential Revision: D40382076

Pulled By: mthrok

fbshipit-source-id: 015f2bab8492d3b4fbe70e1174c7776a5aa2679a",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/streamwriter_basic_tutorial.py'],True,14,10,2022
000d7526def96d08a25110ea45bd564ef361e670,"Fix fading in hybrid demucs tutorial (#2769)

Summary:
The separation applies on chunks of audios to avoid OOM. The combination of consecutive chunks is described in the graph:

![image](https://user-images.githubusercontent.com/8653221/195691886-002844e6-4ec5-41de-8910-df8046553998.png)

In the last audio chunk, there is no future chunk to be combined, hence the overlap on the right side doesn't need to be faded.

Pull Request resolved: https://github.com/pytorch/audio/pull/2769

Reviewed By: carolineechen

Differential Revision: D40358382

Pulled By: nateanl

fbshipit-source-id: ec8be895d7a67acb257e2693b64922397163ed5e",nateanl,zni@fb.com,['examples/tutorials/hybrid_demucs_tutorial.py'],True,14,10,2022
3e4b961dbaa105e83c060a4722b942289a6da118,"Fix CTCDecoder doc (#2766)

Summary:
* Document `__call__` instead of `__init__`
* List CTCHypothesis first as it is used in combination with CTCDecoder
* Fix indentation of score method docstring

Pull Request resolved: https://github.com/pytorch/audio/pull/2766

Reviewed By: carolineechen

Differential Revision: D40349388

Pulled By: mthrok

fbshipit-source-id: 5e512e6c2b29d3533eb62d09b289154ccd1abf4c",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/ctc_decoder_class.rst', 'torchaudio/models/decoder/_ctc_decoder.py']",False,13,10,2022
3a5a83d93081d5262fff41a7516e920e8fd95046,"Add custom lm example to decoder tutorial (#2762)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2762

Reviewed By: mthrok

Differential Revision: D40332603

Pulled By: carolineechen

fbshipit-source-id: 2de51265adc81b4728f4d6798d287bd2eccf5251",Caroline Chen,carolinechen@fb.com,['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py'],False,13,10,2022
fb82ac0b9ef2783c27ffaf2bd5dc60450064ee68,"Update tutorial author information (#2764)

Summary:
Adding and updating author information.

Pull Request resolved: https://github.com/pytorch/audio/pull/2764

Reviewed By: carolineechen

Differential Revision: D40332427

Pulled By: mthrok

fbshipit-source-id: 4f04c7351386c122e3b0a45c2ed1757a04b7dc9a",moto,855818+mthrok@users.noreply.github.com,"['docs/source/hw_acceleration_tutorial.ipynb', 'examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'examples/tutorials/audio_data_augmentation_tutorial.py', 'examples/tutorials/audio_datasets_tutorial.py', 'examples/tutorials/audio_feature_augmentation_tutorial.py', 'examples/tutorials/audio_feature_extractions_tutorial.py', 'examples/tutorials/audio_io_tutorial.py', 'examples/tutorials/audio_resampling_tutorial.py', 'examples/tutorials/device_asr.py', 'examples/tutorials/forced_alignment_tutorial.py', 'examples/tutorials/mvdr_tutorial.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/speech_recognition_pipeline_tutorial.py', 'examples/tutorials/streamreader_advanced_tutorial.py', 'examples/tutorials/streamreader_basic_tutorial.py', 'examples/tutorials/streamwriter_advanced.py', 'examples/tutorials/streamwriter_basic_tutorial.py', 'examples/tutorials/tacotron2_pipeline_tutorial.py']",False,13,10,2022
a9687c220b347db8425e223e45a576b2b998806f,"Add gtzan download note (#2763)

Summary:
GTZAN download link is no longer working, so the torchaudio download functionality for GTZAN does not work properly, per https://github.com/pytorch/audio/issues/2743. Add a note in the docs to reflect this discovery.

Pull Request resolved: https://github.com/pytorch/audio/pull/2763

Reviewed By: nateanl, mthrok

Differential Revision: D40315071

Pulled By: carolineechen

fbshipit-source-id: 3250326c45d227546a9c62b33ba890199ad19242",Caroline Chen,carolinechen@fb.com,['torchaudio/datasets/gtzan.py'],False,13,10,2022
7aabcbd4335c7aab17c27f6f024050b48b2af0ec,"Fix typos in tacotron2 tutorial (#2761)

Summary:
`publishe`->`published`

Also, not sure if it should be `pre-trained weight is published` or `pre-trained weights are published`

Pull Request resolved: https://github.com/pytorch/audio/pull/2761

Reviewed By: carolineechen

Differential Revision: D40313042

Pulled By: malfet

fbshipit-source-id: c22085ca0b1125a06aa04bf38231d0a9fbfed00b",Nikita Shulga,nshulga@fb.com,['examples/tutorials/tacotron2_pipeline_tutorial.py'],True,12,10,2022
274330505ebb9329418bf7c5f2bb4d43bb803113,"Improve hubert recipe for pre-training and fine-tuning (#2744)

Summary:
following pr https://github.com/pytorch/audio/issues/2716
- For preprocessing
  - The HuBERT feature takes lots of memory which may not fit some machines. Enable to use a subset of feature for training a k-means model.

- For pre-training
  - Normalize the loss based on the total number of masked frames across all GPUs.
  - Use mixed precision training. fp16 is not well supported in pytorch_lightning.
  - Log accuracies of masked/unmasked frames during training.
  - Clip the gradients with norm `10.0`.

- For ASR fine-tuning
  - Normalize the loss based on the total number of batches across all GPUs, same as in the conformer recipe of TorchAudio.
  - Use mixed precision training.
  - Add ""|"" after the end of transcription to capture the silence/word termination, same as in fairseq recipe.

- Update the WER results on LibriSpeech dev and test sets.

|                   | WER% (Viterbi)|  WER% (KenLM) |
|:-----------------:|--------------:|--------------:|
| dev-clean         |       10.9    |       4.2     |
| dev-other         |       17.5    |       9.4     |
| test-clean        |       10.9    |       4.4     |
| test-other        |       17.8    |       9.5     |

Pull Request resolved: https://github.com/pytorch/audio/pull/2744

Reviewed By: carolineechen

Differential Revision: D40282322

Pulled By: nateanl

fbshipit-source-id: 4723584c912e70e8970149fe09de005385eaab90",Zhaoheng Ni,zni@fb.com,"['examples/hubert/README.md', 'examples/hubert/dataset/hubert_dataset.py', 'examples/hubert/evaluate.py', 'examples/hubert/finetune.py', 'examples/hubert/lightning.py', 'examples/hubert/preprocess.py', 'examples/hubert/train.py', 'examples/hubert/utils/feature_utils.py', 'examples/hubert/utils/kmeans.py']",False,12,10,2022
c5bd93b6c274664167a1118e7e14c71920d7fad2,"Improve wav2vec2/hubert model for pre-training (#2716)

Summary:
This PR improves the Wav2Vec2/HuBERT model regarding model pre-training.

- The model initialization of positional embedding and transformer module is essential to model pre-training. The accuracy of unmasked frames should be higher than masked frames, as it is an easier task. but without the initialization, the accuracy of masked frames is higher than unmasked frames.
  Compared the performance after two epochs with 16 GPUs.
  - With model initialization, the accuracies of masked/unmasked frames are 0.08/0.11.
  - Without model initialization, the accuracies of masked/unmasked frames are 0.06/0.04.
- After adding the model initialization, the gradient is easy to overflow (aka `nan` gradient). In paper [Self-Supervised Learning for speech recognition with Intermediate layer supervision](https://arxiv.org/abs/2112.08778) the authors propose a simple but effective method to mitigate the overflow issue, by scaling down the multiplication of query and key and subtracting the maximum value from it (subtracting a constant value won't change the output of softmax). Then it guarantees the value won't be overflowed.
- In the original fairseq, the mask indices are generated by `numpy.random.choice`. Here replace `torch.multinomial` with `torch.randperm`. (cc carolineechen).

Other improvements within training scripts will be included in a separate PR.

Pull Request resolved: https://github.com/pytorch/audio/pull/2716

Reviewed By: xiaohui-zhang

Differential Revision: D39832189

Pulled By: nateanl

fbshipit-source-id: f4d2a473a79ad63add2dd16624bd155d5ce4de27",Zhaoheng Ni,zni@fb.com,"['torchaudio/models/wav2vec2/components.py', 'torchaudio/models/wav2vec2/model.py']",False,12,10,2022
c2ea6898bd91975cc13004d63908eddbb7f4d28e,"Skip hubert xlarge torchscript test (#2758)

Summary:
a couple of circleci unittests are failing during hubert xlarge torchscript test, which has been known to fail on Windows in the past (#65776). this PR disables this test on circleci

cc atalman

Pull Request resolved: https://github.com/pytorch/audio/pull/2758

Reviewed By: mthrok

Differential Revision: D40290535

Pulled By: carolineechen

fbshipit-source-id: 5c5fb43434a517b6c439a8cb8e853015d1550a57",Caroline Chen,carolinechen@fb.com,['test/torchaudio_unittest/models/wav2vec2/model_test.py'],True,12,10,2022
d735b078d5094734ce7d13070b8653c97d0c452b,"Increase inactivity timeout for binary build jobs (#2754)

Summary:
Increase inactivity timeout for binary build jobs

Pull Request resolved: https://github.com/pytorch/audio/pull/2754

Reviewed By: carolineechen

Differential Revision: D40275368

Pulled By: atalman

fbshipit-source-id: 5e682bb78bda640d615f874fbdf0e650b5a38ee0",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,11,10,2022
67e64225c54715ecc9733712c5f08d2a1f03539f,"Add metadata for Librimix (#2751)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2751

Reviewed By: nateanl

Differential Revision: D40267874

Pulled By: carolineechen

fbshipit-source-id: 4e45a02c650ed65c05cde82289a400a3be877927",Caroline Chen,carolinechen@fb.com,['torchaudio/datasets/librimix.py'],False,11,10,2022
c38229d447f55532a1bdffdbbe7832d16cd0de5e,"Fix windows python 3.8 loading path (#2747)

Summary:
Fix windows python 3.8 loading path

Pull Request resolved: https://github.com/pytorch/audio/pull/2747

Reviewed By: nateanl

Differential Revision: D40264326

Pulled By: nateanl

fbshipit-source-id: f4a24757de7b48c63a7481034eb11fc3ff174327",atalman,atalman@fb.com,['torchaudio/_extension.py'],False,11,10,2022
841879099cedbe15addb7f19f17e276cab5bf535,"Add Snips Dataset (#2738)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2738

Reviewed By: carolineechen

Differential Revision: D40238099

Pulled By: nateanl

fbshipit-source-id: c5cc94c2a348a6ef34c04b8dd26114ecb874d73e",Zhaoheng Ni,zni@fb.com,"['docs/source/datasets.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/datasets/snips_test.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/snips.py']",False,11,10,2022
c5b8e58551138dbe3d275ec65974c84d30affbfb,"Add unit test for LibriMix dataset (#2659)

Summary:
Besides the unit test, the PR also addresses these issues:
- The original `LibriMix` dataset only supports ""min"" mode, which means the audio length is the minimum of all clean sources. It is default for source separation task. Users may also want to use ""max"" mode which allows for end-to-end separation and recognition. The PR adds ``mode`` argument to let users decide which dataset they want to use.
- If the task is ``""enh_both""``, the target is the audios in ``mix_clean`` instead of separate clean sources. The PR fixes it to use ``mix_clean`` as target.

Pull Request resolved: https://github.com/pytorch/audio/pull/2659

Reviewed By: carolineechen

Differential Revision: D40229227

Pulled By: nateanl

fbshipit-source-id: fc07e0d88a245e1367656d3767cf98168a799235",Zhaoheng Ni,zni@fb.com,"['test/torchaudio_unittest/datasets/librimix_test.py', 'torchaudio/datasets/librimix.py']",False,10,10,2022
be938e7e6d608f7355e5979b9810b211b4cf7b25,"Fix HuBERT docstring (#2746)

Summary:
The docstring of `wav2vec2` argument is wrong. Fix it in this PR.

Pull Request resolved: https://github.com/pytorch/audio/pull/2746

Reviewed By: carolineechen

Differential Revision: D40225995

Pulled By: nateanl

fbshipit-source-id: 770e9c928ebebd7b6307e181601eb64625d668da",Zhaoheng Ni,zni@fb.com,['torchaudio/models/wav2vec2/model.py'],False,10,10,2022
0b4b1fd4296fd7d54f0059a23cf9c9e168ad9376,"Add IEMOCAP dataset (#2732)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2732

Reviewed By: nateanl

Differential Revision: D40186996

Pulled By: nateanl

fbshipit-source-id: a0ad325b7153c9e580dad2c515730dadbe8840c4",Caroline Chen,carolinechen@fb.com,"['docs/source/datasets.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/datasets/iemocap_test.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/iemocap.py']",False,9,10,2022
4609daf73a553f498cf347de4892d91fd7daa908,"Update HW video processing tutorial (#2739)

Summary:
* Add HW encoding to HW tutorial

https://colab.research.google.com/drive/1DDah_IaGULEO66CfQWltRqaVheBkiXdN#scrollTo=eXzKSVrHk1vS

Pull Request resolved: https://github.com/pytorch/audio/pull/2739

Reviewed By: hwangjeff

Differential Revision: D40197086

Pulled By: hwangjeff

fbshipit-source-id: 1780a5419f6705f7c24ba96bd46c3310438af7db",moto,855818+mthrok@users.noreply.github.com,['docs/source/hw_acceleration_tutorial.ipynb'],False,8,10,2022
8ef6de9feaa6618ab64f1fe2983cf392aa2908fa,"Update sox info docstring to account for mp3 frame count handling (#2742)

Summary:
Updates sox info docstring to account for mp3 frame count handling fix introduced in https://github.com/pytorch/audio/issues/2740.

Pull Request resolved: https://github.com/pytorch/audio/pull/2742

Reviewed By: nateanl

Differential Revision: D40189846

Pulled By: nateanl

fbshipit-source-id: d6371418d7d4867dd0b97ee72ebf846d5c93dc30",hwangjeff,jeffhwang@meta.com,['torchaudio/backend/sox_io_backend.py'],False,7,10,2022
7729723b868112d72b45926daacc3f03483b1f63,"Modify `info_audio` to compute and return number of frames if not found in stream info (#2740)

Summary:
Modifies `info_audio` to compute and return number of frames if not found in stream info. This resolves the `num_frames == 0` issue for mp3 that's cited in https://github.com/pytorch/audio/issues/2524.

Pull Request resolved: https://github.com/pytorch/audio/pull/2740

Reviewed By: nateanl

Differential Revision: D40168639

Pulled By: nateanl

fbshipit-source-id: bb45baa0f9cd56844315b04e40ab9835d825fc24",hwangjeff,iamjeffhwang@gmail.com,"['test/torchaudio_unittest/backend/sox_io/info_test.py', 'torchaudio/io/_compat.py']",False,7,10,2022
1a18c41dc42438fed6948804c72903c8c441215a,"Fix sphinx gallery list in io doc (#2736)

Summary:
Specifying multiple object in `:minigallery:` directive shows duplicated tutorials.

This commit fixes it by listing tutorials based on module used.

https://output.circle-artifacts.com/output/job/c3da2a22-40d5-4e2d-b73a-28b39e712817/artifacts/0/docs/io.html

Before:
<img width=""694"" alt=""Screen Shot 2022-10-07 at 7 04 35 AM"" src=""https://user-images.githubusercontent.com/855818/194427092-ca1202e7-0731-4c18-b48b-24923d692a4a.png"">

After:

<img width=""648"" alt=""Screen Shot 2022-10-07 at 7 03 14 AM"" src=""https://user-images.githubusercontent.com/855818/194426950-5b780458-2bf0-43ef-b020-fcbbfdf8d41b.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2736

Reviewed By: carolineechen

Differential Revision: D40160247

Pulled By: carolineechen

fbshipit-source-id: 547496f9b569ff7a4d70db97e90f3ea503344477",moto,855818+mthrok@users.noreply.github.com,"['docs/source/io.rst', 'examples/tutorials/device_asr.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streamreader_advanced_tutorial.py', 'examples/tutorials/streamreader_basic_tutorial.py', 'examples/tutorials/streamwriter_advanced.py', 'examples/tutorials/streamwriter_basic_tutorial.py']",False,7,10,2022
0c5a8bf7c25c53ee14f48c33bc31e3390e6ae48e,"Add StreamWriter tutorial (#2698)

Summary:
Add a tutorial for basic usage of torchaudio.io.StreamWriter.

https://output.circle-artifacts.com/output/job/55d9a495-af7a-483c-84cb-de9a08cfd2f3/artifacts/0/docs/tutorials/streamwriter_basic_tutorial.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2698

Reviewed By: carolineechen

Differential Revision: D40133007

Pulled By: carolineechen

fbshipit-source-id: 141f692c32343981bfb228357f21562ffe36f623",moto,855818+mthrok@users.noreply.github.com,"['docs/source/tutorials.io.rst', 'examples/tutorials/streamwriter_basic_tutorial.py', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/io/_stream_writer.py']",False,6,10,2022
fdbf14502b43271dbe67b19f5422568bc7fb534a,"Torchaudio load libary path fix for windows python 3.8 (#2735)

Summary:
Torchaudio load libary path fix for windows and python = 3.8

Fixes: https://github.com/pytorch/audio/issues/2726

Fixes following issue:

```
>>> import torchaudio
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\atalman\miniconda3\envs\mywin38\lib\site-packages\torchaudio\__init__.py"", line 1, in <module>
    from torchaudio import (  # noqa: F401
  File ""C:\Users\atalman\miniconda3\envs\mywin38\lib\site-packages\torchaudio\_extension.py"", line 128, in <module>
    _init_extension()
  File ""C:\Users\atalman\miniconda3\envs\mywin38\lib\site-packages\torchaudio\_extension.py"", line 98, in _init_extension
    _load_lib(""libtorchaudio"")
  File ""C:\Users\atalman\miniconda3\envs\mywin38\lib\site-packages\torchaudio\_extension.py"", line 52, in _load_lib
    torch.ops.load_library(path)
  File ""C:\Users\atalman\miniconda3\envs\mywin38\lib\site-packages\torch\_ops.py"", line 573, in load_library
    ctypes.CDLL(path)
  File ""C:\Users\atalman\miniconda3\envs\mywin38\lib\ctypes\__init__.py"", line 373, in __init__
    self._handle = _dlopen(self._name, mode)
FileNotFoundError: Could not find module 'C:\Users\atalman\miniconda3\envs\mywin38\Lib\site-packages\torchaudio\lib\libtorchaudio.pyd' (or one of its dependencies). Try using the full path with constructor syntax.
>>>
```

Caused by dlls not being found in the conda environment
```
C:\Users\atalman\miniconda3\envs\mywin38\bin\
```

While this environment is set correctly in PATH its ignored with Python = 3.8
Please refer to: https://stackoverflow.com/questions/59330863/cant-import-dll-module-in-python

Pull Request resolved: https://github.com/pytorch/audio/pull/2735

Reviewed By: carolineechen

Differential Revision: D40112293

Pulled By: carolineechen

fbshipit-source-id: c7fc9bb49fc3ec4a2855c6ea473f36808103ed1e",atalman,atalman@fb.com,['torchaudio/_extension.py'],False,6,10,2022
856552a55d00b5413f9f66d9c76503f592ff3b6a,"Increase CircleCi no_output_timeout for `install binaries` steps (#2734)

Summary:
The goal is to to reduce the number of job failures due to timeouts, see https://app.circleci.com/pipelines/github/pytorch/audio/12882/workflows/f99da1a5-32e6-4bac-8ceb-fbf36d693e2d/jobs/936363?invite=true#step-105-105 for example.

Pull Request resolved: https://github.com/pytorch/audio/pull/2734

Reviewed By: weiwangmeta, atalman

Differential Revision: D40077578

fbshipit-source-id: 573f43a4d088a7086fa6925ac5ba1fdd1e8f39ec",Ivan Zaitsev,ivanzaitsev@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,6,10,2022
b076abd17bb93a61ef9cc7d4265dab8b1e154dd8,"Tweak tutorials (#2733)

Summary:
* Port downstream change https://github.com/pytorch/tutorials/pull/2060
* Fix inter-tutorial links and references

Pull Request resolved: https://github.com/pytorch/audio/pull/2733

Reviewed By: hwangjeff

Differential Revision: D40086902

Pulled By: hwangjeff

fbshipit-source-id: 00b04c6a1b68fb9fadd52b610b26ecaab15d52d8",moto,855818+mthrok@users.noreply.github.com,"['docs/source/conf.py', 'examples/tutorials/device_asr.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streamreader_advanced_tutorial.py', 'examples/tutorials/streamreader_basic_tutorial.py', 'examples/tutorials/tacotron2_pipeline_tutorial.py']",False,5,10,2022
fda00bf7bfe0b6a3a67ae0274a892299fdbefc4f,"Add StreamWriter media device/streaming tutorial (#2708)

Summary:
https://output.circle-artifacts.com/output/job/213c71c8-c9b5-4516-af92-a2f8dab2c9fd/artifacts/0/docs/tutorials/streamwriter_advanced.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2708

Reviewed By: carolineechen

Differential Revision: D40013310

Pulled By: mthrok

fbshipit-source-id: 7226b021ce2fe951b3bf0bd41e93a6bbcf696124",moto,855818+mthrok@users.noreply.github.com,"['docs/source/tutorials.io.rst', 'examples/tutorials/streamwriter_advanced.py']",False,3,10,2022
ef1ba56ff7177868df588636bf994526444eca64,"Adopt :autosummary: to multiple modules (#2664)

Summary:
Adopt `:autosummary:` to various modules

    * torchaudio.compliance.kaldi
    * torchaudio.sox_effects
    * torchaudio.utils

Pull Request resolved: https://github.com/pytorch/audio/pull/2664

Reviewed By: nateanl

Differential Revision: D39841873

Pulled By: mthrok

fbshipit-source-id: ff4fa6976324fca5f35b737b715f976e2a722bac",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/utils.rst', 'docs/source/backend.rst', 'docs/source/compliance.kaldi.rst', 'docs/source/sox_effects.rst', 'docs/source/utils.rst', 'torchaudio/backend/common.py', 'torchaudio/utils/ffmpeg_utils.py', 'torchaudio/utils/sox_utils.py']",False,3,10,2022
6db69ef9724a4c7df4592d84af0eb042b20f738a,"Add citation for MuST-C dataset in Emformer RNNT pipeline. (#2728)

Summary:
The MuST-C reference is added in https://github.com/pytorch/audio/pull/2689. This PR adds the citation to the RNNT pipeline documentation.

Pull Request resolved: https://github.com/pytorch/audio/pull/2728

Reviewed By: carolineechen

Differential Revision: D39990882

Pulled By: nateanl

fbshipit-source-id: 011057952dd8aa30a4cb7c7af0ac75123e329d7e",Zhaoheng Ni,zni@fb.com,['torchaudio/prototype/pipelines/rnnt_pipeline.py'],False,3,10,2022
6b2b6c79ca029b4aa9bdb72d12ad061b144c2410,"Delete packaging/README.md (#2730)

Summary:
The file looks hopelessly outdated.

Pull Request resolved: https://github.com/pytorch/audio/pull/2730

Reviewed By: mthrok

Differential Revision: D39993805

Pulled By: kit1980

fbshipit-source-id: f5ad97c83873061175455cc7b129ec71a9ec3d7d",Sergii Dymchenko,kit1980@gmail.com,['packaging/README.md'],False,1,10,2022
fd44cac5ef3fd9c4385c3bccf131293b8af26774,"Cuda 102 deprecation (#2724)

Summary:
Cuda 10.2 deprecation, migration of unit tests from cuda 10.2 to cuda 11.6

Pull Request resolved: https://github.com/pytorch/audio/pull/2724

Reviewed By: weiwangmeta

Differential Revision: D39912484

Pulled By: atalman

fbshipit-source-id: e760b630375eae94384cda68d24f83ef46ada6d9",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.circleci/unittest/linux/scripts/install.sh', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",False,29,9,2022
4625408a4b16a6bca1f739741c254c9618d0d41d,"Revert ""Removing cuda102 (#2715)"" (#2723)

Summary:
Revert this fot now untill docker is updated

Pull Request resolved: https://github.com/pytorch/audio/pull/2723

Reviewed By: nateanl

Differential Revision: D39900382

Pulled By: atalman

fbshipit-source-id: f8701e359bc11e8f9f3a29144f7e7da336a470da",atalman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",False,28,9,2022
f52d4fb1a419234089288f5c2043e3f129f12164,"Removing cuda102 (#2715)

Summary:
Removing cuda102

Pull Request resolved: https://github.com/pytorch/audio/pull/2715

Reviewed By: hwangjeff

Differential Revision: D39823444

Pulled By: atalman

fbshipit-source-id: c11d798ab86cf9a6d5ed3804958b4a0c2f8a87ff",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",False,28,9,2022
25ed2936f61c820a1d7a19b01ee8ebf6f81970c6,"Fix mismatched cuda version in smoke tests on windows wheels (#2721)

Summary:
Example job that was failing previously:
https://app.circleci.com/pipelines/github/pytorch/audio/12796/workflows/ae96794a-6df4-4a2a-84df-ada7a7250045/jobs/927709

The failure:
```
""Detected that PyTorch and TorchAudio were compiled with different CUDA versions. ""
RuntimeError: Detected that PyTorch and TorchAudio were compiled with different CUDA versions. PyTorch has CUDA version 11.7 whereas TorchAudio has CUDA version 11.6. Please install the TorchAudio version that matches your PyTorch version.
```

Has install command:
```
pip install $(ls ~/workspace/torchaudio*.whl) -f ""https://download.pytorch.org/whl/${UPLOAD_CHANNEL}/torch_${UPLOAD_CHANNEL}.html""

# expands to:
pip install /c/Users/circleci/workspace/torchaudio-0.13.0.dev20220927+cu116-cp37-cp37m-win_amd64.whl -f https://download.pytorch.org/whl/nightly/torch_nightly.html
```

Linux job (succeeds) for uses different ""-f"" (find links) url, that includes specific cuda version:
https://app.circleci.com/pipelines/github/pytorch/audio/12809/workflows/aadca2ab-5a00-4a0a-ab6a-4a1b7a503713/jobs/927861

Command:
```
pip install $(ls ~/workspace/torchaudio*.whl) -f ""https://download.pytorch.org/whl/${UPLOAD_CHANNEL}/${CU_VERSION}/torch_${UPLOAD_CHANNEL}.html""

# expands to:
 pip install /root/workspace/torchaudio-0.13.0.dev20220927+cu116-cp37-cp37m-linux_x86_64.whl -f https://download.pytorch.org/whl/nightly/cu116/torch_nightly.html

```

This PR makes Windows installation match the linux one.

Testing:
* verified command manually on Circle CI:
```
>>> import torch
>>> import torchaudio
C:\tools\miniconda3\lib\site-packages\torchaudio\compliance\kaldi.py:22: UserWarning: Failed to initialize NumPy: numpy.core.multiarray failed to import (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\torch\csrc\utils\tensor_numpy.cpp:77.)
  EPSILON = torch.tensor(torch.finfo(torch.float).eps)
C:\tools\miniconda3\lib\site-packages\torchaudio\backend\utils.py:62: UserWarning: No audio backend is available.
  warnings.warn(""No audio backend is available."")
```

Co-authered: weiwangmeta

Pull Request resolved: https://github.com/pytorch/audio/pull/2721

Reviewed By: hwangjeff

Differential Revision: D39870805

Pulled By: izaitsevfb

fbshipit-source-id: 2957cba4f53d00783a5c07099f24050ce15e7d1c",Ivan Zaitsev,ivanzaitsev@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,28,9,2022
08a5adb2189abbf270023a9d2680b75c300ded83,"Back out ""[audio][PR] [Nova] Moving Linux Wheels over to Nova"" (#2718)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2718

Original commit changeset: 7e222d80ca07

Original Phabricator Diff: D39756852 (https://github.com/pytorch/audio/commit/7ba7cf4d24a2967b8fa4aaff437116524281f8fd)

Reviewed By: weiwangmeta

Differential Revision: D39839899

fbshipit-source-id: f5605eb9882f7c7f0008e88338ab711131b29404",Omkar Salpekar,osalpekar@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.github/workflows/build_wheels_linux.yml']",False,27,9,2022
539476e246270b0be5614156cc2a5b0d2de98bcf,"[Nova] Add build-type argument for when upload should be triggered (#2706)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2706

Reviewed By: kit1980

Differential Revision: D39786253

Pulled By: osalpekar

fbshipit-source-id: 2a0c427f57e5c70ff1cf419b7e0c2316e5f0e16c",Omkar Salpekar,osalpekar@fb.com,['.github/workflows/build_wheels_linux.yml'],False,27,9,2022
1c8accfc3a60aa2afeacfd04f1fdd6024e3e4f7c,"Fix windows tests related to old conda on circleci (#2704)

Summary:
Conda version on circleCI prints following message:
```
==> WARNING: A newer version of conda exists. <==
  current version: 4.6.14
  latest version: 4.14.0
```
and as a result this error:

```
+ /c/tools/miniconda3/Scripts/conda.exe install -v -y -c pytorch-nightly -c nvidia pytorch numpy ffmpeg pytorch-cuda=11.6
Collecting package metadata: ...working... done
Solving environment: ...working...

Too long with no output (exceeded 30m0s): context deadline exceeded
```

This should update the conda version running on the system and allow us to install pytorch and run some tests.

Pull Request resolved: https://github.com/pytorch/audio/pull/2704

Reviewed By: weiwangmeta

Differential Revision: D39820037

Pulled By: atalman

fbshipit-source-id: 4a82a7a6cbe3dc1a5807ac669e2fa79f454037fa",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,26,9,2022
14714f2975cfd14260989995c0ac99e1395b3c74,"Remove linux wheel from circleci (#2714)

Summary:
Remove linux wheel from circleci

Pull Request resolved: https://github.com/pytorch/audio/pull/2714

Reviewed By: weiwangmeta

Differential Revision: D39816121

Pulled By: atalman

fbshipit-source-id: a3c99b530896888d7b4271d8b3f27f3c986b3480",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py']",False,26,9,2022
ce08f8d2cf3f51a13f80cef09e7d0e6f8a09bfb6,"Fix CUDA check (#2710)

Summary:
`torch.version.cuda` can return a string of form X.X or X.X.X. This PR modifies the CUDA version check to account for this.

Pull Request resolved: https://github.com/pytorch/audio/pull/2710

Reviewed By: carolineechen, nateanl

Differential Revision: D39796810

Pulled By: hwangjeff

fbshipit-source-id: b483bd8200195844d65d0caddebaf1b10f939b64",hwangjeff,iamjeffhwang@gmail.com,['torchaudio/_extension.py'],False,24,9,2022
0a5825aef414c84507445e9a80b18dd786d4f5b4,"Add CUDA version check (#2707)

Summary:
Adds check to ensure that TorchAudio and PyTorch versions use the same CUDA version.

Pull Request resolved: https://github.com/pytorch/audio/pull/2707

Reviewed By: mthrok

Differential Revision: D39791154

Pulled By: hwangjeff

fbshipit-source-id: de00889c7bac897c6b8762502f9d37797016b71d",hwangjeff,iamjeffhwang@gmail.com,"['torchaudio/_extension.py', 'torchaudio/csrc/utils.cpp']",False,24,9,2022
c7e2eb50253e91aa9398d1134c730070c5a0586f,"[perf][5/5] Replace IValue::toString()->string() with IValue::toStringRef() (#2700)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2700

ATT for pytorch/audio

Reviewed By: mthrok

Differential Revision: D39707243

fbshipit-source-id: 1dc2a5a9fe913a9071e6df679e39d632b75212fb",Alex Beloi,alexbeloi@fb.com,"['examples/libtorchaudio/speech_recognition/transcribe.cpp', 'examples/libtorchaudio/speech_recognition/transcribe_list.cpp']",False,23,9,2022
7ba7cf4d24a2967b8fa4aaff437116524281f8fd,"[Nova] Moving Linux Wheels over to Nova (#2702)

Summary:
This does 2 things:

Comments out Linux Wheels-related jobs in CircleCI so that they are not run on nightlies/releases.
Adds a GHA workflow that calls the build workflow in pytorch/test-infra.
Testing:
Verified that the builds are triggered by this workflow, and all builds are green: https://github.com/pytorch/audio/actions/runs/3109635749/jobs/5040029155

Pull Request resolved: https://github.com/pytorch/audio/pull/2702

Reviewed By: seemethere

Differential Revision: D39756852

Pulled By: osalpekar

fbshipit-source-id: 7e222d80ca0720e3be43b929f1e55f5c0166b947",Omkar Salpekar,osalpekar@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.github/workflows/build_wheels_linux.yml']",False,23,9,2022
faf8f1cc06995c56fe06237fd2e485ab7b571546,"Introduce IO section to getting started tutorials (#2703)

Summary:
Since that new tutorials for StreamWriter are being added, there are more tutorials for media IO than the rest.
So this commit introduces sub-index for IO tutorials.

Pull Request resolved: https://github.com/pytorch/audio/pull/2703

Reviewed By: carolineechen

Differential Revision: D39769049

Pulled By: mthrok

fbshipit-source-id: 19a3981bc624fdce1d5d703c67e28a751a15e812",moto,855818+mthrok@users.noreply.github.com,"['docs/source/index.rst', 'docs/source/io.rst', 'docs/source/tutorials.io.rst', 'examples/tutorials/streamreader_advanced_tutorial.py', 'examples/tutorials/streamreader_basic_tutorial.py']",False,23,9,2022
49b23e1583346029bdd28e67b2fd146c9569a789,"Adopt `:autosummary:` in `torchaudio.datasets` module doc (#2692)

Summary:
* Introduce the mini-index at `torchaudio.datasets` page.
* Standardize the format of return type docstring.

https://output.circle-artifacts.com/output/job/989328b2-0270-4958-b577-19cf749af3fd/artifacts/0/docs/datasets.html

<img width=""936"" alt=""Screen Shot 2022-09-21 at 6 56 52 PM"" src=""https://user-images.githubusercontent.com/855818/191475141-a97f2bea-705f-49bc-8c34-6ec869e76793.png"">

https://output.circle-artifacts.com/output/job/989328b2-0270-4958-b577-19cf749af3fd/artifacts/0/docs/generated/torchaudio.datasets.CMUDict.html#torchaudio.datasets.CMUDict

<img width=""1069"" alt=""Screen Shot 2022-09-21 at 6 57 32 PM"" src=""https://user-images.githubusercontent.com/855818/191475293-e3302528-27ea-4212-9c12-fd6d900fdf3e.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2692

Reviewed By: carolineechen

Differential Revision: D39687463

Pulled By: mthrok

fbshipit-source-id: 4175fc15388817d2fe76206188618dd1576281df",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/dataset_class.rst', 'docs/source/datasets.rst', 'examples/tutorials/audio_datasets_tutorial.py', 'torchaudio/datasets/cmuarctic.py', 'torchaudio/datasets/cmudict.py', 'torchaudio/datasets/commonvoice.py', 'torchaudio/datasets/dr_vctk.py', 'torchaudio/datasets/fluentcommands.py', 'torchaudio/datasets/gtzan.py', 'torchaudio/datasets/librilight_limited.py', 'torchaudio/datasets/librimix.py', 'torchaudio/datasets/librispeech.py', 'torchaudio/datasets/libritts.py', 'torchaudio/datasets/ljspeech.py', 'torchaudio/datasets/musdb_hq.py', 'torchaudio/datasets/quesst14.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/tedlium.py', 'torchaudio/datasets/vctk.py', 'torchaudio/datasets/voxceleb1.py', 'torchaudio/datasets/yesno.py']",False,22,9,2022
709b4439bead016bef8f3af4b68cfc3c6429af33,"Update and fix tutorials (#2701)

Summary:
* Fix Sphinx warning
* Update asset management

Pull Request resolved: https://github.com/pytorch/audio/pull/2701

Reviewed By: carolineechen

Differential Revision: D39714126

Pulled By: mthrok

fbshipit-source-id: a5b04cfbf8bedce67c621b6bfe1dcd975b343313",moto,855818+mthrok@users.noreply.github.com,"['examples/tutorials/audio_data_augmentation_tutorial.py', 'examples/tutorials/audio_feature_augmentation_tutorial.py']",False,22,9,2022
ad2b61d7a0173ce86cb9c812432d4f5a95410a50,"Add metadata mode for various datasets (#2697)

Summary:
Add metadata mode for the following SUPERB benchmark datasets
- QUESST14
- Fluent Speech Commands
- VoxCeleb1

follow ups:
- Add metadata mode for LibriMix -- waiting for unit tests to merge
- Add IEMOCAP + SNIPS datasets

Pull Request resolved: https://github.com/pytorch/audio/pull/2697

Reviewed By: mthrok

Differential Revision: D39666809

Pulled By: carolineechen

fbshipit-source-id: 3a8f07627acceed70f960f47e694efad75b108c2",Caroline Chen,carolinechen@meta.com,"['torchaudio/datasets/fluentcommands.py', 'torchaudio/datasets/quesst14.py', 'torchaudio/datasets/voxceleb1.py']",False,21,9,2022
0b3ddec6540d7fc7fb59c1b6184a5e6c9e1d32e0,"Adopt `:autosummary:` in `torchaudio.pipelines` module doc (#2689)

Summary:
* Introduce the mini-index at `torchaudio.pipelines` page.
* Add introductions
* Update pipeline tutorials

https://output.circle-artifacts.com/output/job/ccc57d95-1930-45c9-b967-c8d477d35f29/artifacts/0/docs/pipelines.html

<img width=""1163"" alt=""Screen Shot 2022-09-20 at 1 23 29 PM"" src=""https://user-images.githubusercontent.com/855818/191167049-98324e93-2e16-41db-8538-3b5b54eb8224.png"">

<img width=""1115"" alt=""Screen Shot 2022-09-20 at 1 23 49 PM"" src=""https://user-images.githubusercontent.com/855818/191167071-4770f594-2540-43a4-a01c-e983bf59220f.png"">

https://output.circle-artifacts.com/output/job/ccc57d95-1930-45c9-b967-c8d477d35f29/artifacts/0/docs/generated/torchaudio.pipelines.RNNTBundle.html#torchaudio.pipelines.RNNTBundle

<img width=""1108"" alt=""Screen Shot 2022-09-20 at 1 24 18 PM"" src=""https://user-images.githubusercontent.com/855818/191167123-51b33a5f-c30c-46bc-b002-b05d2d0d27b7.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2689

Reviewed By: carolineechen

Differential Revision: D39691253

Pulled By: mthrok

fbshipit-source-id: ddf5fdadb0b64cf2867b6271ba53e8e8c0fa7e49",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/bundle_class.rst', 'docs/source/_templates/autosummary/bundle_data.rst', 'docs/source/pipelines.rst', 'docs/source/refs.bib', 'docs/source/transforms.rst', 'examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/speech_recognition_pipeline_tutorial.py', 'examples/tutorials/tacotron2_pipeline_tutorial.py', 'torchaudio/pipelines/_source_separation_pipeline.py', 'torchaudio/pipelines/_tts/impl.py', 'torchaudio/pipelines/_tts/interface.py', 'torchaudio/pipelines/_wav2vec2/impl.py', 'torchaudio/pipelines/rnnt_pipeline.py']",False,21,9,2022
045cc372fc71a524e672d378967f35c69f884ea2,"Add StreamReader Tensor Binding to src (#2699)

Summary:
In https://github.com/pytorch/audio/issues/2694 CMakeLists.txt was not properly updated, so the tests are failing. This commit fix it.

Pull Request resolved: https://github.com/pytorch/audio/pull/2699

Reviewed By: carolineechen

Differential Revision: D39687409

Pulled By: mthrok

fbshipit-source-id: 2e14f3c478f1f8a112a03839f2dbcca51215fed7",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/CMakeLists.txt'],False,21,9,2022
c5a43372a5fc3ef0a7212338243245621e342002,"Support in-memory decoding via Tensor wrapper in StreamReader (#2694)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2694

This commit adds Tensor type as input to `StreamReader`.
The Tensor is interpreted as byte string buffer.

Reviewed By: hwangjeff

Differential Revision: D39467630

fbshipit-source-id: 6369eed5e16fbb657568bf6bb80d703483d72f8e",Moto Hira,moto@fb.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_tensor_binding.h', 'torchaudio/io/_stream_reader.py']",False,21,9,2022
30c7077b5119664a23b0d1b266ff6856a7c3d818,"Adopt `:autosummary:` in `torchaudio.models` module doc (#2690)

Summary:
* Introduce the mini-index at `torchaudio.models` page.

https://output.circle-artifacts.com/output/job/25e59810-3866-4ece-b1b7-8a10c7a2286d/artifacts/0/docs/models.html

<img width=""1042"" alt=""Screen Shot 2022-09-20 at 1 20 50 PM"" src=""https://user-images.githubusercontent.com/855818/191166816-83314ad1-8b67-475b-aa10-d4cc59126295.png"">

<img width=""1048"" alt=""Screen Shot 2022-09-20 at 1 20 58 PM"" src=""https://user-images.githubusercontent.com/855818/191166829-1ceb65e0-9506-4328-9a2f-8b75b4e54404.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2690

Reviewed By: carolineechen

Differential Revision: D39654948

Pulled By: mthrok

fbshipit-source-id: 703d1526617596f647c85a7148f41ca55fffdbc8",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/model_class.rst', 'docs/source/models.rst', 'docs/source/refs.bib', 'examples/tutorials/hybrid_demucs_tutorial.py', 'torchaudio/models/_hdemucs.py', 'torchaudio/models/conformer.py', 'torchaudio/models/conv_tasnet.py', 'torchaudio/models/deepspeech.py', 'torchaudio/models/emformer.py', 'torchaudio/models/rnnt.py', 'torchaudio/models/rnnt_decoder.py', 'torchaudio/models/tacotron2.py', 'torchaudio/models/wav2letter.py', 'torchaudio/models/wav2vec2/model.py', 'torchaudio/models/wav2vec2/utils/import_fairseq.py', 'torchaudio/models/wav2vec2/utils/import_huggingface.py', 'torchaudio/models/wavernn.py']",False,21,9,2022
4a65b050de16b7fbca2788891e7b6b534816c0fc,"Add Speech Commands metadata function (#2687)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2687

Reviewed By: mthrok

Differential Revision: D39647596

Pulled By: carolineechen

fbshipit-source-id: 8ff874fc1e828130f6754e83ce1f702ca13dfac0",Caroline Chen,carolinechen@fb.com,"['torchaudio/datasets/librispeech.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/utils.py']",False,20,9,2022
ad15bc714dc78929b495820c1a7fcee476b38aa8,"Adopt `:autosummary:` in `torchaudio.functional` module doc (#2693)

Summary:
https://output.circle-artifacts.com/output/job/b23174d2-5cee-4ee9-be39-3228b9ae4abe/artifacts/0/docs/functional.html

<img width=""1133"" alt=""Screen Shot 2022-09-20 at 11 19 23 AM"" src=""https://user-images.githubusercontent.com/855818/191152824-96c5b16c-bd38-4656-b1ae-0b58699dbd62.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2693

Reviewed By: carolineechen

Differential Revision: D39650930

Pulled By: mthrok

fbshipit-source-id: 28b5b03d21b922e37e02bfddda2bf1dea696cc18",moto,855818+mthrok@users.noreply.github.com,['docs/source/functional.rst'],False,20,9,2022
3f2ffc94fc0a5f3fd67bfd8d72bcaad2aa6d01d9,"Update nightly wheels to ROCm5.2 (#2672)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2672

Reviewed By: atalman

Differential Revision: D39468320

Pulled By: mthrok

fbshipit-source-id: 0e7bd4fd922ba0db51700e140b95328a5b687a6f",Jithun Nair,jithun.nair@amd.com,"['.circleci/config.yml', '.circleci/regenerate.py']",False,20,9,2022
ad32eae85c40c4ef1f07be0f906bce848a24a514,"[Nova] Remove Extraneous Build Scripts (#2695)

Summary:
There is a single pre/post script needed for building torchaudio. This PR:
1. Removes the old conda-specific build script
2. Renames the wheel script to be a general name

Pull Request resolved: https://github.com/pytorch/audio/pull/2695

Reviewed By: kit1980

Differential Revision: D39631971

Pulled By: osalpekar

fbshipit-source-id: 52b49a6e792536b6264228c01ac356d247b18ea8",Omkar Salpekar,osalpekar@fb.com,"['packaging/post_build_script.sh', 'packaging/post_build_script_wheel.sh', 'packaging/pre_build_script.sh', 'packaging/pre_build_script_conda.sh']",False,20,9,2022
baf354a7f152198222a4020da6071e7730c3ba3b,"Adopt `:autosummary:` in `torchaudio.transforms` module doc (#2683)

Summary:
* Introduce the mini-index at `torchaudio.transforms` page.
* Add ""Augmentations"" subsection.
* Also updated the overall introduction.

https://output.circle-artifacts.com/output/job/1b65246a-403c-4d2c-b97d-d1b582d8b4e5/artifacts/0/docs/transforms.html

<img width=""721"" alt=""Screen Shot 2022-09-16 at 5 20 08 PM"" src=""https://user-images.githubusercontent.com/855818/190591795-97c169db-a95b-480a-8d3c-d80072efa045.png"">

<img width=""755"" alt=""Screen Shot 2022-09-16 at 5 20 28 PM"" src=""https://user-images.githubusercontent.com/855818/190591828-03026918-febd-4194-91aa-7d8f704e17cc.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2683

Reviewed By: carolineechen

Differential Revision: D39574255

Pulled By: mthrok

fbshipit-source-id: a4beed7cacbb5184bad96efa903a3a1123dab627",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/class.rst', 'docs/source/transforms.rst']",False,16,9,2022
c89ab0c65d2ede2ece9b42a1972aa6c506a4040e,"Adopt `:autosummary:` in `torchaudio.models.decoder` module doc (#2684)

Summary:
* Adopts `:autosummary:` in decoder module doc
* Hide the constructor signature of `CTCDecoder` as `ctc_decoder` function is the one client code is supposed to be using.
* Introduce `children` property to `CTCDecoderLMState` otherwise it does not show up in the doc.

https://output.circle-artifacts.com/output/job/7aac5eb9-7d2d-4f63-bcdf-83a6f40b4e5a/artifacts/0/docs/models.decoder.html

<img width=""748"" alt=""Screen Shot 2022-09-16 at 5 23 22 PM"" src=""https://user-images.githubusercontent.com/855818/190592409-0c2ec8a4-d2cf-4d76-a965-8a570faaeb1a.png"">

https://output.circle-artifacts.com/output/job/7aac5eb9-7d2d-4f63-bcdf-83a6f40b4e5a/artifacts/0/docs/generated/torchaudio.models.decoder.CTCDecoder.html#torchaudio.models.decoder.CTCDecoder

<img width=""723"" alt=""Screen Shot 2022-09-16 at 5 23 53 PM"" src=""https://user-images.githubusercontent.com/855818/190592501-3fad1e07-ae3e-44f5-93be-f33181025390.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2684

Reviewed By: carolineechen

Differential Revision: D39574272

Pulled By: mthrok

fbshipit-source-id: d977660bd46f5cf98c535adbf2735be896b28773",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/autosummary/ctc_decoder_class.rst', 'docs/source/models.decoder.rst', 'torchaudio/models/decoder/_ctc_decoder.py']",False,16,9,2022
f50a92869c37bbc54fe08af819304e6ad1011e84,"Adopt `:autosummary:` in `torchaudio.io` module doc (#2681)

Summary:
This commit adopts :autosummary: directive to `torchaudio.io` module.
It adds table of contents on `torchaudio.io` level.

https://output.circle-artifacts.com/output/job/282089d1-c120-4d22-809f-0e0ac0947c37/artifacts/0/docs/io.html
<img width=""1094"" alt=""Screen Shot 2022-09-16 at 7 33 32 AM"" src=""https://user-images.githubusercontent.com/855818/190520248-27e469f8-7689-4dc2-b591-7b3f08bb4dff.png"">

https://output.circle-artifacts.com/output/job/282089d1-c120-4d22-809f-0e0ac0947c37/artifacts/0/docs/generated/torchaudio.io.StreamReader.html#torchaudio.io.StreamReader
<img width=""1108"" alt=""Screen Shot 2022-09-16 at 7 33 59 AM"" src=""https://user-images.githubusercontent.com/855818/190520292-d090fed0-2f18-4961-b9f3-9e4808fd437e.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2681

Reviewed By: carolineechen

Differential Revision: D39560459

Pulled By: mthrok

fbshipit-source-id: 3de5f22b8d8d0834dfd8bac8619fbfaa44c5f4dd",moto,855818+mthrok@users.noreply.github.com,"['.gitignore', 'docs/source/_static/css/custom.css', 'docs/source/_templates/autosummary/io_class.rst', 'docs/source/io.rst', 'torchaudio/io/_stream_reader.py']",False,16,9,2022
c2870b6e8b157ce34b5c9e09a1a4507726c73ef6,"Switch to use conda install action for m1 builds (#2674)

Summary:
Usage setup-minicoda action for m1 build
We want to try to address space issues on m1. The following action:
```
pytorch/test-infra/.github/actions/setup-miniconda@main
```

Sets up miniconda in temp folder which should be cleaned between runs

Pull Request resolved: https://github.com/pytorch/audio/pull/2674

Reviewed By: jeanschmidt

Differential Revision: D39540481

Pulled By: atalman

fbshipit-source-id: 0596598ab6b2f99c775aa0c9e14a3a388533068d",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,15,9,2022
b66a85ae6c344b838e90d65740e68051ea69ffc8,"Update Sphinx to 5.1.1 (#2678)

Summary:
Previous versions of Sphinx reported wrong path for return class. This issue is fixed on the latest Sphinx.

It allows to remove the patch we apply in `conf.py`. This is essential for the adoptation of `:autosummary:`, as it won't render correctly with the patch.

https://output.circle-artifacts.com/output/job/19d93ede-08de-4b9e-9d66-67ca5dab964e/artifacts/0/docs/pipelines.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2678

Reviewed By: carolineechen

Differential Revision: D39509447

Pulled By: mthrok

fbshipit-source-id: e104bc6a87f32cba6c549a9fe8f2d1e489ee27e4",moto,855818+mthrok@users.noreply.github.com,"['docs/requirements.txt', 'docs/source/conf.py', 'docs/source/pipelines.rst', 'torchaudio/models/wav2vec2/model.py']",False,15,9,2022
bfdb6764850c722b2cb9dacacd1eb46200ac03e0,"Update doc theme to the latest (#2679)

Summary:
To follow the change related to Linux Foundation movement.

(we are still pinning the theme version so that our customization does not break randomly.)

Pull Request resolved: https://github.com/pytorch/audio/pull/2679

Reviewed By: carolineechen

Differential Revision: D39531566

Pulled By: mthrok

fbshipit-source-id: 64353577d05f9dbda00dd9d10b9ebcedddfdce5b",moto,855818+mthrok@users.noreply.github.com,['docs/requirements.txt'],False,15,9,2022
476ab9ab9deecfec6ff091ef4e3f1caad066321f,"Consolidate bibliography / reference (#2676)

Summary:
Preparation for the adoptation of `autosummary`.

Replace `:footcite:` with `:cite:` and introduce dedicated reference page, as `:footcite:` does not work well with `autosummary`.

Example:

https://output.circle-artifacts.com/output/job/4da47ba6-d9c7-418e-b5b0-e9f8a146a6c3/artifacts/0/docs/datasets.html#cmuarctic

https://output.circle-artifacts.com/output/job/4da47ba6-d9c7-418e-b5b0-e9f8a146a6c3/artifacts/0/docs/references.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2676

Reviewed By: carolineechen

Differential Revision: D39509431

Pulled By: mthrok

fbshipit-source-id: e6003dd01ec3eff3d598054690f61de8ee31ac9a",moto,855818+mthrok@users.noreply.github.com,"['docs/source/conf.py', 'docs/source/datasets.rst', 'docs/source/functional.rst', 'docs/source/index.rst', 'docs/source/models.decoder.rst', 'docs/source/models.rst', 'docs/source/pipelines.rst', 'docs/source/prototype.models.rst', 'docs/source/prototype.pipelines.rst', 'docs/source/references.rst', 'docs/source/transforms.rst', 'torchaudio/datasets/cmuarctic.py', 'torchaudio/datasets/cmudict.py', 'torchaudio/datasets/commonvoice.py', 'torchaudio/datasets/dr_vctk.py', 'torchaudio/datasets/fluentcommands.py', 'torchaudio/datasets/gtzan.py', 'torchaudio/datasets/librimix.py', 'torchaudio/datasets/librispeech.py', 'torchaudio/datasets/libritts.py', 'torchaudio/datasets/ljspeech.py', 'torchaudio/datasets/musdb_hq.py', 'torchaudio/datasets/quesst14.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/tedlium.py', 'torchaudio/datasets/vctk.py', 'torchaudio/datasets/voxceleb1.py', 'torchaudio/datasets/yesno.py', 'torchaudio/functional/functional.py', 'torchaudio/models/_hdemucs.py', 'torchaudio/models/conformer.py', 'torchaudio/models/conv_tasnet.py', 'torchaudio/models/decoder/_ctc_decoder.py', 'torchaudio/models/deepspeech.py', 'torchaudio/models/emformer.py', 'torchaudio/models/tacotron2.py', 'torchaudio/models/wav2letter.py', 'torchaudio/models/wav2vec2/model.py', 'torchaudio/models/wavernn.py', 'torchaudio/pipelines/_source_separation_pipeline.py', 'torchaudio/pipelines/_tts/impl.py', 'torchaudio/pipelines/_wav2vec2/impl.py', 'torchaudio/prototype/models/conv_emformer.py', 'torchaudio/transforms/_multi_channel.py', 'torchaudio/transforms/_transforms.py']",False,15,9,2022
50c66721b1cef7cb9dbea8fdba8120e46c6c1694,"Move conv_tasnet_base doc out of prototype (#2675)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2675

Reviewed By: carolineechen

Differential Revision: D39515996

Pulled By: nateanl

fbshipit-source-id: 5824375f6a758af21b6ad6c635dd06081663644f",Zhaoheng Ni,zni@fb.com,"['docs/source/models.rst', 'docs/source/prototype.models.rst']",False,14,9,2022
a0b5ee309e3bd346a09010fea96e3d1ef512cba6,"Tweak badge link URL generation (#2677)

Summary:
Currently, the way feature badges are generated assumes that both documentations and the supported features page are on the same level from the root.

This does not work when we introduce `:autosummary:` which generates individual documentation pages one level below.

This commit changes it so that links to the supported features page are properly relative from the documentation level.

There is no appearance change from this commit.

Pull Request resolved: https://github.com/pytorch/audio/pull/2677

Reviewed By: carolineechen

Differential Revision: D39507451

Pulled By: mthrok

fbshipit-source-id: f18da4201f0eb747586be21c8bd9a958217aebc2",moto,855818+mthrok@users.noreply.github.com,['docs/source/custom_directives.py'],False,14,9,2022
9f2bbf6c14ff856bf1fea6852fb8581cfd922f02,"Add Decoder LM Docs (#2658)

Summary:
modifications to ctc decoder LM docstrings on top of https://github.com/pytorch/audio/issues/2657

Pull Request resolved: https://github.com/pytorch/audio/pull/2658

Reviewed By: mthrok

Differential Revision: D39468921

Pulled By: carolineechen

fbshipit-source-id: c5497cc2fa22fb98a304d037e27c91bf68a9ad6a",Caroline Chen,carolinechen@fb.com,"['docs/source/conf.py', 'docs/source/models.decoder.rst', 'torchaudio/models/decoder/_ctc_decoder.py']",False,14,9,2022
6086874863402d2cbe2e2d2c1b4caec831007b98,"Move Hybrid Demucs pipeline to beta (#2673)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2673

Reviewed By: mthrok

Differential Revision: D39507612

Pulled By: carolineechen

fbshipit-source-id: 3a9ee53f72cabd6e3085c76867017be4a6ed7f53",Caroline Chen,carolinechen@fb.com,"['docs/source/pipelines.rst', 'docs/source/prototype.pipelines.rst', 'examples/tutorials/hybrid_demucs_tutorial.py', 'test/integration_tests/source_separation_pipeline_test.py', 'torchaudio/pipelines/__init__.py', 'torchaudio/pipelines/_source_separation_pipeline.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,14,9,2022
155dc2982eb92c941fa42bbbeb0b75cf8780ff3d,"CUDA 11.3 remove. New Stable version is 11.6 (#2670)

Summary:
CUDA 11.3 Removing.

Core PR: https://github.com/pytorch/pytorch/pull/84866
cc malfet ptrblck

Pull Request resolved: https://github.com/pytorch/audio/pull/2670

Reviewed By: malfet, osalpekar

Differential Revision: D39449263

Pulled By: atalman

fbshipit-source-id: f86bb119685ead3ffcabd92c4bb8076aecde4095",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', 'packaging/pkg_helpers.bash']",False,14,9,2022
4d535e885bf190478fb9293384351b615ae41b19,"Move SourceSeparationBundle and pre-trained ConvTasNet pipeline into Beta (#2669)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2669

Reviewed By: carolineechen, mthrok

Differential Revision: D39433560

Pulled By: nateanl

fbshipit-source-id: 5b652b31c00badb37b27a32ac25b422a5bcc74cb",Zhaoheng Ni,zni@fb.com,"['docs/source/pipelines.rst', 'docs/source/prototype.pipelines.rst', 'test/integration_tests/source_separation_pipeline_test.py', 'torchaudio/models/__init__.py', 'torchaudio/models/conv_tasnet.py', 'torchaudio/pipelines/__init__.py', 'torchaudio/pipelines/_source_separation_pipeline.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/conv_tasnet.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,13,9,2022
697e15aba83574dba61cf8aade0f59c6bc7e9590,"[Bootcamp] Fix Typo (#2661)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2661

Fixed typo in `audio_data_augmentation_tutorial.py`

Reviewed By: malfet, mthrok

Differential Revision: D39352353

fbshipit-source-id: aea35dab03fb7422421948bd26716e10a8d65f92",Anthony Tao,anthonytao@fb.com,['examples/tutorials/audio_data_augmentation_tutorial.py'],False,13,9,2022
cb8fa04ceed8217e65168f4520dd1580c38de239,"Do not use nested namespaces in torchaudio/sox (#2663)

Summary:
As it is a C++17 feature, and PyTorch and its extensions must still be C++14 compatible, as also specified in the top level CMakeLists.txt:
https://github.com/pytorch/audio/blob/8a0d7b36f7821fe55175f0d4e3ca6299b3817a6c/CMakeLists.txt#L30

Otherwise, it pollutes build logs with noisy
```
/Users/runner/work/test-infra/test-infra/pytorch/audio/torchaudio/csrc/sox/pybind/io.cpp:12:21: warning: nested namespace definition is a C++17 extension; define each namespace separately [-Wc++17-extensions]
namespace torchaudio::sox_io {
                    ^~~~~~~~
                     { namespace sox_io
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2663

Reviewed By: atalman, nateanl

Differential Revision: D39362842

Pulled By: malfet

fbshipit-source-id: f9659d4420f1cc0194990d531455cf59b66c26b9",Nikita Shulga,nshulga@fb.com,"['.clang-tidy', 'torchaudio/csrc/sox/effects.cpp', 'torchaudio/csrc/sox/effects.h', 'torchaudio/csrc/sox/pybind/effects.cpp', 'torchaudio/csrc/sox/pybind/effects.h', 'torchaudio/csrc/sox/pybind/effects_chain.cpp', 'torchaudio/csrc/sox/pybind/effects_chain.h', 'torchaudio/csrc/sox/pybind/io.cpp', 'torchaudio/csrc/sox/pybind/io.h', 'torchaudio/csrc/sox/pybind/utils.cpp', 'torchaudio/csrc/sox/pybind/utils.h']",False,13,9,2022
ec0e3a806520e5d86b51d42e4b45309b621af8be,"Move hybrid demucs model out of prototype (#2668)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2668

Reviewed By: nateanl, mthrok

Differential Revision: D39433671

Pulled By: carolineechen

fbshipit-source-id: 3545a5b4019832861c34fd8c05e5f8600fd80d5c",Caroline Chen,carolinechen@fb.com,"['docs/source/models.rst', 'docs/source/prototype.models.rst', 'test/torchaudio_unittest/models/hdemucs/__init__.py', 'test/torchaudio_unittest/models/hdemucs/hdemucs_cpu_test.py', 'test/torchaudio_unittest/models/hdemucs/hdemucs_gpu_test.py', 'test/torchaudio_unittest/models/hdemucs/hdemucs_test_impl.py', 'torchaudio/models/__init__.py', 'torchaudio/models/_hdemucs.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/hdemucs/__init__.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,12,9,2022
1ddb70f9e5faaa70bfa333a053ec6b1ccc83c311,"[Nova] Remove the old caller GitHub Actions Linux wheels/conda Build Workflows (#2660)

Summary:
We moved over to a new design for release workflows that encompass all the build logic in the test-infra repo (apart from custom pre-build and post-build scripts). Thus, we no longer need these caller workflows in the audio repo. This PR removes them entirely.

Pull Request resolved: https://github.com/pytorch/audio/pull/2660

Reviewed By: seemethere

Differential Revision: D39392456

Pulled By: osalpekar

fbshipit-source-id: a8bdeb4738b91666abcdc883f6f8f1bf359f1d42",Omkar Salpekar,osalpekar@fb.com,"['.github/workflows/build_linux_conda.yml', '.github/workflows/build_wheels_linux.yml']",False,9,9,2022
3b194f68558a4b981bdb57498336980b66bbc544,"Fix LibriSpeech Conforner RNN-T eval script (#2666)

Summary:
`ConformerRNNTModule`'s initializer now accepts a SentencePiece model rather than a path to a model as input. This PR corrects `eval.py` accordingly.

Pull Request resolved: https://github.com/pytorch/audio/pull/2666

Reviewed By: carolineechen

Differential Revision: D39386968

Pulled By: hwangjeff

fbshipit-source-id: 95a94dd898263d648650f7376c29810b1456d6c1",hwangjeff,iamjeffhwang@gmail.com,['examples/asr/librispeech_conformer_rnnt/eval.py'],False,9,9,2022
8a0d7b36f7821fe55175f0d4e3ca6299b3817a6c,"Tweak documentation (#2656)

Summary:
1. Override class `__module__` attribute in `conf.py` so that no manual override is necessary
2. Fix SourceSeparationBundle member attribute

Pull Request resolved: https://github.com/pytorch/audio/pull/2656

Reviewed By: carolineechen

Differential Revision: D39293053

Pulled By: mthrok

fbshipit-source-id: 2b8d6be1aee517d0e692043c26ac2438a787adc6",moto,855818+mthrok@users.noreply.github.com,"['docs/source/conf.py', 'docs/source/prototype.pipelines.rst', 'torchaudio/models/decoder/_ctc_decoder.py', 'torchaudio/models/wav2vec2/model.py', 'torchaudio/models/wav2vec2/utils/import_fairseq.py', 'torchaudio/models/wav2vec2/utils/import_huggingface.py', 'torchaudio/pipelines/_tts/interface.py', 'torchaudio/pipelines/_wav2vec2/impl.py']",False,7,9,2022
3430fd6849ce9a80a2dd5b72fbaf38357a4a7060,"Fix random Gaussian generation (#2639)

Summary:
This PR is meant to address the bug raised in issue https://github.com/pytorch/audio/issues/2634.

In particular, previously the Box Muller transform was used to generate Gaussian variates for dithering based on `torch.rand` uniform variates, but it was incorrectly implemented (e.g. the same uniform variate was used as input to the transform, rather than two different uniform variates), which led to a different (non-Gaussian) distribution. This PR instead uses `torch.randn` to generate the Gaussian variates.

Pull Request resolved: https://github.com/pytorch/audio/pull/2639

Reviewed By: mthrok

Differential Revision: D39101144

Pulled By: carolineechen

fbshipit-source-id: 691e49679f6598ef0a1675f6f4ee721ef32215fd",Ravi Makhija,ravi.makhija.pi@gmail.com,['torchaudio/compliance/kaldi.py'],False,6,9,2022
08d3bb17242c0255bcbf90a9f80cccb81d6b3b35,"Add metadata function for LibriSpeech (#2653)

Summary:
Adding support for metadata mode, requested in https://github.com/pytorch/audio/issues/2539, by adding a public `get_metadata()` function in the dataset. This function can be used directly by users to fetch metadata for individual dataset indices, or users can subclass the dataset and override `__getitem__` with `get_metadata` to create a dataset class that directly handles metadata mode.

Pull Request resolved: https://github.com/pytorch/audio/pull/2653

Reviewed By: nateanl, mthrok

Differential Revision: D39105114

Pulled By: carolineechen

fbshipit-source-id: 6f26f1402a053dffcfcc5d859f87271ed5923348",Caroline Chen,carolinechen@fb.com,"['torchaudio/datasets/librilight_limited.py', 'torchaudio/datasets/librispeech.py']",False,6,9,2022
4a20c412d6ce7949517af674b5b36f3fa50ec661,"Remove obsolete examples (#2655)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2655

Removed obsolete example and the corresponding test

Reviewed By: mthrok

Differential Revision: D39260253

fbshipit-source-id: 0bde71ffd75dd0c94a5cc4a9940f4648a5d61bd7",Peter Albert,peteralbert@fb.com,"['examples/interactive_asr/README.md', 'examples/interactive_asr/__init__.py', 'examples/interactive_asr/asr.py', 'examples/interactive_asr/data/sample.wav', 'examples/interactive_asr/utils.py', 'examples/interactive_asr/vad.py', 'examples/test/__init__.py', 'examples/test/test_interactive_asr.py']",False,6,9,2022
95eada24fcff616aebdffe9aa0b174eee2264fc5,"Add CUDA HW encoding support to StreamWriter (#2505)

Summary:
This commits add CUDA hardware encoding to StreamWriter.
For certain video formats, it can encode video directly from
CUDA Tensor, without needing to move the data to host CPU.

Pull Request resolved: https://github.com/pytorch/audio/pull/2505

Reviewed By: hwangjeff

Differential Revision: D37446830

Pulled By: mthrok

fbshipit-source-id: eee6424f01a99a3b611dcad45ed58f86cba4672a",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/pybind/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_binding.cpp', 'torchaudio/io/_stream_writer.py']",False,2,9,2022
28da8b84886d409fc1d536e0bf5b6ac557b174dd,"Add file-like object support to StreamWriter (#2648)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2648

Reviewed By: nateanl

Differential Revision: D38976874

Pulled By: mthrok

fbshipit-source-id: 0541dea2a633d97000b4b8609ff6b83f6b82c864",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_writer.h', 'torchaudio/csrc/ffmpeg/pybind/typedefs.cpp', 'torchaudio/csrc/ffmpeg/pybind/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_wrapper.h', 'torchaudio/io/_stream_writer.py']",False,1,9,2022
76fca37ac8941b72a509a6e58d623632efe04543,"add CUDA 11.7 builds (#2623)

Summary:
CC atalman

Pull Request resolved: https://github.com/pytorch/audio/pull/2623

Reviewed By: hwangjeff, nateanl

Differential Revision: D39036432

Pulled By: atalman

fbshipit-source-id: cd74a1bf8f74e31bd2c32c80d32c617f4b1766e8",pbialecki,piotr.bialecki@hotmail.de,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.circleci/unittest/windows/scripts/install.sh', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",False,26,8,2022
32389c6384294fea492dbfcd7a31bfa7072b64c8,"[Nova] Use pkg-helpers to modularize GHA Linux Conda Builds (#2650)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2650

Reviewed By: mehtanirav

Differential Revision: D39040559

Pulled By: osalpekar

fbshipit-source-id: df39e23d7c246728793aab969b8dc1070af88d75",Omkar Salpekar,osalpekar@fb.com,['.github/workflows/build_linux_conda.yml'],False,26,8,2022
8682b6449f1bb6504ae9c809dbcdce8cbf7815ba,"Replace bg_iterator in examples (#2645)

Summary:
`bg_iterator` was deprecated in 0.11 because it was known to have issues (deadlock) without speed up. Remove instances of `bg_iterator` used in torchaudio examples.

Resolves https://github.com/pytorch/audio/issues/2642

Pull Request resolved: https://github.com/pytorch/audio/pull/2645

Reviewed By: nateanl

Differential Revision: D38954292

Pulled By: carolineechen

fbshipit-source-id: 2333ab5228c2b8511ff532057543aaf9d02b2789",Caroline Chen,carolinechen@fb.com,"['examples/pipeline_wav2letter/main.py', 'examples/pipeline_wavernn/main.py']",False,26,8,2022
c7e0595bb7e1754afc5fc329c764350c682962be,"[Nova] Build Linux Conda Binaries using reusable workflow (#2626)

Summary:
Calling the reusable workflow introduced in https://github.com/pytorch/test-infra/pull/546 to build conda binaries on linux.

Pull Request resolved: https://github.com/pytorch/audio/pull/2626

Reviewed By: mehtanirav

Differential Revision: D39028057

Pulled By: osalpekar

fbshipit-source-id: d74ea3771967d0ee2b0ad28a8f811a95145b2183",Omkar Salpekar,osalpekar@fb.com,"['.github/workflows/build_linux_conda.yml', 'packaging/pkg_helpers.bash', 'packaging/post_build_script_conda.sh', 'packaging/pre_build_script_conda.sh']",False,25,8,2022
72404de901cdb47049d8f0383a4dc51a1b739317,"Add StreamWriter (#2628)

Summary:
This commit adds FFmpeg-based encoder StreamWriter class.
StreamWriter is pretty much the opposite of StreamReader class, and
it supports;

* Encoding audio / still image / video
* Exporting to local file / streaming protocol / devices etc...
* File-like object support (in later commit)
* HW video encoding (in later commit)

See also: https://fburl.com/gslide/z85kn5a9 (Meta internal)

Pull Request resolved: https://github.com/pytorch/audio/pull/2628

Reviewed By: nateanl

Differential Revision: D38816650

Pulled By: mthrok

fbshipit-source-id: a9343b0d55755e186971dc96fb86eb52daa003c8",moto,855818+mthrok@users.noreply.github.com,"['.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh', 'docs/source/io.rst', 'test/torchaudio_unittest/io/stream_writer_test.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer.h', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_writer/stream_writer_wrapper.h', 'torchaudio/io/__init__.py', 'torchaudio/io/_stream_writer.py']",False,24,8,2022
068fc29cfe47d44a1b07cb1fe89d2e907354a203,"Added example for LFCC transform (#2640)

Summary:
Added example for LFCC transform as mentioned in issue https://github.com/pytorch/audio/issues/1564.

Pull Request resolved: https://github.com/pytorch/audio/pull/2640

Reviewed By: carolineechen

Differential Revision: D38908975

Pulled By: nateanl

fbshipit-source-id: ffdd994390db7f27556b011a8050a65eef9cd09d",Ravi Makhija,ravi.makhija.pi@gmail.com,['torchaudio/transforms/_transforms.py'],False,23,8,2022
c0815850b202cfd2c713d99a832917bac9d6b9d3,"[Nova] Added draft calling GHA workflow for building linux wheels (#2548)

Summary:
As part of Project Nova, we are consolidating CI/CD workflows and infra, making them reusable across PyTorch ecosystem libraries. https://github.com/pytorch/test-infra/pull/460 introduces a general-purpose reusable workflow to build linux wheels for python libraries. This PR introduces a caller workflow that triggers the reusable workflow. Details around modular env setup, passing input args across workflows, etc. are still being worked out.

Using reusable workflow defined in https://github.com/pytorch/test-infra/pull/506

Pull Request resolved: https://github.com/pytorch/audio/pull/2548

Reviewed By: osalpekar

Differential Revision: D38947733

Pulled By: mehtanirav

fbshipit-source-id: 03ab88cef973a092f5c5d1ff8c74ec7ae7e46d01",Omkar Salpekar,osalpekar@fb.com,"['.github/workflows/build_wheels_linux.yml', 'packaging/post_build_script_wheel.sh', 'packaging/pre_build_script_wheel.sh']",False,23,8,2022
2a8108eb2979fce4372a909b0fa4f1c20ade8f6f,"Update Sphinx-gallery to 0.11.1 (#2638)

Summary:
The minor release fixes some gallery issue, which allows to remove
some of the customization we had in https://github.com/pytorch/audio/issues/2629

https://output.circle-artifacts.com/output/job/553a9b98-8260-4cb4-a681-20ef97d2c33e/artifacts/0/docs/pipelines.html#torchaudio.pipelines.Wav2Vec2ASRBundle

Pull Request resolved: https://github.com/pytorch/audio/pull/2638

Reviewed By: carolineechen, nateanl

Differential Revision: D38909097

Pulled By: mthrok

fbshipit-source-id: 78346d93b54fca2a19b28991c224324ef53221c9",moto,855818+mthrok@users.noreply.github.com,"['docs/requirements.txt', 'docs/source/_static/css/custom.css']",False,22,8,2022
0c94d6efa5f7ca4023abb14653a4a82970c5c276,"Added example for Loudness transform (#2641)

Summary:
Added example for Loudness transform (implemented in PR https://github.com/pytorch/audio/issues/2472) as mentioned in issue https://github.com/pytorch/audio/issues/1564.

Pull Request resolved: https://github.com/pytorch/audio/pull/2641

Reviewed By: nateanl

Differential Revision: D38907782

Pulled By: carolineechen

fbshipit-source-id: fd2bcc4bac3095a626ea9cf36cb70cb2bf003d63",Ravi Makhija,ravi.makhija.pi@gmail.com,['torchaudio/transforms/_transforms.py'],False,22,8,2022
533f87480420424741c2c8bf1242fdd9f9486bad,"Added example for MFCC transform (#2637)

Summary:
Added example for MFCC transform as mentioned in issue https://github.com/pytorch/audio/issues/1564.

Note: Python formatter package `black` uses double quotes for the string dict keys (e.g. in `melkwargs` for this example). Please let me know if there is a different linter/format/convention that is preferred!

Pull Request resolved: https://github.com/pytorch/audio/pull/2637

Reviewed By: carolineechen

Differential Revision: D38873729

Pulled By: nateanl

fbshipit-source-id: 2e8fe2930671e7c5d02c0c37cf1ca5cc8c5079e3",Ravi Makhija,87270246+ravimakhija@users.noreply.github.com,['torchaudio/transforms/_transforms.py'],False,20,8,2022
789adf07bc8e9b0b555ab141fa2849eecd9d51b8,"Refactor sox pybind source code (#2636)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2636

At the early stage of torchaudio extension module,
`torchaudio/csrc/pybind` directory was created so that
all the code defining Python interface would be placed
there and there will be only one extension module called
`torchaudio._torchaudio`.

However, the codebase has been evolved in a way separate
extensions are defined for each feature (third party
dependency) for the sake of more moduler file organization.

What is left in `csrc/pybind` is libsox Python bindings.
This commit moves it under `csrc/sox`.

Follow-up rename `torchaudio._torchaudio` to `torchaudio._torchaudio_sox`.

Reviewed By: carolineechen

Differential Revision: D38829253

fbshipit-source-id: 3554af45a2beb0f902810c5548751264e093f28d",Moto Hira,moto@fb.com,"['torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/sox/pybind/effects.cpp', 'torchaudio/csrc/sox/pybind/effects.h', 'torchaudio/csrc/sox/pybind/effects_chain.cpp', 'torchaudio/csrc/sox/pybind/effects_chain.h', 'torchaudio/csrc/sox/pybind/io.cpp', 'torchaudio/csrc/sox/pybind/io.h', 'torchaudio/csrc/sox/pybind/pybind.cpp', 'torchaudio/csrc/sox/pybind/utils.cpp', 'torchaudio/csrc/sox/pybind/utils.h']",False,19,8,2022
0b7f2fbaf8c4e828ddc4c44fe4f9942102246a22,"Update README.md (#2633)

Summary:
Update compatibility matrix

Pull Request resolved: https://github.com/pytorch/audio/pull/2633

Reviewed By: nateanl

Differential Revision: D38827670

Pulled By: mthrok

fbshipit-source-id: 5c66bf60a06e37919ee725a5f4adf571e6c89100",moto,855818+mthrok@users.noreply.github.com,['README.md'],False,19,8,2022
189edb1b34e05e6a88b9de6a8a388959dcb34094,"Update ASR inference tutorial (#2631)

Summary:
* Use download_asset
* Remove notes around nightly
* Print versions first
* Remove duplicated import

Pull Request resolved: https://github.com/pytorch/audio/pull/2631

Reviewed By: carolineechen

Differential Revision: D38830395

Pulled By: mthrok

fbshipit-source-id: c9259df33562defe249734d1ed074dac0fddc2f6",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py'],False,18,8,2022
129a7c1be119e70184a66e1d231c128e852acdef,"Added example for InverseMelScale transform (#2635)

Summary:
Added example for InverseMelScale transform as mentioned in issue https://github.com/pytorch/audio/issues/1564.

Pull Request resolved: https://github.com/pytorch/audio/pull/2635

Reviewed By: carolineechen

Differential Revision: D38830318

Pulled By: nateanl

fbshipit-source-id: fd26a700d495f6755db0767625aa8577cb89bd83",Ravi Makhija,87270246+ravimakhija@users.noreply.github.com,['torchaudio/transforms/_transforms.py'],False,18,8,2022
55ce80b1189070a666c2262189f33c38cec3ff7c,"Update notes around nightly build and third parties (#2632)

Summary:
Google Colab now has torchaudio 0.12 pre-installed.
This commit removes the note about nightly build.

Pull Request resolved: https://github.com/pytorch/audio/pull/2632

Reviewed By: carolineechen

Differential Revision: D38827632

Pulled By: mthrok

fbshipit-source-id: ac769780868b741c3012357d589ec0019d9af6eb",moto,855818+mthrok@users.noreply.github.com,"['examples/tutorials/device_asr.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streaming_api2_tutorial.py', 'examples/tutorials/streaming_api_tutorial.py']",False,18,8,2022
cab2bb44b576e5d445fb2759232d85931c4dd530,"Tweak tutorials (#2630)

Summary:
Resolves the following warnings

```
/torchaudio/docs/source/tutorials/asr_inference_with_ctc_decoder_tutorial.rst:195: WARNING: Unexpected indentation.
/torchaudio/docs/source/tutorials/asr_inference_with_ctc_decoder_tutorial.rst:446: WARNING: Unexpected indentation.
/torchaudio/docs/source/tutorials/audio_io_tutorial.rst:559: WARNING: Content block expected for the ""note"" directive; none found.
/torchaudio/docs/source/tutorials/mvdr_tutorial.rst:338: WARNING: Bullet list ends without a blank line; unexpected unindent.
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2630

Reviewed By: nateanl

Differential Revision: D38816632

Pulled By: mthrok

fbshipit-source-id: 135ded4e064d136be67ce24439e96f5e9c9ce635",moto,855818+mthrok@users.noreply.github.com,"['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'examples/tutorials/audio_io_tutorial.py', 'examples/tutorials/mvdr_tutorial.py']",False,18,8,2022
265c09d80e22c7c26063770ea2d11c0095270fc0,"Fix Sphinx-gallery display and pin sphinx-related packages (#2629)

Summary:
This commit fixes the issue with the recent Sphinx-Gallery update.
Also it pins the versions of Sphinx-related packages.

Before:

<img width=""256"" alt=""Screen Shot 2022-08-17 at 10 02 23 PM"" src=""https://user-images.githubusercontent.com/855818/185140952-28f2d98a-b586-424c-a003-b69089f48eb9.png"">

After:

https://user-images.githubusercontent.com/855818/185271889-bd4f86a0-986b-43bb-8121-bd77750d74f0.mov

Pull Request resolved: https://github.com/pytorch/audio/pull/2629

Reviewed By: carolineechen

Differential Revision: D38816417

Pulled By: mthrok

fbshipit-source-id: 11ee3f9121d9a302772ee1f461dacae52eb28852",moto,855818+mthrok@users.noreply.github.com,"['docs/requirements-tutorials.txt', 'docs/requirements.txt', 'docs/source/_static/css/custom.css']",False,18,8,2022
39d24d9ddb60ec6f43ac9255753a9ea315bd0349,"Fix doc warning (#2627)

Summary:
Resolves the following warning

```
/torchaudio/docs/source/transforms.rst:94: WARNING: Title underline too short.

:hidden:`Loudness`
-----------------
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2627

Reviewed By: carolineechen

Differential Revision: D38814802

Pulled By: mthrok

fbshipit-source-id: 5dfaf2d7bae22dba0f4a14f04ca63f28d6b2a749",moto,855818+mthrok@users.noreply.github.com,['docs/source/transforms.rst'],False,18,8,2022
7ac3e2e237e443baf91dfbf9893fca114c1c6001,"Use double quotes for string in functional and transforms (#2618)

Summary:
To make the code consistent, we should use double quotation marks for all strings. This PR make such changes in functional and transforms.

Pull Request resolved: https://github.com/pytorch/audio/pull/2618

Reviewed By: carolineechen

Differential Revision: D38744137

Pulled By: nateanl

fbshipit-source-id: 74213a24d9f66c306cc92019d77dcb2a877f94bd",Zhaoheng Ni,zni@fb.com,"['torchaudio/functional/filtering.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_multi_channel.py', 'torchaudio/transforms/_transforms.py']",False,16,8,2022
05545791920017c7103de28d69b41fbf0c426c0f,"Added example for AmplitudeToDB transform (#2615)

Summary:
Added example for AmplitudeToDB transform as mentioned in issue https://github.com/pytorch/audio/issues/1564.

Pull Request resolved: https://github.com/pytorch/audio/pull/2615

Reviewed By: carolineechen

Differential Revision: D38743117

Pulled By: nateanl

fbshipit-source-id: bf0f760299f4777a4bca65da86359faa00b16207",Ravi Makhija,ravi.makhija.pi@gmail.com,['torchaudio/transforms/_transforms.py'],False,16,8,2022
3742cebb7dc0f8adf24f4ee1cea368195c448f78,"Added example for MelScale transform (#2616)

Summary:
Added example for MelScale transform as mentioned in issue https://github.com/pytorch/audio/issues/1564.

Pull Request resolved: https://github.com/pytorch/audio/pull/2616

Reviewed By: carolineechen

Differential Revision: D38743145

Pulled By: nateanl

fbshipit-source-id: e24ca92f5317a0ea5a141418bf084b12cfb22486",Ravi Makhija,ravi.makhija.pi@gmail.com,['torchaudio/transforms/_transforms.py'],False,16,8,2022
9efefff18b332c6eb0cb0bfd508803bc7e83f77e,"Move xcode to 14 from 12.5 (#2622)

Summary:
Similar to https://github.com/pytorch/vision/pull/6218
Fixing MacOS builds

Pull Request resolved: https://github.com/pytorch/audio/pull/2622

Reviewed By: weiwangmeta

Differential Revision: D38722983

Pulled By: atalman

fbshipit-source-id: 4cef85c97dc270fc812bc289592c4f3815f73c85",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,16,8,2022
556a8dcdbe671cd18e04a59d2482a6b4ca65e10a,"Fix anaconda upload (#2621)

Summary:
Same as:
https://github.com/pytorch/vision/pull/6422

Testing:
```
export ANACONDA_PATH=$(conda info --base)/bin
echo $ANACONDA_PATH
/opt/homebrew/Caskroom/miniconda/base/bin
$ANACONDA_PATH/anaconda -V
anaconda Command line client (version 1.10.0)
```
Failure: https://github.com/pytorch/audio/runs/7837085749?check_suite_focus=true

Pull Request resolved: https://github.com/pytorch/audio/pull/2621

Reviewed By: weiwangmeta, seemethere

Differential Revision: D38714324

Pulled By: atalman

fbshipit-source-id: 55342cf69006e9250403c955202846bab4516f3e",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,15,8,2022
b475dc3d05909c069399bc15f3132c3a1be7c1f3,"Update doc version selector link (#2605)

Summary:
The link to version selector has been absolute link, which had been
a trap when reviewing gh-pages deployment from folk.

This commit changes that to relative link.

Pull Request resolved: https://github.com/pytorch/audio/pull/2605

Test Plan:
- https://mthrok.github.io/audio/main/index.html -> click version selector -> https://mthrok.github.io/audio/versions.html
- https://mthrok.github.io/audio/0.12.1/index.html -> click version selector -> https://pytorch.org/audio/versions.html

Reviewed By: carolineechen, nateanl

Differential Revision: D38695645

Pulled By: mthrok

fbshipit-source-id: 91132ac19b8c61f39d304a162435b9c6599ef2b2",moto,855818+mthrok@users.noreply.github.com,['docs/source/_templates/layout.html'],False,15,8,2022
aa591c0daf44b8287774604f83b8e9ba8782cfd1,"Remove outdated doc (#2617)

Summary:
`ctc_decoder` has become beta, remove it from prototype documents.

Pull Request resolved: https://github.com/pytorch/audio/pull/2617

Reviewed By: hwangjeff

Differential Revision: D38706869

Pulled By: nateanl

fbshipit-source-id: 41679f4e65a584b6b882af4551a50123f1dcef02",Zhaoheng Ni,zni@fb.com,['docs/source/index.rst'],False,15,8,2022
776cf0990b19dd568a845bbc1bf0c57f278512f5,"Introducing pytorch-cuda metapackage (#2612)

Summary:
Introducing pytorch-cuda metapackage

Same as: https://github.com/pytorch/vision/pull/6371
Following PR: https://github.com/pytorch/builder/pull/1094
Adds cuda metapackage called pytorch-cuda . This way we can make sure to install correct version of cuda dependencies and don't depend on conda-forge.

Pull Request resolved: https://github.com/pytorch/audio/pull/2612

Reviewed By: hwangjeff, seemethere, nateanl

Differential Revision: D38633332

Pulled By: atalman

fbshipit-source-id: 78a6115bb252ebdb6d66a57d7d2c4a4978ddb501",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/unittest/linux/scripts/install.sh', 'packaging/build_conda.sh', 'packaging/pkg_helpers.bash', 'packaging/torchaudio/meta.yaml', 'packaging/vs2019/conda_build_config.yaml', 'tools/setup_helpers/extension.py']",False,12,8,2022
f3bb30b8893b4700c668bd917389a28905831aaf,"Add additive noise function (#2608)

Summary:
Adds function `add_noise`, which computes and returns the sum of a waveform and scaled noise.

Pull Request resolved: https://github.com/pytorch/audio/pull/2608

Reviewed By: nateanl

Differential Revision: D38557141

Pulled By: hwangjeff

fbshipit-source-id: 1457fa213f43ca5b4333d3c7580971655d4260a0",hwangjeff,iamjeffhwang@gmail.com,"['docs/source/prototype.functional.rst', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/functional.py']",False,11,8,2022
cd4d66076708522ac8bf3adc8f19aea1d931e714,"Fix bug in Conformer RNN-T recipe (#2611)

Summary:
https://github.com/pytorch/audio/issues/2535 modified the Conformer RNN-T Lightning module to accept a SentencePiece model instance rather than a file path. This PR makes changes to account for this in the train script.

Pull Request resolved: https://github.com/pytorch/audio/pull/2611

Reviewed By: carolineechen

Differential Revision: D38578892

Pulled By: hwangjeff

fbshipit-source-id: ec3b9823ad30ffb730baa13d10d8b79020866aac",hwangjeff,iamjeffhwang@gmail.com,['examples/asr/librispeech_conformer_rnnt/train.py'],False,10,8,2022
fb4eb981a47d77d0ac45a6379eef3329ddc60c84,"Fixed argument validation in TorchAudio filtering (#2609)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2609

Converted argument validations in torchaudio/functional/filtering from assert based validation to the preferred if-then raise validation. Added specific error messages in all cases.

Reviewed By: mthrok

Differential Revision: D38515029

fbshipit-source-id: 6c644a042f86c6feb2bbe8bd02fdb484fe27fae9",Kunal Upadya,kunalu@fb.com,['torchaudio/functional/filtering.py'],False,10,8,2022
733ca909bbce938a6f1583c246d4ce74dd02f989,"Fix dataset docs parsing issue with extra spaces (#2607)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2607

Reviewed By: carolineechen, nateanl

Differential Revision: D38522606

Pulled By: skim0514

fbshipit-source-id: 2c38b8dcb343bcf624bfda1bfa2afd91abf2e668",Sean Kim,skim0514@fb.com,"['torchaudio/datasets/librilight_limited.py', 'torchaudio/datasets/librimix.py']",False,10,8,2022
03a0d68e9ab06d7e1fbf84280a65d104a07abcff,"Add NNLM support to CTC Decoder (#2528)

Summary:
Expose flashlight's LM and LMState classes to support decoding with custom language models, including NN LMs.

The `ctc_decoder` API is as follows
- To decode with KenLM, pass in KenLM language model path to `lm` variable
- To decode with custom LM, create Python class with `CTCDecoderLM` subclass, and pass in the class to `lm` variable. Additionally create a file of LM words listed in order of the LM index, with a word per line, and pass in the file to `lm_path`.
- To decode without a language model, set `lm` to `None` (default)

Validated against fairseq w2l decoder on sample LibriSpeech dataset and LM. Code for validation can be found [here](https://github.com/facebookresearch/fairseq/compare/main...carolineechen:fairseq:ctc-decoder). Also added unit tests to validate custom implementations of ZeroLM and KenLM, and also using a biased LM.

Follow ups:
- Train simple LM on LibriSpeech and demonstrate usage in tutorial or examples directory

cc jacobkahn

Pull Request resolved: https://github.com/pytorch/audio/pull/2528

Reviewed By: mthrok

Differential Revision: D38243802

Pulled By: carolineechen

fbshipit-source-id: 445e78f6c20bda655aabf819fc0f771fe68c73d7",Caroline Chen,carolinechen@fb.com,"['test/torchaudio_unittest/assets/decoder/nnlm_lex_dict.txt', 'test/torchaudio_unittest/assets/decoder/nnlm_lexfree_dict.txt', 'test/torchaudio_unittest/models/ctc_decoder_test.py', 'test/torchaudio_unittest/models/decoder/__init__.py', 'test/torchaudio_unittest/models/decoder/ctc_decoder_test.py', 'test/torchaudio_unittest/models/decoder/ctc_decoder_utils.py', 'torchaudio/models/decoder/__init__.py', 'torchaudio/models/decoder/_ctc_decoder.py']",False,9,8,2022
c15eee23964098f88ab0afe25a8d5cd9d728af54,"Fix stylecheck (#2606)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2606

Reviewed By: nateanl

Differential Revision: D38502666

Pulled By: carolineechen

fbshipit-source-id: 1e279996fff3621835a07882c63328856fe38f3a",Caroline Chen,carolinechen@fb.com,['torchaudio/transforms/_transforms.py'],False,8,8,2022
b396157d986a8d59ea8928938389a3d7aa1af4e0,"Add convolution operator (#2602)

Summary:
Adds functions `convolve` and `fftconvolve`, which compute the convolution of two tensors along their trailing dimension. The former performs the convolution directly, whereas the latter performs it using FFT.

Pull Request resolved: https://github.com/pytorch/audio/pull/2602

Reviewed By: nateanl, mthrok

Differential Revision: D38450771

Pulled By: hwangjeff

fbshipit-source-id: b2d1e063ba21eafeddf317d60749e7120b14292b",hwangjeff,iamjeffhwang@gmail.com,"['docs/source/index.rst', 'docs/source/prototype.functional.rst', 'docs/source/prototype.rst', 'test/torchaudio_unittest/prototype/functional/__init__.py', 'test/torchaudio_unittest/prototype/functional/autograd_cpu_test.py', 'test/torchaudio_unittest/prototype/functional/autograd_cuda_test.py', 'test/torchaudio_unittest/prototype/functional/autograd_test_impl.py', 'test/torchaudio_unittest/prototype/functional/batch_consistency_test.py', 'test/torchaudio_unittest/prototype/functional/functional_cpu_test.py', 'test/torchaudio_unittest/prototype/functional/functional_cuda_test.py', 'test/torchaudio_unittest/prototype/functional/functional_test_impl.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_cpu_test.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_cuda_test.py', 'test/torchaudio_unittest/prototype/functional/torchscript_consistency_test_impl.py', 'torchaudio/prototype/functional/__init__.py', 'torchaudio/prototype/functional/functional.py']",False,5,8,2022
33485b8c2284d2b69766d9404421b2a884223d31,"Add note for lexicon free decoder output (#2603)

Summary:
``words`` field of CTCHypothesis is empty if no lexicon is provided, which produces confusing output (see issue https://github.com/pytorch/audio/issues/2584) when following our tutorial example with lexicon free usage. This PR adds a note in both docs and tutorial.

Followup: determine if we want to modify the behavior of ``words`` in the lexicon free case. One option is to merge and then split the generated tokens by the input silent token to populate the words field, but this is tricky since the meaning of a ""word"" in the lexicon free case can be vague and not all languages have whitespaces between words, etc

Pull Request resolved: https://github.com/pytorch/audio/pull/2603

Reviewed By: mthrok

Differential Revision: D38459709

Pulled By: carolineechen

fbshipit-source-id: d64ff186df4633f00e94c64afeaa6a50cebf2934",Caroline Chen,carolinechen@fb.com,"['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'torchaudio/models/decoder/_ctc_decoder.py']",False,5,8,2022
50bba1df820fea35d6395f92b4a2c96821482156,"Added example for SlidingWindowCmn transform (#2600)

Summary:
Added example for `SlidingWindowCmn` transform as mentioned in issue https://github.com/pytorch/audio/issues/1564

Pull Request resolved: https://github.com/pytorch/audio/pull/2600

Reviewed By: mthrok

Differential Revision: D38395579

Pulled By: carolineechen

fbshipit-source-id: 44c5b7181789eedcaaa1d80149d5a1ab8de4c0ba",Ravi Makhija,ravi.makhija.pi@gmail.com,['torchaudio/transforms/_transforms.py'],False,5,8,2022
bcf958f6fd6589e1a3f7c406eafb8f9e9d6bbcae,"Added example for Vad transform (#2598)

Summary:
Added example for Vad transform as mentioned in issue https://github.com/pytorch/audio/issues/1564

Pull Request resolved: https://github.com/pytorch/audio/pull/2598

Reviewed By: mthrok

Differential Revision: D38432103

Pulled By: carolineechen

fbshipit-source-id: 8f7e26c48d4ffb6bfe55bba6f9c7ee915e6edaef",Ravi Makhija,87270246+ravimakhija@users.noreply.github.com,['torchaudio/transforms/_transforms.py'],False,5,8,2022
77a2baa81ef9f98da84ceb26c9ac63d83a6537ae,"Replace assert statements with raise in transforms (#2599)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2599

Bootcamp task T127107566.
Replacing assert statements  with if ... then raise so can be run in optimized mode

Reviewed By: mthrok

Differential Revision: D38370108

fbshipit-source-id: 74eaf5b72c511b62ddbb8e0e3b0ed638ad49e4f2",Omkar Vichare,ovichare@fb.com,"['torchaudio/transforms/_multi_channel.py', 'torchaudio/transforms/_transforms.py']",False,4,8,2022
6ecc11c2eb5c6fc60bddf43d59d06842fb2ab015,"Add HDEMUCS_HIGH_MUSDB (#2601)

Summary:
Add new model pretrained weights and tests

Pull Request resolved: https://github.com/pytorch/audio/pull/2601

Reviewed By: carolineechen, nateanl

Differential Revision: D38396673

Pulled By: skim0514

fbshipit-source-id: e06f97d28508543bc18e671344386a947bc870c1",Sean Kim,skim0514@fb.com,"['docs/source/prototype.pipelines.rst', 'test/integration_tests/source_separation_pipeline_test.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,3,8,2022
946b180af66971b3252bf0de1d117d72c68ee201,"An implemenation of the ITU-R BS.1770-4 loudness recommendation (#2472)

Summary:
I took a stab at implementing the ITU-R BS.1770-4 loudness recommendation (closes https://github.com/pytorch/audio/issues/1205). To give some more details:
- I've implemented K-weighting following csteinmetz1 instead of BrechtDeMan since it fit well with torchaudio's already implemented filters (`treble_biquad` and `highpass_biquad`).
- I've added four audio files to test compliance with the recommendation. These are linked in [this pdf](https://www.itu.int/dms_pub/itu-r/opb/rep/R-REP-BS.2217-2-2016-PDF-E.pdf). There are many more test files there but I didn't want to bog down the assets directory with too many files. Let me know if I should add or remove anything.
- I've kept many of the constant internal to the function (e.g. the block duration, overlap, and the absolute threshold gamma). I'm not sure if these should be exposed in the signature.
- I've implemented support for up to 5 channels (following both csteinmetz1 and BrechtDeMan). The recommendation includes weights for up to 24 channels. Is there any convention for how many channels to support?

I hope this is helpful! looking forward to hearing from you.

Pull Request resolved: https://github.com/pytorch/audio/pull/2472

Reviewed By: hwangjeff

Differential Revision: D38389155

Pulled By: carolineechen

fbshipit-source-id: fcc86d864c04ab2bedaa9acd941ebc4478ca6904",bshall,benji.l.shall@gmail.com,"['docs/source/functional.rst', 'docs/source/transforms.rst', 'test/integration_tests/loudness_compliance_test.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",False,3,8,2022
8e0c2a3bab2c09c1d489377b66c1dfbf4c79498d,"ci: Fix anaconda uploading (#2581)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2581

Also removes spurious lines of code that were erroring out silently

Signed-off-by: Eli Uriegas <eliuriegas@fb.com>

Test Plan: Imported from OSS

Reviewed By: carolineechen

Differential Revision: D38336705

Pulled By: seemethere

fbshipit-source-id: 700a969a4bace7d9ca94a9db908b29f383b7d94e",Eli Uriegas,eliuriegas@fb.com,['.github/workflows/build-m1-binaries.yml'],False,2,8,2022
ccb2d6f2995455ee5249c38f8ba9d7ce783a2abd,"Added example for Vol transform (#2597)

Summary:
Added example for [Vol transform](https://pytorch.org/audio/stable/transforms.html#torchaudio.transforms.Vol) as mentioned in this issue https://github.com/pytorch/audio/issues/1564.

Also made a minor edit to the docstring for `class Vol` to fix a grammar typo and use more common verbiage.

Pull Request resolved: https://github.com/pytorch/audio/pull/2597

Reviewed By: nateanl, mthrok

Differential Revision: D38316433

Pulled By: carolineechen

fbshipit-source-id: 0be8fc505800a59acdab843813767acfdeac8243",Ravi Makhija,ravi.makhija.pi@gmail.com,['torchaudio/transforms/_transforms.py'],False,1,8,2022
e646de729f71f583662655b2b34116932f20ebd2,"Fix typo - ""dimension"" (#2596)

Summary:
Fixed minor typo in `Contributing.md`: ""diemension"" -> ""dimension""

Pull Request resolved: https://github.com/pytorch/audio/pull/2596

Reviewed By: mthrok

Differential Revision: D38315517

Pulled By: carolineechen

fbshipit-source-id: 5e771f22a5be008d3be30b4699fb5cc5637c627d",Ravi Makhija,ravi.makhija.pi@gmail.com,['CONTRIBUTING.md'],False,1,8,2022
f1443b8feda3dbaba2d0fa2a3a3ca14e4f3db73c,"Update data augmentation tutorial (#2595)

Summary:
In https://github.com/pytorch/audio/pull/2285, the SNR calculation was fixed,
but there was still one that was not fixed. This commit fixes it.

Also following the feedback https://github.com/pytorch/tutorials/issues/1930#issuecomment-1199741336, update the variable name.

Pull Request resolved: https://github.com/pytorch/audio/pull/2595

Reviewed By: carolineechen

Differential Revision: D38314672

Pulled By: mthrok

fbshipit-source-id: b2015e2709729190d97264aa191651b3af4ba856",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/audio_data_augmentation_tutorial.py'],False,1,8,2022
e502df0106403f7666f89fee09715256ea2e0df3,"Replace assert with raise in torchaudio.models (#2590)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2590

Converted assert checks for argument validation to if-else checks so that they are executed in optimized mode as well.

Reviewed By: mthrok

Differential Revision: D38211246

fbshipit-source-id: 922b5bcafe8214980e535527dd94c3345c1ff3e2",Ansh Nanda,anshn@fb.com,"['torchaudio/models/conformer.py', 'torchaudio/models/emformer.py', 'torchaudio/models/rnnt_decoder.py', 'torchaudio/models/tacotron2.py', 'torchaudio/models/wav2vec2/components.py', 'torchaudio/models/wav2vec2/model.py', 'torchaudio/models/wavernn.py']",False,30,7,2022
c26b38b29b3f3f972f50057df20d0a226dc062a4,"Update forced alignment tutorial (#2544)

Summary:
1. Fix initialization.
Previously, the SOS token score was initialized to 0 across the time axis.
This was biasing the alignment to delay the start.
The proper way to delay the SOS is via blank token.
The new initilization takes the cumulated sum of blank scores.
2. Fill the end of trellis with Inf
Similar to the start, at the end where there remaining time frame is less
than the number of tokens, it is no longer possible to align the text, thus
we fill with Inf for better visualization.
3. Clean up asset management code.

Pull Request resolved: https://github.com/pytorch/audio/pull/2544

Reviewed By: nateanl

Differential Revision: D38276478

Pulled By: mthrok

fbshipit-source-id: 6d934cc850a0790b8c463a4f69f8f1143633d299",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/forced_alignment_tutorial.py'],False,29,7,2022
67cb420d0c54ee27682d3ceb1e20872b39f17a35,"Enable CTC decoder in Windows (#2587)

Summary:
This commit enables CTC decoder on Windows.

The functionality seems to work fine.
The tests are passing, the decoding tutorial runs fine.

The only difference to the Linux/macOS version is that
loading model in XZ compression format is not supported.

![289961785_399620772041679_7768117002438616376_n](https://user-images.githubusercontent.com/855818/181420923-cfbd8402-20de-4e63-b9e4-e39f9aa9fc50.png)

Pull Request resolved: https://github.com/pytorch/audio/pull/2587

Reviewed By: carolineechen, nateanl

Differential Revision: D38276490

Pulled By: mthrok

fbshipit-source-id: f2203b2235c5bbb0220fe560aaaf0e1d5530347a",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'CMakeLists.txt', 'third_party/CMakeLists.txt', 'third_party/bzip2/CMakeLists.txt', 'third_party/flashlight-text/CMakeLists.txt', 'third_party/kenlm/CMakeLists.txt', 'third_party/zlib/CMakeLists.txt', 'tools/setup_helpers/extension.py']",False,29,7,2022
f234e51ff8e5c8b6a7971b608b72f0e4eb602db2,"Replace 'runtime_error' exception with 'TORCH_CHECK' in TorchAudio sox (#2592)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2592

std::runtime_error does not preserve the C++ stack trace, so it is unclear to users what went wrong internally.

PyTorch's TORCH_CHECK macro allows to print C++ stack trace when TORCH_SHOW_CPP_STACKTRACES environment variable is set to 1.

Reviewed By: mthrok

Differential Revision: D38219331

fbshipit-source-id: f51c27111077e927f97127f73f83a31b8e74f61f",Javier Cardenete Morales,jcardenete@fb.com,"['torchaudio/csrc/sox/effects.cpp', 'torchaudio/csrc/sox/effects_chain.cpp', 'torchaudio/csrc/sox/io.cpp', 'torchaudio/csrc/sox/types.cpp', 'torchaudio/csrc/sox/utils.cpp']",False,29,7,2022
d626703191eed866cfe2512d51ebd37f07057a14,"Improve speech enhancement tutorial (#2527)

Summary:
- The ""speech + noise"" mixture still has a high SNR, which can't show the effectiveness of MVDR beamforming. To make the task more challenging, amplify the noise waveform to reduce the SNR of mixture speech.
- Show the Si-SNR score of mixture speech when visualizing the mixture spectrogram.
- FIx the figure in `rtf_power` subsection.
    - The description of enhanced spectrogram by `rtf_power` is wrong. Correct it to `rtf_power`.
- Print PESQ, STOI, and SDR metric scores.

Pull Request resolved: https://github.com/pytorch/audio/pull/2527

Reviewed By: mthrok

Differential Revision: D38190218

Pulled By: nateanl

fbshipit-source-id: 39562850a67f58a16e0a2866ed95f78c3f4dc7de",Zhaoheng Ni,zni@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'docs/requirements-tutorials.txt', 'examples/tutorials/mvdr_tutorial.py']",False,29,7,2022
0fde7c57da6a8a73050bbf1919c614b9f6e55d58,"Add Union normalization parameter on spectrogram and inverse spectrogram (#2554)

Summary:
Add str to normalized parameter to enable frame_length based normalization to align with torch implementation of stft. Addresses issue https://github.com/pytorch/audio/issues/2104

Pull Request resolved: https://github.com/pytorch/audio/pull/2554

Reviewed By: carolineechen, mthrok

Differential Revision: D38247554

Pulled By: skim0514

fbshipit-source-id: c243c7a6b8fda2a1e565cef4600f7c5a06baf602",Sean Kim,skim0514@fb.com,"['test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,28,7,2022
338e310438d2e1f6a531d058405f27a01fbf7e58,"Change docstring for easier understanding (#2570)

Summary:
Edit factory function's docstrings.

Pull Request resolved: https://github.com/pytorch/audio/pull/2570

Reviewed By: carolineechen

Differential Revision: D38250369

Pulled By: skim0514

fbshipit-source-id: fa777e37d7cc517cf4ff1842d5585bf36558f50a",Sean Kim,skim0514@fb.com,"['test/torchaudio_unittest/prototype/hdemucs_test_impl.py', 'torchaudio/prototype/models/hdemucs.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,28,7,2022
39b6343dcf6e5aa23bbfe1121113d0771d2bc8a2,"Migrate CTC decoder code (#2580)

Summary:
This commit gets rid of our copy of CTC decoder code and
replace it with upstream Flashlight-Text repo.

Pull Request resolved: https://github.com/pytorch/audio/pull/2580

Reviewed By: carolineechen

Differential Revision: D38244906

Pulled By: mthrok

fbshipit-source-id: d274240fc67675552d19ff35e9a363b9b9048721",moto,855818+mthrok@users.noreply.github.com,"['.gitmodules', 'third_party/CMakeLists.txt', 'third_party/flashlight-text/CMakeLists.txt', 'third_party/flashlight-text/submodule', 'third_party/kenlm/CMakeLists.txt', 'third_party/kenlm/kenlm', 'tools/setup_helpers/extension.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/decoder/bindings/pybind.cpp', 'torchaudio/csrc/decoder/src/decoder/Decoder.h', 'torchaudio/csrc/decoder/src/decoder/LexiconDecoder.cpp', 'torchaudio/csrc/decoder/src/decoder/LexiconDecoder.h', 'torchaudio/csrc/decoder/src/decoder/LexiconFreeDecoder.cpp', 'torchaudio/csrc/decoder/src/decoder/LexiconFreeDecoder.h', 'torchaudio/csrc/decoder/src/decoder/Trie.cpp', 'torchaudio/csrc/decoder/src/decoder/Trie.h', 'torchaudio/csrc/decoder/src/decoder/Utils.cpp', 'torchaudio/csrc/decoder/src/decoder/Utils.h', 'torchaudio/csrc/decoder/src/decoder/lm/KenLM.cpp', 'torchaudio/csrc/decoder/src/decoder/lm/KenLM.h', 'torchaudio/csrc/decoder/src/decoder/lm/LM.h', 'torchaudio/csrc/decoder/src/decoder/lm/ZeroLM.cpp', 'torchaudio/csrc/decoder/src/decoder/lm/ZeroLM.h', 'torchaudio/csrc/decoder/src/dictionary/Defines.h', 'torchaudio/csrc/decoder/src/dictionary/Dictionary.cpp', 'torchaudio/csrc/decoder/src/dictionary/Dictionary.h', 'torchaudio/csrc/decoder/src/dictionary/String.cpp', 'torchaudio/csrc/decoder/src/dictionary/String.h', 'torchaudio/csrc/decoder/src/dictionary/System.cpp', 'torchaudio/csrc/decoder/src/dictionary/System.h', 'torchaudio/csrc/decoder/src/dictionary/Utils.cpp', 'torchaudio/csrc/decoder/src/dictionary/Utils.h', 'torchaudio/models/decoder/_ctc_decoder.py']",False,28,7,2022
919fd0c4bb96a0ea60b68607b29590b509532d57,"Create tutorial for HDemucs (#2572)

Summary:
Add tutorial python file, draft PR, will continue to modify accordingly to feedback.

Future plan: modify spectrogram and bottom audio design and work on finding best audio track and segments

Pull Request resolved: https://github.com/pytorch/audio/pull/2572

Reviewed By: carolineechen, nateanl, mthrok

Differential Revision: D38234001

Pulled By: skim0514

fbshipit-source-id: fe9207864f354dec5cf5ff52bf7d9ddcf4a001d5",Sean Kim,skim0514@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'docs/requirements-tutorials.txt', 'docs/source/index.rst', 'examples/tutorials/hybrid_demucs_tutorial.py']",False,28,7,2022
08395ba617bf085a1de7a20ed49d6c510c4032c3,"Remove deprecated prototype alias (#2583)

Summary:
CTC decoder and StreamReader are now in the main library.
This commit removes their aliases in `torchaudio.prototypes`

Pull Request resolved: https://github.com/pytorch/audio/pull/2583

Reviewed By: mthrok

Differential Revision: D38189314

fbshipit-source-id: c62209f2ad4f7052c6756a537b6fc509064e428c",Vamsi Desu,vamsidesu@fb.com,"['torchaudio/prototype/ctc_decoder/__init__.py', 'torchaudio/prototype/io/__init__.py']",False,28,7,2022
0092aa3cd61d356da5ac19a6706fc4783dc38c1b,"Fix hubert fine-tuning recipe bugs (#2588)

Summary:
- The optimizer in fine-tuning recipe should also be `AdamW`. See https://github.com/pytorch/audio/pull/2412
- Fix the import of `DistributedBatchSampler` in hubert dataset
- Fix `dataset_path` in fine-tuning module.

Pull Request resolved: https://github.com/pytorch/audio/pull/2588

Reviewed By: carolineechen

Differential Revision: D38243423

Pulled By: nateanl

fbshipit-source-id: badc88ce9eddfd71270201a65ae89433fae2733f",Zhaoheng Ni,zni@fb.com,"['examples/hubert/README.md', 'examples/hubert/dataset/__init__.py', 'examples/hubert/finetune.py', 'examples/hubert/lightning.py']",False,28,7,2022
d84ce3b20f6a695fcfe2c21d0e440194db77c987,"Refactor cmake (#2585)

Summary:
Extract the helper functions for defining library and extension so that they can be reused for building flashlight library and binding in https://github.com/pytorch/audio/issues/2580.

Pull Request resolved: https://github.com/pytorch/audio/pull/2585

Reviewed By: carolineechen

Differential Revision: D38233407

Pulled By: mthrok

fbshipit-source-id: 96f7c62a8b70bb3ff5caede9730165d54a55272f",moto,855818+mthrok@users.noreply.github.com,"['CMakeLists.txt', 'cmake/TorchAudioHelper.cmake', 'torchaudio/csrc/CMakeLists.txt']",False,28,7,2022
04057fa6353340e6db9430d7ae8e26623a7f1770,"Replaced CHECK_ by TORCH_CHECK_ (#2582)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2582

CHECK_ were deprecated in upstream so we should replace them here as
well

Similar to https://github.com/pytorch/vision/pull/6322, relates to https://github.com/pytorch/pytorch/pull/82032

Signed-off-by: Eli Uriegas <eliuriegas@fb.com>

Test Plan: Imported from OSS

Reviewed By: malfet, mthrok

Differential Revision: D38208356

Pulled By: seemethere

fbshipit-source-id: 6f42d517362f415e0775803514eee2628402918f",Eli Uriegas,eliuriegas@fb.com,"['torchaudio/csrc/rnnt/cpu/compute.cpp', 'torchaudio/csrc/rnnt/cpu/compute_alphas.cpp', 'torchaudio/csrc/rnnt/cpu/compute_betas.cpp', 'torchaudio/csrc/rnnt/cpu/cpu_kernels.h', 'torchaudio/csrc/rnnt/cpu/cpu_transducer.h', 'torchaudio/csrc/rnnt/gpu/compute.cu', 'torchaudio/csrc/rnnt/gpu/compute_alphas.cu', 'torchaudio/csrc/rnnt/gpu/compute_betas.cu', 'torchaudio/csrc/rnnt/workspace.h']",False,27,7,2022
34ef7e9cd55fc558f691ae32c61fbd3baec7f9fa,"Replace assert with raise in prototypes.models (#2578)

Summary:
This commit replaces the use of assert with `if ~ then raise` idiom,
So that they are executed even when Python is running in optimized mode.

Pull Request resolved: https://github.com/pytorch/audio/pull/2578

Reviewed By: mthrok

Differential Revision: D38158122

fbshipit-source-id: da561145a6e021238e9e9df10ab8d2d3a751fb69",Son Dinh,sondinh@fb.com,"['torchaudio/prototype/models/conv_emformer.py', 'torchaudio/prototype/models/hdemucs.py']",False,27,7,2022
0f4e1e8c63113efca847c7c72fc5d853399189bc,"Replace assert with raise (#2579)

Summary:
`assert` is not executed when running in optimized mode.

This commit replaces all instances of ""assert"" in /fbcode/pytorch/audio/torchaudio/functional/functional.py

Pull Request resolved: https://github.com/pytorch/audio/pull/2579

Reviewed By: mthrok

Differential Revision: D38158280

fbshipit-source-id: f8d7fca1c8f9b3955c6ca312b16947eb12894d81",Piyush Soni,piyush27@fb.com,['torchaudio/functional/functional.py'],False,27,7,2022
5bf73b591dcef337051fe0bbbe9352cd682810d6,"Fix argument validation in TorchAudio datasets (#2571)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2571

Per T127106783, replace `assert` statement with `if _ then raise` statement to enforce the assertion even in optimized mode

Reviewed By: mthrok

Differential Revision: D38123481

fbshipit-source-id: 19321f7467bfd993b38bd9e44fcd01e5f5e64b87",Yu Shi,yushi@fb.com,"['torchaudio/datasets/commonvoice.py', 'torchaudio/datasets/fluentcommands.py', 'torchaudio/datasets/gtzan.py', 'torchaudio/datasets/librilight_limited.py', 'torchaudio/datasets/musdb_hq.py', 'torchaudio/datasets/quesst14.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/voxceleb1.py']",False,26,7,2022
379487de3200c812e8e0a233df942cf3c7526e9a,"Dataset docstring change (#2575)

Summary:
Quick docstring change, adding extra line to properly parse

Pull Request resolved: https://github.com/pytorch/audio/pull/2575

Reviewed By: mthrok

Differential Revision: D38138566

Pulled By: skim0514

fbshipit-source-id: fc1ed68ed0050e194944714c753fb35adc85b27e",Sean Kim,skim0514@fb.com,['torchaudio/datasets/musdb_hq.py'],False,26,7,2022
075a770640e4efd54c923d1794b704c8cd1a4f54,"Switch to flashlight decoder from upstream (#2557)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2557

Allow the use of flahslight-decoder from upstream

Reviewed By: carolineechen

Differential Revision: D37983846

fbshipit-source-id: edb1b701bd18718b3b10cf51cc63d3924d4cc073",Moto Hira,moto@fb.com,"['torchaudio/models/decoder/__init__.py', 'torchaudio/models/decoder/_ctc_decoder.py']",False,26,7,2022
4c4da32c0ab90ad7ec8b08e42f6d2005e9de4acb,"New Pipeline edits for HDemucs (#2565)

Summary:
Created new branch and brought in commits due to rebasing issues, resolved conflicts on new branch, close old branch.

Pull Request resolved: https://github.com/pytorch/audio/pull/2565

Reviewed By: nateanl, mthrok

Differential Revision: D38131189

Pulled By: skim0514

fbshipit-source-id: 96531480cf50562944abb28d70879f21b4609f15",Sean Kim,skim0514@fb.com,"['docs/source/prototype.pipelines.rst', 'test/integration_tests/conftest.py', 'test/integration_tests/source_separation_pipeline_test.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,26,7,2022
45f512f65607331a4b6d8ce3875fa63f1b07947e,"Delay the import of kaldi_io (#2573)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2573

Moved the call to kaldo_io to each function (instead of up top) to delay the call.

Reviewed By: mthrok

Differential Revision: D38108022

fbshipit-source-id: 4ba8cc6a942a00de83668bbb7e361d5ae8b773eb",Abhinav Gupta,abhinav1010@fb.com,['torchaudio/kaldi_io.py'],False,26,7,2022
1634ed01bc7248f43971522669a93b8f6bcfc740,"[BC-breaking] Fix momentum in transforms.GriffinLim (#2568)

Summary:
The momentum in GriffinLim transform is modified before being passed
to the functional. causing inconsistency between functional and transforms.

Fix this by making it pass through in transform.

Fixes https://github.com/pytorch/audio/issues/2567

Pull Request resolved: https://github.com/pytorch/audio/pull/2568

Reviewed By: nateanl

Differential Revision: D38117632

Pulled By: mthrok

fbshipit-source-id: 99754be4b3b6dea45ba115aaea9fb6d7285bc2c9",proxyphi,proxyself001@gmail.com,"['torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,25,7,2022
8dcf06acee1f008bdb693de459caf59aa760c7e7,"Integration test fix deleting temporary directory (#2569)

Summary:
Previous Issue: --use-tmp-hub-dir expected the temp directories used to store large file to be deleted after each test case, but pytest erases directories after 3 full test sessions. This commit fixes by manually deleting a new subdirectory created in each test case. https://github.com/pytorch/audio/pull/2565#discussion_r929007101

Pull Request resolved: https://github.com/pytorch/audio/pull/2569

Reviewed By: nateanl

Differential Revision: D38117848

Pulled By: skim0514

fbshipit-source-id: 3767cb8df1238fd6218f6aaa58d5d583cea72699",Sean Kim,skim0514@fb.com,['test/integration_tests/conftest.py'],False,25,7,2022
81780c952e13c7f2970b5401f6ba70e6f9a775c1,"Fix build_docs job (#2543)

Summary:
This commit fix build_docs job timeout by pinning `resampy=0.2.2`.

For some mysterious reason, `resampy=0.3.1` causes slowdown of unrelated code. https://github.com/bmcfee/resampy/issues/106

Pull Request resolved: https://github.com/pytorch/audio/pull/2543

Reviewed By: carolineechen

Differential Revision: D38115003

Pulled By: mthrok

fbshipit-source-id: 67cd1c73dd4adb3091e0b88aaf5c31de0dd4b87e",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'docs/requirements.txt']",False,25,7,2022
b1f510fa5681e92ee82bdc6b2d1ed896799fc32c,"Add dimension and shape check (#2563)

Summary:
Don't allow users to input incorrect dimensions

Pull Request resolved: https://github.com/pytorch/audio/pull/2563

Reviewed By: carolineechen

Differential Revision: D38074360

Pulled By: skim0514

fbshipit-source-id: 7bcae515706eb358ca6f68c50c7c0ccace1c3f95",Sean Kim,skim0514@fb.com,['torchaudio/prototype/models/hdemucs.py'],False,22,7,2022
6cee56abd2430b111aa13d302e3de47efb75d93c,"Add documents for SourceSeparationBundle (#2559)

Summary:
- Add documentation page for `SourceSeparationBundle` and `CONVTASNET_BASE_LIBRI2MIX`.
- Add citation of Libri2Mix dataset in the bundle documentation.
- url in integration test should use slash instead of `os.path.join` as it will fail on Windows. Change it to f-string.

Pull Request resolved: https://github.com/pytorch/audio/pull/2559

Reviewed By: carolineechen

Differential Revision: D38036116

Pulled By: nateanl

fbshipit-source-id: 736732805191113955badfec3955e2e24e8f4836",Zhaoheng Ni,zni@fb.com,"['docs/source/prototype.pipelines.rst', 'test/integration_tests/conftest.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,22,7,2022
c18a103b784ae7067130e240eed743bc45c36e28,"fix resample (#2561)

Summary:
Added back device in case of tensor creation

Pull Request resolved: https://github.com/pytorch/audio/pull/2561

Reviewed By: mthrok

Differential Revision: D38035351

Pulled By: skim0514

fbshipit-source-id: bdea07cbb34d0aa487187cded1a5636da6623d96",Sean Kim,skim0514@fb.com,['torchaudio/functional/functional.py'],False,21,7,2022
4778c2e517ac5e3f7b715d9ff99e655f8df8f806,"Fix fall back failure in sox_io backend (#2560)

Summary:
Fix the fallback function of load fileobj function in sox_io backend.

The typo in the fallback function prevents showing the intended error message.

Pull Request resolved: https://github.com/pytorch/audio/pull/2560

Reviewed By: carolineechen, nateanl

Differential Revision: D38035077

Pulled By: mthrok

fbshipit-source-id: 53c91c0569c7e7bba611aed6ea748dbd2f323221",Jumon Nozaki,jumon.nozaki@gmail.com,['torchaudio/backend/sox_io_backend.py'],False,21,7,2022
f0088599137f9e4512dff7a8b6ace8f14c0dfafc,"ci: Update macos runners to AWS self hosted (#2556)

Summary:
Updates the runner to the latest apple silicon machines we have that
also run on macOS 12.4

Similar to https://github.com/pytorch/vision/pull/6290

Signed-off-by: Eli Uriegas <eliuriegas@fb.com>

Pull Request resolved: https://github.com/pytorch/audio/pull/2556

Reviewed By: atalman, mthrok

Differential Revision: D37999959

Pulled By: seemethere

fbshipit-source-id: 01d2ff01e48dcc0c4e33ed81758886fa19642aa3",Eli Uriegas,eliuriegas@fb.com,"['.github/workflows/build-m1-binaries.yml', 'packaging/pkg_helpers.bash']",False,21,7,2022
8336258049bea5ad45940b0ab5804418931497fe,"Add SourceSeparationBundle to prototype (#2440)

Summary:
- Add SourceSeparationBundle class for source separation pipeline
- Add `CONVTASNET_BASE_LIBRI2MIX` that is trained on Libri2Mix dataset.
- Add integration test with example mixture audio and expected scale-invariant signal-to-distortion ratio (Si-SDR) score. The test computes the Si-SDR score with permutation-invariant training (PIT) criterion for all permutations of sources and use the highest value as the final output. The test verifies if the score is equal to or larger than the expected value.

Pull Request resolved: https://github.com/pytorch/audio/pull/2440

Reviewed By: mthrok

Differential Revision: D37997646

Pulled By: nateanl

fbshipit-source-id: c951bcbbe8b7ed9553cb8793d6dc1ef90d5a29fe",Zhaoheng Ni,zni@fb.com,"['test/integration_tests/conftest.py', 'test/integration_tests/source_separation_pipeline_test.py', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/source_separation_pipeline.py']",False,21,7,2022
5c6e602c78f075d8a4ba2de1db4f1a35a8f96150,"Speed up resample with kernel generation modification (#2553)

Summary:
Modification from pull request https://github.com/pytorch/audio/issues/2415 to improve resample.

Benchmarked for a 89% time reduction, tested in comparison to original resample method.

Pull Request resolved: https://github.com/pytorch/audio/pull/2553

Reviewed By: carolineechen

Differential Revision: D37997533

Pulled By: skim0514

fbshipit-source-id: ef4b719450ac26794db6ea01f9882509f4fda5cf",Sean Kim,skim0514@fb.com,['torchaudio/functional/functional.py'],False,20,7,2022
a2d6fee2fa71741e70130a8b83520ebcf81e95f3,"Replace `runtime_error` exception with `TORCH_CHECK` in TorchAudio ffmpeg dir (2/2) (#2551)

Summary:
`std::runtime_error` does not preserve the C++ stack trace, so it is unclear to users what went wrong internally.

PyTorch's `TORCH_CHECK` macro allows to print C++ stack trace when `TORCH_SHOW_CPP_STACKTRACES` environment variable is set to 1.

Pull Request resolved: https://github.com/pytorch/audio/pull/2551

Improve assertion for TorchAudio ffmpeg directory

Reviewed By: mthrok

Differential Revision: D37915732

fbshipit-source-id: 9f597eb00cadd0dc6a1bbf8f7d5c8092804ef685",John Lu,johnthelu@fb.com,"['torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp']",False,19,7,2022
ee631d6bb4d4e1a4a6273c14607f570118e08bca,"Remove boost (#2552)

Summary:
After reviewing the code for KenLM it turned out that we can build it without boost.

Pull Request resolved: https://github.com/pytorch/audio/pull/2552

Reviewed By: xiaohui-zhang

Differential Revision: D37949699

Pulled By: mthrok

fbshipit-source-id: 4a4ffae4220d0b764b53f52b93040670d91a84a3",moto,855818+mthrok@users.noreply.github.com,"['setup.py', 'third_party/CMakeLists.txt', 'third_party/boost/CMakeLists.txt', 'third_party/kenlm/CMakeLists.txt']",False,19,7,2022
62854588d45c9bbaaef7db92724fbdc4c8e5c6a0,"Adding pipeline changes, factory functions to HDemucs (#2547)

Summary:
Factory functions have been added to HDemucs class and test the implementation within the testing files.

Pull Request resolved: https://github.com/pytorch/audio/pull/2547

Reviewed By: carolineechen

Differential Revision: D37948600

Pulled By: skim0514

fbshipit-source-id: 7ac4e4a71519450cfbbc24ff7d7e70521f676040",Sean Kim,skim0514@fb.com,"['.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh', 'docs/source/prototype.models.rst', 'test/torchaudio_unittest/prototype/hdemucs_cpu_test.py', 'test/torchaudio_unittest/prototype/hdemucs_gpu_test.py', 'test/torchaudio_unittest/prototype/hdemucs_test_impl.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/hdemucs.py']",False,19,7,2022
af6ebbaee9b28afc8080a1417ee9d05ae5ce6e28,"Replace `runtime_error` exception with `TORCH_CHECK` in TorchAudio ffmpeg dir (1/2) (#2550)

Summary:
`std::runtime_error` does not preserve the C++ stack trace, so it is unclear to users what went wrong internally.

PyTorch's `TORCH_CHECK` macro allows to print C++ stack trace when `TORCH_SHOW_CPP_STACKTRACES` environment variable is set to 1.

Pull Request resolved: https://github.com/pytorch/audio/pull/2550

Improves assertion for TorchAudio ffmpeg directory

Reviewed By: mthrok

Differential Revision: D37914953

fbshipit-source-id: 7704c41bb88b0616ae2e73961a5496bc0d95cf13",John Lu,johnthelu@fb.com,"['torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/pybind/typedefs.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp']",False,18,7,2022
b53ff1b96fdba9885a40857dec6d25ae87f3e5d4,"Set MACOSX_DEPLOYMENT_TARGET=10.9 in binary build jobs (#2546)

Summary:
Recent CircleCI migration https://github.com/pytorch/audio/pull/2529
silently bumped the minimum supported macOS version to 11.

PyTorch still supports 10.9 and the ecosystem still uses 10.9.
Issue: https://github.com/pytorch/audio/issues/2536

This commit sets MACOSX_DEPLOYMENT_TARGET=10.9, so that binary
distribution are compatible on macOS=10.9.

Pull Request resolved: https://github.com/pytorch/audio/pull/2546

Reviewed By: atalman

Differential Revision: D37854586

Pulled By: mthrok

fbshipit-source-id: a43986ae4de9ef51a4261e0f9fe58e88b4b72148",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'packaging/torchaudio/meta.yaml']",False,15,7,2022
632ea670544a2d2aad4f011a632281ebe3d13f80,"Simplify the requirements to minimum runtime dependencies (#2313)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2313

Reviewed By: carolineechen, nateanl

Differential Revision: D37799552

Pulled By: mthrok

fbshipit-source-id: 12e27fccb7098f3142e9ca0b748c71325cd324ee",moto,855818+mthrok@users.noreply.github.com,"['docs/requirements-tutorials.txt', 'requirements.txt']",False,12,7,2022
9930314361ae8729046273e91da1dfe4b7fcbaca,"Docstring change for Hybrid Demucs (#2542)

Summary:
Small edit to docstring for kernel

Pull Request resolved: https://github.com/pytorch/audio/pull/2542

Reviewed By: carolineechen

Differential Revision: D37797937

Pulled By: skim0514

fbshipit-source-id: 4bdd1e3ddb49cbdf2bd5367edb03cf9603d4ec6e",Sean Kim,skim0514@fb.com,['torchaudio/prototype/models/hdemucs.py'],False,12,7,2022
4ba563230522966cc7fe7a1c68b60e5be2de21c1,"Simplify HW acceleration code (#2534)

Summary:
FFmpeg's API provide multiple ways to initialize decoder. This PR simplifies the initialization by delegating the HW device context management to FFmpeg's native code.

Pull Request resolved: https://github.com/pytorch/audio/pull/2534

Reviewed By: hwangjeff

Differential Revision: D37734573

Pulled By: mthrok

fbshipit-source-id: e61736b4d4d2ca6e94d8965abd93b4e9a68e7351",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.h']",False,12,7,2022
608b8ea67d63209b26f4e89d27efaa4f040421f3,"Hybrid Demucs model implementation (#2506)

Summary:
Draft PR with initial model implementation with minor changes from previous implementation

Pull Request resolved: https://github.com/pytorch/audio/pull/2506

Reviewed By: nateanl

Differential Revision: D37762671

Pulled By: skim0514

fbshipit-source-id: b7dc0a6ef725d6ae6d76c23c882623f7d339977c",Sean Kim,skim0514@fb.com,"['docs/source/prototype.models.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/prototype/hdemucs_cpu_test.py', 'test/torchaudio_unittest/prototype/hdemucs_gpu_test.py', 'test/torchaudio_unittest/prototype/hdemucs_test_impl.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/hdemucs.py']",False,12,7,2022
e26414529205e8c666303ccc3edc302d976ef9c9,"Clean up the interface around dictionary (#2533)

Summary:
Python dictionary is bound to different types in TorchBind and PyBind.
StreamReader has methods that receive and return dictionary.

This commit cleans up the treatment of dictionary and consolidate
helper functions.

* The core implementation and TorchBind all uses `c10::Dict`.
* PyBind version uses `std::map` and converts it to `c10::Dict`.
* The helper functions to convert `std::map` <-> `c10::Dict` are consolidated in pybind directory.
* The wrapper methods are implemented in `pybind` dir.

Pull Request resolved: https://github.com/pytorch/audio/pull/2533

Reviewed By: hwangjeff

Differential Revision: D37731866

Pulled By: mthrok

fbshipit-source-id: 5a5cf1372668f7d3aacc0bb461bc69fa07212f3f",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/pybind/typedefs.cpp', 'torchaudio/csrc/ffmpeg/pybind/typedefs.h', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h']",False,12,7,2022
05d2580a6886f2ba47a20b2b6f1382c25c9fc397,"Fix docstring (#2540)

Summary:
The docstring of `apply_beamforming` has warning when building the documentation page. Fix it in this PR.

Pull Request resolved: https://github.com/pytorch/audio/pull/2540

Reviewed By: mthrok

Differential Revision: D37763745

Pulled By: nateanl

fbshipit-source-id: 0e9f1e098865af032b00ac56d918cb9d2ffc5024",Zhaoheng Ni,zni@fb.com,['torchaudio/functional/functional.py'],False,12,7,2022
a7d1b31c68e5fd5e5b0b62d5c9114a2a40a4bc20,"Revise LibriSpeech Conformer RNN-T recipe (#2535)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2535

Modifies LibriSpeech Conformer RNN-T example recipe to make the Lightning module and datamodule more generic and reusable.

Reviewed By: mthrok

Differential Revision: D36731576

fbshipit-source-id: 4643e86fac78f3c2bacc15f5d385bc7b10f410a2",Jeff Hwang,jeffhwang@fb.com,"['examples/asr/librispeech_conformer_rnnt/eval.py', 'examples/asr/librispeech_conformer_rnnt/lightning.py', 'examples/asr/librispeech_conformer_rnnt/train.py', 'examples/asr/librispeech_conformer_rnnt/transforms.py']",False,11,7,2022
54eb0991fae635c6586f7f1d6bf6080128fbff11,"Put StreamReader source code into dedicated directory (#2531)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2531

Reviewed By: carolineechen

Differential Revision: D37698120

Pulled By: mthrok

fbshipit-source-id: d0fd6445d69758cd803a485cd17836d1936aa1ee",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/buffer.h', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/decoder.h', 'torchaudio/csrc/ffmpeg/stream_reader/sink.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/sink.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/stream_reader/typedefs.h']",False,8,7,2022
0859723699c2706ef6a4c649237e9cdb6d351418,"Rename AVContextPtr with AVContextInputPtr (#2530)

Summary:
Preparation to add save features with ffmpeg.

Pull Request resolved: https://github.com/pytorch/audio/pull/2530

Reviewed By: carolineechen

Differential Revision: D37698147

Pulled By: mthrok

fbshipit-source-id: feb5cbb6349a2b6b7faf44b629c574fdae47ecab",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.h']",False,7,7,2022
8b70c93edbf5f30a37351ab61525272480db122d,"Update CircleCI Xcode image (#2529)

Summary:
CircleCI is removing Xcode 12.4.0 image on August, and there was a planned
burnout on July 6th. [[detail](https://discuss.circleci.com/t/xcode-image-deprecation/44294?mkt_tok=NDg1LVpNSC02MjYAAAGFbbxbX7nSPCzN0MCKN078pw0VLJ-TMdICr8_gouRNYBM8C55RL8NDKLXA_9CQGPqnhJE5lsSFdetLRF-nH7iBLzoPGBfYpf2vuJ-XkW_C4__4)]

https://app.circleci.com/pipelines/github/pytorch/audio/11566/workflows/da167296-a84f-4dfe-b1b9-60d67e7a3d1c/jobs/771638

This commit updates Xcode image to 12.5

Pull Request resolved: https://github.com/pytorch/audio/pull/2529

Reviewed By: atalman

Differential Revision: D37688122

Pulled By: mthrok

fbshipit-source-id: 1095edbf0d920c4dc772555915bce93875b74671",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,7,7,2022
b2a90f9189505d3651fa882f993437fbabd3a63e,"Add YUV444P support to StreamReader (#2516)

Summary:
This commit add support for `""yuv444p""` type as output format of StreamReader.

Pull Request resolved: https://github.com/pytorch/audio/pull/2516

Reviewed By: hwangjeff

Differential Revision: D37659715

Pulled By: mthrok

fbshipit-source-id: eae9b5590d8f138a6ebf3808c08adfe068f11a2b",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/image_utils.py', 'test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/buffer.cpp']",False,7,7,2022
10ac6d2bbbd6d45731d2061d89d1c9053aa30d38,"Move helper functions out of common utility for better locality (#2512)

Summary:
This commits move helper functions/definitions around so that better locality of logics are achieved.

## Detail

`ffmpeg.[h|cpp]` implements classes that convert FFmpeg structures into RAII semantics.
Initially it these classes included the construction logic in their constructors, but such logics were
extracted to factory functions in https://github.com/pytorch/audio/issues/2373.

Now the reason why the factory functions stayed in `ffmpeg.[h|cpp]` was because the logic for
the initialization and  clean-up of AVDictionary class was only available in `ffmpeg.cpp`.

Now AVDictionary class handling is properly defined in https://github.com/pytorch/audio/issues/2507, the factory functions, which are not
that reusable better stay with the implementation that use them.

This makes `ffmpeg.h` lean and clean, makes it easier to see what can be reused.

Pull Request resolved: https://github.com/pytorch/audio/pull/2512

Reviewed By: hwangjeff

Differential Revision: D37477592

Pulled By: mthrok

fbshipit-source-id: 8c1b5059ea5f44649cc0eb1f82d1a92877ef186e",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/decoder.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.h']",False,7,7,2022
515fd01c9d9bdff341d97e25a3100efe6496bcc8,"Update lint config (#2389)

Summary:
Following the formatter changes heppened in fbcode, this commit update the linter config.

Pull Request resolved: https://github.com/pytorch/audio/pull/2389

Reviewed By: hwangjeff

Differential Revision: D37659649

Pulled By: mthrok

fbshipit-source-id: 1c52ff93f0b10cb2e7303d2ad13b2d65ffccfcb0",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.pre-commit-config.yaml', 'docs/source/hw_acceleration_tutorial.ipynb']",False,7,7,2022
09daa438f8a1a8135e7b9960a3ab141dde70f85b,"Fix fluent test for windows (#2510)

Summary:
fluent dataset test currently fails on windows, due to new line generation in csv writer in testing and incorrect path parsing in dataset impl.

Pull Request resolved: https://github.com/pytorch/audio/pull/2510

Reviewed By: carolineechen

Differential Revision: D37573203

Pulled By: mthrok

fbshipit-source-id: 4868bc649690c7e596b002686c6128ce735d3564",Caroline Chen,carolinechen@fb.com,"['test/torchaudio_unittest/datasets/fluentcommands_test.py', 'torchaudio/datasets/fluentcommands.py']",False,6,7,2022
ef8bd7b679f90ca699d04b335df01a9f67d912cc,"Fix build doc job (#2520)

Summary:
The build doc job is failing these days due to the fact that CUDA 11.6 requires different handling.

Pull Request resolved: https://github.com/pytorch/audio/pull/2520

Reviewed By: xiaohui-zhang

Differential Revision: D37527088

Pulled By: mthrok

fbshipit-source-id: 34c23bdbf70ba9fb8e315c7036cff01b3ddf4c91",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,29,6,2022
d3b4ce68ed3a5b01e294ecdcb6cc7a478ddf6a10,"Add 0.12.0 to version compatibility matrix (#2513)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2513

Reviewed By: mthrok

Differential Revision: D37491994

Pulled By: hwangjeff

fbshipit-source-id: 2c164bcec39342fd94abf4cc148d96dc9844699e",hwangjeff,iamjeffhwang@gmail.com,['README.md'],False,28,6,2022
0dd57236b63341b91e6915da2cf3a3beab752c22,"Refactor FilterGraph interface (#2508)

Summary:
FilterGraph is necessary for StreamWriter when saving video as
Tensor array format cannot express commonot video formats like yub420.

The current implementation of FilterGraph is specific to StreamReader,
as it takes AVCodecParameters object. Not individual parameters.

This PR refactor FilterGraph interface so that it can be constructed
from more primitive information.

Pull Request resolved: https://github.com/pytorch/audio/pull/2508

Reviewed By: hwangjeff

Differential Revision: D37466033

Pulled By: mthrok

fbshipit-source-id: 8414e985da7579c2dfe260b4dccd2afe113bb573",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/README.md', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/sink.cpp', 'torchaudio/csrc/ffmpeg/sink.h', 'torchaudio/csrc/ffmpeg/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_reader.h']",False,28,6,2022
0ad03adf4d005bacd67c8ec30e1c4a2b25c1a853,"Refactor AVDictionary clean up (#2507)

Summary:
Small clean up in ffmpeg binding code.

1. Make `get_option_dict` and `clean_up_dict` public utility
2. Merge the exception into `clean_up_dict`
3. Get rid of custom string join function and use `c10::Join`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2507

Reviewed By: hwangjeff

Differential Revision: D37466022

Pulled By: mthrok

fbshipit-source-id: 44b769ac6ff1ab20e6d6ae086cd1447deacb5969",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h']",True,28,6,2022
d50ed5219d00d4089621f1ca02de0e8986ce270b,"Add missing __init__ in io test directory (#2511)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2511

Reviewed By: nateanl

Differential Revision: D37461021

Pulled By: mthrok

fbshipit-source-id: 6f894c02bbefc5afda0f9584d26ad785f7c71ee4",moto,855818+mthrok@users.noreply.github.com,['test/torchaudio_unittest/io/__init__.py'],False,27,6,2022
9b4ee17cef6a190e04316c5298a012bf8c56c406,"Fix download links of RNNT pipelines in prototype (#2444)

Summary:
In https://github.com/pytorch/audio/issues/2283, torchaudio's downloading function is updated to reduce code duplication. The links in `EMFORMER_RNNT_BASE_LIBRISPEECH` are updated, but the ones in prototype pipelines are not. This PR addresses it by updating the download links of `EMFORMER_RNNT_BASE_MUSTC` and `EMFORMER_RNNT_BASE_TEDLIUM3` in prototype. Corresponding integration tests are added as well.

Pull Request resolved: https://github.com/pytorch/audio/pull/2444

Reviewed By: mthrok

Differential Revision: D37389178

Pulled By: nateanl

fbshipit-source-id: 46598dd71c95be47d1e1b54cef89ea51d280e17a",Zhaoheng Ni,zni@fb.com,"['test/integration_tests/rnnt_pipeline_test.py', 'torchaudio/prototype/pipelines/rnnt_pipeline.py']",False,27,6,2022
4ba7dc38c1d4ec3b680e409c8b56084dd8419a45,"Add utility function to fetch FFmpeg library versions (#2467)

Summary:
Follow-up of https://github.com/pytorch/audio/issues/2464. Add utility function to fetch the versions of FFmpeg.

Pull Request resolved: https://github.com/pytorch/audio/pull/2467

Reviewed By: carolineechen

Differential Revision: D37028006

Pulled By: mthrok

fbshipit-source-id: 72adce1e6b43985760ce55b715b0e59af5244fdb",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'test/torchaudio_unittest/utils/ffmpeg_utils_test.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/utils.cpp', 'torchaudio/utils/ffmpeg_utils.py']",False,27,6,2022
8ede3e1e9859227024ab31888a436b5a0196c999,"Fix for the cuda 11.6 and usage of cudatoolkit (#2501)

Summary:
Fix for the cuda 11.6 and usage of cudatoolkit

Pull Request resolved: https://github.com/pytorch/audio/pull/2501

Reviewed By: mthrok

Differential Revision: D37388598

Pulled By: atalman

fbshipit-source-id: 41add7ad6fbb3d156cc1270625dc085c62f7a531",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh', 'packaging/build_conda.sh', 'packaging/pkg_helpers.bash']",False,27,6,2022
21b2d1392c4ff998fed71d14d2cb5892afc445b8,"Add VoxCeleb1 dataset (#2349)

Summary:
This PR adds two dataset classes of VoxCeleb1 corpus.
- `VoxCeleb1Identification`
Each data sample contains the waveform, sample rate, speaker id, and the file id.
- `VoxCeleb1Verification`
Each data sample contains a pair of waveforms, sample rate, the label indicating if they are from the same speaker, and the file ids.

Pull Request resolved: https://github.com/pytorch/audio/pull/2349

Reviewed By: carolineechen

Differential Revision: D35927921

Pulled By: nateanl

fbshipit-source-id: 3e07ddd329178777698841565053eb59befe6449",Zhaoheng Ni,zni@fb.com,"['docs/source/datasets.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/datasets/voxceleb1_test.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/voxceleb1.py']",False,27,6,2022
49551eedb94c53d9590ead6c6cd2f80ae4a2f6d8,"Fix version number on main branch (#2509)

Summary:
The source build is still saying its 0.12.

Pull Request resolved: https://github.com/pytorch/audio/pull/2509

Reviewed By: carolineechen

Differential Revision: D37427703

Pulled By: mthrok

fbshipit-source-id: a6e455ba7c583af7b1a2a355ca45a9e5ab5fe30d",moto,855818+mthrok@users.noreply.github.com,['setup.py'],False,24,6,2022
b92a8a097dda2fc3305c1c26bb0a964794c90eb5,"Create musdb handler and tests (#2484)

Summary:
Create dataset handler and tests for new dataset. Manually tested and unit tested to test validity. Pre-commit ran for style checks.

Pull Request resolved: https://github.com/pytorch/audio/pull/2484

Reviewed By: carolineechen, nateanl

Differential Revision: D37250556

Pulled By: skim0514

fbshipit-source-id: d2c8d73d22fd9d7282026265676f3eab1e178d51",Sean Kim,skim0514@fb.com,"['docs/source/datasets.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/datasets/musdb_hq_test.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/musdb_hq.py']",False,21,6,2022
66a67d2efbab894196a733426b05f2b08da6fd79,"Add fluent speech commands (#2480)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2480

Reviewed By: nateanl

Differential Revision: D37249571

Pulled By: carolineechen

fbshipit-source-id: caefeec4253c91f2579655a0c1735edaeed51be9",Caroline Chen,carolinechen@fb.com,"['docs/source/datasets.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/datasets/fluentcommands_test.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/fluentcommands.py']",False,20,6,2022
10195316c4e5b97413cf97af97f275b48100316d,"Make lazy import for joblib (#2498)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2498

Reviewed By: mthrok

Differential Revision: D37224024

Pulled By: nateanl

fbshipit-source-id: 5d5d561c43d1ee323ae0cc599ffa1479208ea09a",Zhaoheng Ni,zni@fb.com,['examples/hubert/utils/kmeans.py'],True,17,6,2022
74dcfba3727c90fc18cff9965545c37bc94b1ae9,"Add special handling to filelike object mp3 (#2478)

Summary:
Loading and querying file-like object is not possible to use the fallback
mechanism introduced in https://github.com/pytorch/audio/issues/2419 because file-like objects are not seekable.

This commit add special case handling to mp3.

For filelike object mp3 input, it was required to pass `format=""mp3""`
because libsox did not auto detect the format.

With the transition of mp3 handling from libsox to ffmpeg, the logic
is to let the ffmpeg handle it without waiting for libsox to fail,
if the `format=""mp3""`

Note: This is back port of https://github.com/pytorch/audio/issues/2477.

Pull Request resolved: https://github.com/pytorch/audio/pull/2478

Reviewed By: carolineechen

Differential Revision: D37177123

Pulled By: mthrok

fbshipit-source-id: 997eead01c0ad1f04ffa0daa1039302a75f62b63",moto,855818+mthrok@users.noreply.github.com,['torchaudio/backend/sox_io_backend.py'],False,16,6,2022
5e966711994380f8f11a22401426aa43b768130b,"Making sure channel flag is set correctly (#2496)

Summary:
Making sure channel flag is set correctly for the test channel

Pull Request resolved: https://github.com/pytorch/audio/pull/2496

Reviewed By: hwangjeff, mthrok

Differential Revision: D37183083

Pulled By: atalman

fbshipit-source-id: 5df8aad1bceb22ad65b0942bf370480bb1cbd44a",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,15,6,2022
c46a00c2370abbb42cc5a42c0f98e498787ad9e5,"Fix typo in release build step (#2495)

Summary:
Fix typo in release build step

Pull Request resolved: https://github.com/pytorch/audio/pull/2495

Reviewed By: hwangjeff

Differential Revision: D37176695

Pulled By: atalman

fbshipit-source-id: 37b4e30c1084e506f3a45cf7427784c955868909",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,15,6,2022
6b152cb18b7329b556c3daa2e91fb9d04f43d5cf,"Fix push on release reference name (#2492)

Summary:
Fix push on release reference name
We want to compare it against refs/heads/release rather then release
Tests: https://github.com/atalman/vision/commit/af17cd95d2d43ca13354fb700e2da42108dd5a87
Sets correctly release chanell (wheels): https://github.com/atalman/vision/runs/6901327010?check_suite_focus=true

Pull Request resolved: https://github.com/pytorch/audio/pull/2492

Reviewed By: hwangjeff

Differential Revision: D37174090

Pulled By: atalman

fbshipit-source-id: e114972935572a701eb7daff429a0df0ed5a75e4",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,15,6,2022
722982eac30f6890d67ebb5d9a3c43585edfb604,"Making sure we are picking correct release branch (#2489)

Summary:
Making sure we are picking correct release branch
Ref: https://github.com/pytorch/vision/pull/6168

Pull Request resolved: https://github.com/pytorch/audio/pull/2489

Reviewed By: mthrok

Differential Revision: D37160145

Pulled By: atalman

fbshipit-source-id: 3e4a2208cbe47f85147573159f9adb8d6a824956",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,15,6,2022
575478ecf4a3c9f7b2593f6efc5e7c8c122b237b,"Update config.guess to the latest (#2479)

Summary:
closes https://github.com/pytorch/audio/issues/2420

Pull Request resolved: https://github.com/pytorch/audio/pull/2479

Reviewed By: carolineechen

Differential Revision: D37142717

Pulled By: mthrok

fbshipit-source-id: c3d4cc1435a74dfa6992112590c988c2903511a8",moto,855818+mthrok@users.noreply.github.com,['third_party/patches/config.guess'],False,15,6,2022
1e3cc6b2bdb0d3700e03d5f187b0bc0d07cb1b85,"Disable lint CI signal (#2487)

Summary:
Lint style has diverged since fb-internal lint engine has been changed.

Backport of https://github.com/pytorch/audio/issues/2466.

Pull Request resolved: https://github.com/pytorch/audio/pull/2487

Reviewed By: carolineechen

Differential Revision: D37160193

Pulled By: mthrok

fbshipit-source-id: cf4e2091a78a0da53269ae1251a55d4d1e52ead2",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,15,6,2022
be213bfbc40dca21c20bb32f2148ce28d7b34741,"Pin MKL to 2020.04 (#2486)

Summary:
The version of MKL that is installed alongside PyTorch has been bumped
to 2022.1 on Windows and it is causing installation issue in unit tests.

This commit pins the previous version

Backport of https://github.com/pytorch/audio/issues/2463

Pull Request resolved: https://github.com/pytorch/audio/pull/2486

Reviewed By: nateanl

Differential Revision: D37160156

Pulled By: mthrok

fbshipit-source-id: 7e3a30c25782b349a3cad2ee6d1141affc921881",moto,855818+mthrok@users.noreply.github.com,['.circleci/unittest/windows/scripts/install.sh'],False,15,6,2022
489999e2b8e055134ded0a2396c9be80455de23d,"Adding conda builds for M1 (#2473)

Summary:
Adding conda builds for M1

Pull Request resolved: https://github.com/pytorch/audio/pull/2473

Reviewed By: mthrok

Differential Revision: D37151454

Pulled By: atalman

fbshipit-source-id: 0108b937a4c7048bd4bb03b2b5a367704d7b78cc",Andrey Talman,atalman@fb.com,"['.github/workflows/build-m1-binaries.yml', 'packaging/pkg_helpers.bash']",False,14,6,2022
6fa5732c3c8101d038bee285921310c60c060b8d,"Add note about `normalize` argument (#2449)

Summary:
`load` function has `normalize` argument, which converts the native
sample type to `torch.float32`.

This argument is confusing for audio practitioners as it seems
to perform [volume normalization](https://en.wikipedia.org/wiki/Audio_normalization).

See https://github.com/pytorch/audio/issues/2253

Due to the BC-breaking concern, we cannot easily change the argument name.
This commit adds warnings to documentations.

Fix https://github.com/pytorch/audio/issues/2253

Pull Request resolved: https://github.com/pytorch/audio/pull/2449

Reviewed By: nateanl

Differential Revision: D36995756

Pulled By: carolineechen

fbshipit-source-id: 0b7db2758a355f6aafe06a2273bc72a1027690bd",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/backend/soundfile_backend.py', 'torchaudio/backend/sox_io_backend.py', 'torchaudio/sox_effects/sox_effects.py']",False,14,6,2022
a9c1e3a31dd7025e3e4dab9003f091424706d770,"Fix typo in nightly m1 ref (#2474)

Summary:
Fix typo in nightly m1 ref
See: https://github.com/pytorch/vision/pull/6158

Pull Request resolved: https://github.com/pytorch/audio/pull/2474

Reviewed By: malfet, mthrok

Differential Revision: D37117637

Pulled By: atalman

fbshipit-source-id: 2a8f7b5bf3506f2a53884424799919137870a0ad",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,13,6,2022
19d93282734230e8c16c7862745a841e1067a054,"Adding tagged builds to torchaudio (#2471)

Summary:
Adding tagged builds for torchaudio
see: https://github.com/pytorch/vision/pull/6140

Pull Request resolved: https://github.com/pytorch/audio/pull/2471

Reviewed By: hwangjeff

Differential Revision: D37080828

Pulled By: atalman

fbshipit-source-id: 13d754f522510514f0148ba465ce12a320058722",Andrey Talman,atalman@fb.com,"['.github/workflows/build-m1-binaries.yml', 'packaging/pkg_helpers.bash']",False,10,6,2022
df2262b53842c59a5a92db76a969cbfc0fb3046e,"Modifying Pitchshift for faster resampling (#2441)

Summary:
Split existing Pitchshift into multiple helper functions in order to cache kernel and speed up overall process addressing https://github.com/pytorch/audio/issues/2359.
Existing unit tests pass.

edit: functional and transforms unit test pass. Adopted lazy initialization to avoid BC-breaking.

Pull Request resolved: https://github.com/pytorch/audio/pull/2441

Reviewed By: carolineechen

Differential Revision: D36905582

Pulled By: skim0514

fbshipit-source-id: 6780db3ac8a29d59017a6abe7e82ce1fd17aaac2",Sean Kim,skim0514@fb.com,"['test/torchaudio_unittest/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/_transforms.py']",False,10,6,2022
4d2fa1908e531c6c815c026533b0e51a10ef9aef,"Fix metadata fetch (#2464)

Summary:
In https://github.com/pytorch/audio/issues/2461, `metadata` field was added to StreamInfo.
However, the value attached to this new field was source-level metadata,
while each stream can have different metadata.

* source level metadata
[AVFormatContext->metadata](https://ffmpeg.org/doxygen/4.1/structAVFormatContext.html#a3019a56080ed2e3297ff25bc2ff88adf)
* stream level metadata
[AVFormatContext->streams[]->metadata](https://ffmpeg.org/doxygen/4.1/structAVStream.html#a50d250a128a3da9ce3d135e84213fb82)

This commit moves source level metadata to dedicated method, `get_metadata`, and
fix the stream-level metadata to report stream metadata.

Pull Request resolved: https://github.com/pytorch/audio/pull/2464

Reviewed By: hwangjeff, xiaohui-zhang

Differential Revision: D36995452

Pulled By: mthrok

fbshipit-source-id: 534be1f7feb07790a0ce8624c336cdb7b65a8697",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader_binding.cpp', 'torchaudio/io/_stream_reader.py']",False,8,6,2022
711d60169fbca40803cb72d87b175afa80bf793d,"Update HW decoding tutorial and add notes about unseekable object (#2408)

Summary:
https://output.circle-artifacts.com/output/job/75187a52-b0d8-4cac-89f3-24e10889a36a/artifacts/0/docs/hw_acceleration_tutorial.html

1. Update HW decoding tutorial to include file-like object
1. Add note about unseekable object int streaming API tutorial

Pull Request resolved: https://github.com/pytorch/audio/pull/2408

Reviewed By: hwangjeff

Differential Revision: D36632702

Pulled By: mthrok

fbshipit-source-id: 17be2fb8528cb1d2d1ee11901b6a95c512466feb",moto,855818+mthrok@users.noreply.github.com,"['docs/source/hw_acceleration_tutorial.ipynb', 'examples/tutorials/streaming_api_tutorial.py']",False,8,6,2022
2d846263d626b349772bc53315ae7deac1ece844,"Split Streaming API tutorials into two (#2446)

Summary:
The Streaming API tutorial has gotten long, so this commit split it into two.

Pull Request resolved: https://github.com/pytorch/audio/pull/2446

Reviewed By: hwangjeff

Differential Revision: D36987513

Pulled By: mthrok

fbshipit-source-id: 13e3aad74c0d0e654c39c0eeceffca1a00b0dac4",moto,855818+mthrok@users.noreply.github.com,"['docs/source/index.rst', 'examples/tutorials/streaming_api2_tutorial.py', 'examples/tutorials/streaming_api_tutorial.py']",False,8,6,2022
10d1bd89e8adcf5210adcd4d25593f8588138816,"Add metadata to source stream info (#2461)

Summary:
Add metadata, such as ID3 (https://github.com/pytorch/audio/commit/7d98db0567cb60fabcc173949b8c08e3a3487ac2)tag to `StreamReaderSourceAudioStream`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2461

Reviewed By: hwangjeff

Differential Revision: D36985656

Pulled By: mthrok

fbshipit-source-id: e66f9e6e980eb57c378cc643a8979b6b7813dae7",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/typedefs.h', 'torchaudio/io/_compat.py', 'torchaudio/io/_stream_reader.py']",False,8,6,2022
7d98db0567cb60fabcc173949b8c08e3a3487ac2,"Bump version to 0.13 (#2460)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2460

Reviewed By: nateanl, mthrok

Differential Revision: D36992043

Pulled By: hwangjeff

fbshipit-source-id: 3a2a7f8991beaeaa2af0f620985230a68df201c2",hwangjeff,iamjeffhwang@gmail.com,['version.txt'],False,8,6,2022
a5a7849ae86caad70a788130b03a594daf4eea0b,"Quesst14 return type change (#2458)

Summary:
Fixing return types for quesst14

Pull Request resolved: https://github.com/pytorch/audio/pull/2458

Reviewed By: carolineechen

Differential Revision: D36977139

Pulled By: skim0514

fbshipit-source-id: f8f5a2de7cab2de1bec49c529c3bb9316145403d",Sean Kim,skim0514@fb.com,['torchaudio/datasets/quesst14.py'],False,7,6,2022
da3ffe9bf146c89585ed32aaf3be7f81bea2c4ab,"Remove CTC decoder prototype message (#2459)

Summary:
ctc decoder has been moved to beta, remove prototype message from tutorial

(this is done on the release branch in https://github.com/pytorch/audio/issues/2457)

Pull Request resolved: https://github.com/pytorch/audio/pull/2459

Reviewed By: hwangjeff

Differential Revision: D36978417

Pulled By: carolineechen

fbshipit-source-id: e580c1e8475a1a0aa924d44deea3852adc332a86",Caroline Chen,carolinechen@fb.com,['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py'],False,7,6,2022
ab5edfcd73fc06f9ecde839ef85dbc1778897249,"Add HuBERT fine-tuning recipe (#2352)

Summary:
The PR contains the CTC fine-tuning recipe of HuBERT Base model.
The files include:
- lightning module
- training script
- README and the result table
- evaluation scripts

Pull Request resolved: https://github.com/pytorch/audio/pull/2352

Reviewed By: hwangjeff

Differential Revision: D36915712

Pulled By: nateanl

fbshipit-source-id: 0249635ad5e81a8aa2d228c1d5fe84d78b62a15b",Zhaoheng Ni,zni@fb.com,"['examples/hubert/README.md', 'examples/hubert/dataset/__init__.py', 'examples/hubert/dataset/hubert_dataset.py', 'examples/hubert/evaluate.py', 'examples/hubert/finetune.py', 'examples/hubert/lightning.py', 'examples/hubert/train.py', 'examples/hubert/utils/__init__.py', 'examples/hubert/utils/common_utils.py']",False,7,6,2022
4c19e2cb3ef78ab3f6ae4052182c3aeed4817d08,"Update audio I/O tutorials (#2385)

Summary:
- Adopt `torchaudio.utils.download_asset` to simplify asset management.
- Break down the first section about helper functions.
- Use tempfile so that executing tutorial won't leave any artifacts on local file system.

Example: https://output.circle-artifacts.com/output/job/b11a0087-8bf9-4999-a74f-b53798eaa77f/artifacts/0/docs/tutorials/audio_io_tutorial.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2385

Reviewed By: hwangjeff

Differential Revision: D36404399

Pulled By: mthrok

fbshipit-source-id: 106af34e8ddd22a061aa12767b444b32aef07bad",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/audio_io_tutorial.py'],False,7,6,2022
550e6dcb109b2f84d6c8a188c907986d2b4837f6,"[DOC/CI] Store doc as tar archive (#2448)

Summary:
At the time of release, we need to download doc built by CI.
CircleCI does not have feature to download multiple files.

This commit add the archive of built documentations as
CI artifact so that the whole documentation can be downloaded
at once.

Resolves https://github.com/pytorch/audio/issues/2340

Pull Request resolved: https://github.com/pytorch/audio/pull/2448

Reviewed By: hwangjeff

Differential Revision: D36942077

Pulled By: mthrok

fbshipit-source-id: 61dde0d71841434a3d0624404d99911aa6956f88",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,7,6,2022
d2d8b67092d2c3cc2f6340f414c2833cbd81a53c,"Update smoke test (#2455)

Summary:
Import StreamReader from the new location

Pull Request resolved: https://github.com/pytorch/audio/pull/2455

Reviewed By: nateanl

Differential Revision: D36959668

Pulled By: mthrok

fbshipit-source-id: c2b8c9f9dff1ec306ea39c495294faa9208b3c4e",moto,855818+mthrok@users.noreply.github.com,['test/smoke_test/smoke_test.py'],False,7,6,2022
f11fc7cf4732ff2393b92793bdf53967defbc2c7,"Fix decoder compilation (#2450)

Summary:
Address https://github.com/pytorch/audio/issues/2445

Pull Request resolved: https://github.com/pytorch/audio/pull/2450

Reviewed By: carolineechen

Differential Revision: D36945877

Pulled By: mthrok

fbshipit-source-id: c7f9ba8093c8dc03b27582b9c608b023c7700332",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/decoder/src/decoder/Utils.h'],False,7,6,2022
4e761081c5215ff9924ab4faf329d22fd464178a,"Set the default ffmpeg log level to FATAL (#2447)

Summary:
With the default log-level, completely sane operation like converting
YUV to RGB issues bunch of warnings like

`[swscaler @ 0x128aa8000] No accelerated colorspace conversion found from yuv420p to rgb24.`

This commit sets the log level to FATAL.

Pull Request resolved: https://github.com/pytorch/audio/pull/2447

Reviewed By: hwangjeff

Differential Revision: D36938728

Pulled By: mthrok

fbshipit-source-id: 39c2e6a4307f1eac577fd606e17ab0f298079b54",moto,855818+mthrok@users.noreply.github.com,['torchaudio/_extension.py'],False,6,6,2022
a63629b6992c1486c9f8756ab1298fb8f09da429,"Refactor LibriSpeech Lightning datamodule to accommodate different dataset implementations (#2437)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2437

Refactors LibriSpeech Lightning datamodule to accommodate different dataset implementations.

Reviewed By: carolineechen, nateanl

Differential Revision: D36731577

fbshipit-source-id: 4ba91044311fa3f99a928aef6ef411316955f6b5",Jeff Hwang,jeffhwang@fb.com,['examples/asr/librispeech_conformer_rnnt/data_module.py'],False,4,6,2022
877a88c57e5f25cec3c9b3748bd0525fceec4908,"Make FFmpeg log level configurable (#2439)

Summary:
Undesired logs are one of the loudest UX complains we get.
Yet, loading media files involves uncertainty which is
difficult to debug without debug log.

This commit introduces utility functions to configure logging level
so that we can ask users to enable it when they encounter an issue,
while defaulting to non-verbose option.

Pull Request resolved: https://github.com/pytorch/audio/pull/2439

Reviewed By: hwangjeff, xiaohui-zhang

Differential Revision: D36903763

Pulled By: mthrok

fbshipit-source-id: f4ddd9915b13197c2a2eb97e965005b8b5b8d987",moto,855818+mthrok@users.noreply.github.com,"['docs/source/utils.rst', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/utils/ffmpeg_utils_test.py', 'torchaudio/csrc/ffmpeg/stream_reader_binding.cpp', 'torchaudio/utils/__init__.py', 'torchaudio/utils/ffmpeg_utils.py']",False,4,6,2022
3229fc55052147e7f59e2471cc0123f717cd9913,"Update CTC decoder docs (#2443)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2443

Reviewed By: nateanl

Differential Revision: D36909822

Pulled By: carolineechen

fbshipit-source-id: ef3ab2345e7a4666cf29dd02c83d03504e8aa62c",Caroline Chen,carolinechen@fb.com,['torchaudio/models/decoder/_ctc_decoder.py'],False,4,6,2022
41082eb0681f8ac0f8b6a00d154d9c258ec8e49a,"Update audio data augmentation tutorial (#2388)

Summary:
- Adopt `torchaudio.utils.download_asset` to simplify asset management.
- Break down the first section about helper functions.
- Reduce the number of helper functions

https://output.circle-artifacts.com/output/job/d7dd1b93-6dfe-46da-a080-109bfdc63881/artifacts/0/docs/tutorials/audio_data_augmentation_tutorial.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2388

Reviewed By: carolineechen

Differential Revision: D36404405

Pulled By: mthrok

fbshipit-source-id: f460ed810519797fce6e2fa7baaee110bddd1d06",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/audio_data_augmentation_tutorial.py'],False,3,6,2022
fd2be89aaa37fe2a859c9c5be2766fb905072e10,"Update audio resampling tutorial (#2386)

Summary:
- Replace mis-use of plot_specgram with plot_sweep, and remove plot_specgram
- Move `benchmark_resample` to later section

https://output.circle-artifacts.com/output/job/9f7af187-777d-4d75-840f-2630a36295b7/artifacts/0/docs/tutorials/audio_resampling_tutorial.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2386

Reviewed By: carolineechen

Differential Revision: D36404403

Pulled By: mthrok

fbshipit-source-id: f9df8453e3f531bdc4549b0134e5dbba90653bf7",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/audio_resampling_tutorial.py'],False,3,6,2022
8e20d546aa9d09e20a32083e13fc9d42201ed2bc,"Update audio feature extraction tutorial (#2391)

Summary:
- Adopt torchaudio.utils.download_asset to simplify asset management.
- Break down the first section about helper functions.
- Reduce the number of helper functions

Pull Request resolved: https://github.com/pytorch/audio/pull/2391

Reviewed By: carolineechen, nateanl

Differential Revision: D36885626

Pulled By: mthrok

fbshipit-source-id: 1306f22ab70ab1e7f74ed7e43bf43150015448b6",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/audio_feature_extractions_tutorial.py'],False,3,6,2022
f0bc00c980012badea8db011f84a0e9ef33ba6c1,"Remove possible manual seeds from test files. (#2436)

Summary:
For test files where applicable, removed manual seeds where applicable. Refactoring https://github.com/pytorch/audio/issues/2267

Pull Request resolved: https://github.com/pytorch/audio/pull/2436

Reviewed By: carolineechen

Differential Revision: D36896854

Pulled By: skim0514

fbshipit-source-id: 7b4dd8a8dbfbef271f5cc56564dc83a760407e6c",Sean Kim,skim0514@fb.com,"['test/torchaudio_unittest/example/emformer_rnnt/test_librispeech_lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_mustc_lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_tedlium3_lightning.py', 'test/torchaudio_unittest/example/hubert/test_crop_audio_label.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_cpu_test.py', 'test/torchaudio_unittest/functional/librosa_compatibility_test_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'test/torchaudio_unittest/models/conformer/conformer_test_impl.py', 'test/torchaudio_unittest/models/ctc_decoder_test.py', 'test/torchaudio_unittest/models/rnnt/rnnt_test_impl.py', 'test/torchaudio_unittest/models/rnnt_decoder/rnnt_decoder_test_impl.py', 'test/torchaudio_unittest/models/wav2vec2/fairseq_integration_test.py', 'test/torchaudio_unittest/models/wav2vec2/huggingface_intergration_test.py', 'test/torchaudio_unittest/models/wav2vec2/model_test.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py']",False,3,6,2022
b68864cacba3ff8437e48a60999c6b55c858f83d,"Refactor M1 logic and fix version (#2438)

Summary:
Refactor M1 logic
These improvement introduced in following PR: https://github.com/pytorch/vision/pull/6117

Pull Request resolved: https://github.com/pytorch/audio/pull/2438

Reviewed By: nateanl

Differential Revision: D36896028

Pulled By: atalman

fbshipit-source-id: 2ce360bfa78b2a7c77d5d4db800d487d171831a9",Andrey Talman,atalman@fb.com,"['.github/workflows/build-m1-binaries.yml', 'packaging/pkg_helpers.bash']",False,3,6,2022
c05498c85ef78f6d6c7c2d178616c4b79303c493,"Retrieve version from version.txt (#2434)

Summary:
Retrieve version from version.txt
These improvement introduced in following PR: https://github.com/pytorch/vision/pull/6117
In addition to this we add version.txt file to help us manage torchaudio version

Pull Request resolved: https://github.com/pytorch/audio/pull/2434

Reviewed By: mthrok

Differential Revision: D36867886

Pulled By: atalman

fbshipit-source-id: 14b6d653e46489d8db1c5ae2016a8202c632861e",Andrey Talman,atalman@fb.com,"['packaging/build_conda.sh', 'packaging/build_wheel.sh', 'packaging/pkg_helpers.bash', 'version.txt']",False,2,6,2022
ceee6912a5417a692b4fe231c542e82ceddbe421,"Update QUESST14 getitem (#2435)

Summary:
update QUESST14 getitem to include docstrings and additionally return sample rate

Pull Request resolved: https://github.com/pytorch/audio/pull/2435

Reviewed By: nateanl

Differential Revision: D36864254

Pulled By: carolineechen

fbshipit-source-id: 9e68bbc5de27ad2f32f6b298414103c4f6784801",Caroline Chen,carolinechen@fb.com,"['test/torchaudio_unittest/datasets/quesst14_test.py', 'torchaudio/datasets/quesst14.py']",False,2,6,2022
d2ecba98b396a8fcf3be50687522af1d66832b33,"Remove mad (#2428)

Summary:
Remove the code related to libmad, which had been disabled in https://github.com/pytorch/audio/issues/2354

In https://github.com/pytorch/audio/issues/2419, we mp3 decoding to ffmpeg. But CI tests were still using libmad.
This commit completely removes libmad from torchaudio.

This is BC-breaking change as `apply_sox_effects_file` function cannot handle MP3, and it cannot fallback to ffmpeg.
The workaround for this is to use `torchaudio.load` then `apply_sox_effects_tensor`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2428

Reviewed By: carolineechen

Differential Revision: D36851805

Pulled By: mthrok

fbshipit-source-id: f98795c59a1ac61cef511f2bbeac37f7c3c69d55",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'CMakeLists.txt', 'test/torchaudio_unittest/sox_effect/sox_effect_test.py', 'third_party/patches/libmad.patch', 'third_party/sox/CMakeLists.txt', 'tools/setup_helpers/extension.py', 'torchaudio/functional/functional.py']",False,2,6,2022
d01f58917120e0d3f811931403d8d193bf99b356,"Update MVDR beamforming tutorial (#2398)

Summary:
- Use `download_asset` to download audios.
- Replace `MVDR` module with new-added `SoudenMVDR` and `RTFMVDR` modules.
- Benchmark performances of `F.rtf_evd` and `F.rtf_power` for RTF computation.
- Visualize the spectrograms and masks.

Pull Request resolved: https://github.com/pytorch/audio/pull/2398

Reviewed By: carolineechen

Differential Revision: D36549402

Pulled By: nateanl

fbshipit-source-id: dfd6754e6c33246e6991ccc51c4603b12502a1b5",Zhaoheng Ni,zni@fb.com,['examples/tutorials/mvdr_tutorial.py'],False,2,6,2022
19c60a08a3ce51eaf74883a3952cb6fabad1ac0a,"Use FFmpeg-based I/O as fallback in sox_io backend (#2419)

Summary:
This commit add fallback mechanism to `info` and `load` functions of sox_io backend.
If torchaudio is compiled to use FFmpeg, and runtime dependencies are properly loaded,
in case `info` and `load` fail, it fallback to FFmpeg-based implementation.

BC-breaking changes:
 - FFmpeg does not report the number of frames for MP3, this is because MP3 does not store the information of the number of frames. It can be estimated from the audio duration and sample rate, but it might be inaccurate, so we keep it 0.

Depends on
- https://github.com/pytorch/audio/issues/2416
- https://github.com/pytorch/audio/issues/2417
- https://github.com/pytorch/audio/issues/2418
- https://github.com/pytorch/audio/issues/2423
- https://github.com/pytorch/audio/issues/2427

Pull Request resolved: https://github.com/pytorch/audio/pull/2419

Reviewed By: carolineechen

Differential Revision: D36740306

Pulled By: mthrok

fbshipit-source-id: 9e2ad095b8b39e41404970de0d8d9b5aaa856c97",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/backend/sox_io/info_test.py', 'test/torchaudio_unittest/backend/sox_io/load_test.py', 'test/torchaudio_unittest/backend/sox_io/save_test.py', 'test/torchaudio_unittest/backend/sox_io/smoke_test.py', 'torchaudio/backend/sox_io_backend.py', 'torchaudio/csrc/ffmpeg/stream_reader_binding.cpp', 'torchaudio/io/_compat.py', 'torchaudio/utils/__init__.py']",False,2,6,2022
a61b90c2db462db51fea85fa03315665e430510b,"Raising RuntimeErrors when datasets missing (#2430)

Summary:
Checks download flag and raises error when dataset is missing given download flag exists. Unit tested manually.

edit: Changed path to check as well as comment that is returned.

Pull Request resolved: https://github.com/pytorch/audio/pull/2430

Reviewed By: carolineechen

Differential Revision: D36815729

Pulled By: skim0514

fbshipit-source-id: f062db7919271665b88ec9754d85cfa83b4f6fa3",Sean Kim,skim0514@fb.com,"['torchaudio/datasets/cmuarctic.py', 'torchaudio/datasets/libritts.py', 'torchaudio/datasets/ljspeech.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/tedlium.py']",False,1,6,2022
6e563839a2157af45c81c67340cdad38f0c0a4f8,"Disable OpenMP on mac (#2431)

Summary:
A couple of weeks ago we started to see OpenMP not found error on macOS CI.
From https://github.com/pytorch/audio/issues/2404, we install OpenMP from brew, and build passes, but unit tests are seg-faulting ever since.

https://app.circleci.com/pipelines/github/pytorch/audio/10825/workflows/c0ecae99-d409-4df2-ab91-9bcb126c309d/jobs/671518

The failing test uses `torchaudio.functional.filitfilt`, which uses [OpenMP for parallel execution](https://github.com/pytorch/audio/blob/6057d3cf1c2f3a4c5072a3853a021bb8b4ce61f7/torchaudio/csrc/lfilter.cpp#L20).

This commit reverts https://github.com/pytorch/audio/issues/2404 and disables OpenMP for macOS builds and tests.

Pull Request resolved: https://github.com/pytorch/audio/pull/2431

Reviewed By: atalman

Differential Revision: D36819141

Pulled By: mthrok

fbshipit-source-id: 824300866a55f8b029d21649dc96cd80ae2ff697",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'packaging/torchaudio/meta.yaml']",False,1,6,2022
5d86054ace595bc56372a91525a90dc6161160dc,"Tweak StreamReader error messages and tests (#2429)

Summary:
* Update error messages
* Update audio stream tests

Pull Request resolved: https://github.com/pytorch/audio/pull/2429

Reviewed By: carolineechen, nateanl

Differential Revision: D36812769

Pulled By: mthrok

fbshipit-source-id: 7a51d0c4dbae558010d2e59412333e4a7f00d318",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/stream_reader.cpp']",False,1,6,2022
ac82bdc4722dc25e66a1a8fe85f6d7a8a134a363,"Move Seed to Setup (#2425)

Summary:
Bringing in move seed commit from previous open commit https://github.com/pytorch/audio/issues/2267. Organizes seed to utils.

Pull Request resolved: https://github.com/pytorch/audio/pull/2425

Reviewed By: carolineechen, nateanl

Differential Revision: D36787599

Pulled By: skim0514

fbshipit-source-id: 37a0d632d13d4336a830c4b98bdb04828ed88c20",Sean Kim,skim0514@fb.com,"['test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/models/wav2vec2/fairseq_integration_test.py', 'test/torchaudio_unittest/transforms/autograd_test_impl.py']",False,1,6,2022
94653bf4b9fad703fb134bf32eba97b8fc03580d,"Dataset doc fixes (#2426)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2426

Reviewed By: nateanl

Differential Revision: D36791423

Pulled By: carolineechen

fbshipit-source-id: e011147a716c940755032b8c68f5717d11fc91bf",Caroline Chen,carolinechen@fb.com,"['torchaudio/datasets/librilight_limited.py', 'torchaudio/datasets/librimix.py', 'torchaudio/datasets/quesst14.py']",False,1,6,2022
6057d3cf1c2f3a4c5072a3853a021bb8b4ce61f7,"Add conv_tasnet_base factory function to prototype (#2411)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2411

Reviewed By: carolineechen

Differential Revision: D36663904

Pulled By: nateanl

fbshipit-source-id: c6a7dd530c9cfbb58b7121ebe02db6ae293cc2d0",Zhaoheng Ni,zni@fb.com,"['docs/source/prototype.models.rst', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/conv_tasnet.py']",False,1,6,2022
93024ace026e6e0a30449a932fa30cfd49258251,"Move CTC beam search decoder to beta (#2410)

Summary:
Move CTC beam search decoder out of prototype to new `torchaudio.models.decoder` module.

hwangjeff mthrok any thoughts on the new module + naming, and if we should move rnnt beam search here as well??

Pull Request resolved: https://github.com/pytorch/audio/pull/2410

Reviewed By: mthrok

Differential Revision: D36784521

Pulled By: carolineechen

fbshipit-source-id: a2ec52f86bba66e03327a9af0c5df8bbefcd67ed",Caroline Chen,carolinechen@fb.com,"['docs/source/index.rst', 'docs/source/models.decoder.rst', 'docs/source/prototype.rst', 'examples/asr/librispeech_ctc_decoder/inference.py', 'examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'test/integration_tests/ctc_decoder_integration_test.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/models/ctc_decoder_test.py', 'torchaudio/models/decoder/__init__.py', 'torchaudio/models/decoder/_ctc_decoder.py', 'torchaudio/prototype/ctc_decoder/__init__.py']",False,1,6,2022
b374cc7b4e40373b505b8ed73908beec782254f5,"Move FileObj to dedicated source (#2427)

Summary:
Extract from https://github.com/pytorch/audio/issues/2419. Move the `FileObj` definition to dedicated file, so that it can be reused from files other than StreamReader.

Pull Request resolved: https://github.com/pytorch/audio/pull/2427

Reviewed By: carolineechen

Differential Revision: D36794367

Pulled By: mthrok

fbshipit-source-id: 999658f3f4d833566d933c9223e7a5d49d300574",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/pybind/typedefs.cpp', 'torchaudio/csrc/ffmpeg/pybind/typedefs.h']",False,1,6,2022
b56f60bf582bbacba4b1d9acea3c0cb1e9084819,"Fail on Python if sox_io info/load does not succeed (#2423)

Summary:
Extracted from https://github.com/pytorch/audio/issues/2419. Move the failure of sox_io from C++ to Python layer.

Pull Request resolved: https://github.com/pytorch/audio/pull/2423

Reviewed By: carolineechen

Differential Revision: D36766152

Pulled By: mthrok

fbshipit-source-id: 53f897a608e97b81ebe5df29577374d88ce178f3",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/backend/sox_io/info_test.py', 'test/torchaudio_unittest/backend/sox_io/load_test.py', 'torchaudio/backend/sox_io_backend.py', 'torchaudio/csrc/pybind/sox/effects.cpp', 'torchaudio/csrc/pybind/sox/io.cpp', 'torchaudio/csrc/sox/effects.cpp', 'torchaudio/csrc/sox/io.cpp', 'torchaudio/csrc/sox/utils.cpp', 'torchaudio/csrc/sox/utils.h', 'torchaudio/sox_effects/sox_effects.py']",False,31,5,2022
c209b70ddd3f477db6f173923b62a86362b22394,"Adding m1 builds to torchaudio (#2421)

Summary:
This PR adds M1 wheel builds for torchaudio
Based on this PR: https://github.com/pytorch/vision/pull/5948
And this Builder [script](https://github.com/pytorch/builder/blob/main/build_m1_domains.sh)

Pull Request resolved: https://github.com/pytorch/audio/pull/2421

Reviewed By: mthrok

Differential Revision: D36767469

Pulled By: atalman

fbshipit-source-id: 9fc3b74b50ee669a230302fd27682702f83f63dc",Andrey Talman,atalman@fb.com,['.github/workflows/build-m1-binaries.yml'],False,31,5,2022
22a5d08448c9756f6a2ba536db9dca9592b68727,"Pin test tool versions in CI (#2422)

Summary:
All the unittests jobs are failing due to import error due to protobuf and scipy.
This commit pins the versions of them to an older version.

## protobuf

https://app.circleci.com/pipelines/github/pytorch/audio/10979/workflows/42005226-ca7e-471c-80f4-db09f4bd2089/jobs/692078

```
E   TypeError: Descriptors cannot not be created directly.
E   If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
E   If you cannot immediately regenerate your protos, some other possible workarounds are:
E    1. Downgrade the protobuf package to 3.20.x or lower.
E    2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).
E
E   More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates
```

https://github.com/protocolbuffers/protobuf/issues/10051
https://github.com/PyTorchLightning/pytorch-lightning/issues/13159

## scipy (pypocketfft)

1.8.1 is causing issue.

https://app.circleci.com/pipelines/github/pytorch/audio/10980/workflows/470a9361-4cc5-4d7c-9264-28fc8b86f1cb/jobs/692267

    ```
    ../env/lib/python3.9/site-packages/librosa/core/audio.py:11: in <module>
        import scipy.signal
    ../env/lib/python3.9/site-packages/scipy/signal/__init__.py:309: in <module>
        from . import _sigtools, windows
    ../env/lib/python3.9/site-packages/scipy/signal/windows/__init__.py:41: in <module>
        from ._windows import *
    ../env/lib/python3.9/site-packages/scipy/signal/windows/_windows.py:7: in <module>
        from scipy import linalg, special, fft as sp_fft
    ../env/lib/python3.9/site-packages/scipy/fft/__init__.py:91: in <module>
        from ._helper import next_fast_len
    ../env/lib/python3.9/site-packages/scipy/fft/_helper.py:3: in <module>
        from ._pocketfft import helper as _helper
    ../env/lib/python3.9/site-packages/scipy/fft/_pocketfft/__init__.py:3: in <module>
        from .basic import *
    ../env/lib/python3.9/site-packages/scipy/fft/_pocketfft/basic.py:6: in <module>
        from . import pypocketfft as pfft
    E   ImportError: /home/circleci/project/env/lib/python3.9/site-packages/torch/lib/../../../.././libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /home/circleci/project/env/lib/python3.9/site-packages/scipy/fft/_pocketfft/pypocketfft.cpython-39-x86_64-linux-gnu.so)

Pull Request resolved: https://github.com/pytorch/audio/pull/2422

Reviewed By: atalman

Differential Revision: D36764198

Pulled By: mthrok

fbshipit-source-id: 897a79fe9c3165206c2e747147fd0f257fc4f683",moto,855818+mthrok@users.noreply.github.com,"['.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/windows/scripts/install.sh']",False,30,5,2022
bb77cbebb620a46fdc0dc7e6dae2253eef3f37e2,"Update source info (#2418)

Summary:
Add num_frames and bits_per_sample to match with the current
`torchaudio.info` capability.

Pull Request resolved: https://github.com/pytorch/audio/pull/2418

Reviewed By: carolineechen

Differential Revision: D36749077

Pulled By: mthrok

fbshipit-source-id: 7b368ee993cf5ed63ff2f53c9e3b1f50fcce7713",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/ffmpeg/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/typedefs.h', 'torchaudio/io/_stream_reader.py']",False,29,5,2022
fd7ace17938c74d0928987b9525dbe7799b328fa,"Change sox_io C++ return type to optional (#2416)

Summary:
Preparation for upcoming change where load/info function will use fallback
if sox_io backend cannot handle the input.

Pull Request resolved: https://github.com/pytorch/audio/pull/2416

Reviewed By: carolineechen

Differential Revision: D36736969

Pulled By: mthrok

fbshipit-source-id: f804cfda3678f13bf0c2f6557a2f82ae42ae3c03",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/backend/sox_io_backend.py', 'torchaudio/csrc/pybind/sox/effects.cpp', 'torchaudio/csrc/pybind/sox/effects.h', 'torchaudio/csrc/pybind/sox/io.cpp', 'torchaudio/csrc/pybind/sox/io.h', 'torchaudio/csrc/sox/effects.cpp', 'torchaudio/csrc/sox/effects.h', 'torchaudio/csrc/sox/io.cpp', 'torchaudio/csrc/sox/io.h', 'torchaudio/sox_effects/sox_effects.py']",False,29,5,2022
65ab62e6b73a941d09d8b45b23b389a6fae46f5a,"Update I/O initialization (#2417)

Summary:
Attempt to load ffmpeg extension at the top level import

Preparation to use ffmpeg-based I/O as a fallback for sox_io backend.

Pull Request resolved: https://github.com/pytorch/audio/pull/2417

Reviewed By: carolineechen

Differential Revision: D36736989

Pulled By: mthrok

fbshipit-source-id: 0beb6f459313b5ea91597393ccb12571444c54d9",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/_extension.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/utils.cpp', 'torchaudio/io/__init__.py']",False,28,5,2022
9ef6c23deb3eff22e7bcd6c8833f1a03384e34a8,"Refactor Streamer to StreamReader in C++ codebase (#2403)

Summary:
* `Streamer` has been renamed to `StreamReader` when it was moved from prototype to beta.
This commit applies the same name change to the C++ source code.

* Fix miscellaneous lint issues

* Make the code compilable on FFmpeg 5

Pull Request resolved: https://github.com/pytorch/audio/pull/2403

Reviewed By: carolineechen

Differential Revision: D36613053

Pulled By: mthrok

fbshipit-source-id: 69fedd6720d488dadf4dfe7d375ee76d216b215d",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/README.md', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/stream_reader.h', 'torchaudio/csrc/ffmpeg/stream_reader_binding.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/typedefs.h', 'torchaudio/io/_stream_reader.py']",False,27,5,2022
752de3e47a7e71c2ac8672b8eee2b24c4e158ed0,change Adam to AdamW (#2412),nateanl,zni@fb.com,['examples/hubert/lightning.py'],False,26,5,2022
39c2c0a77e11b82ce152d60df3a92f6854d5f52b,"Fix documentation (#2409)

Summary:
Follow-up of https://github.com/pytorch/audio/issues/2407, the <script> was not properly closed on pages other than tutorials

Pull Request resolved: https://github.com/pytorch/audio/pull/2409

Reviewed By: carolineechen

Differential Revision: D36632668

Pulled By: mthrok

fbshipit-source-id: 9c0409a8011d77f8689e2dcdc1bd9844d3d31f79",moto,855818+mthrok@users.noreply.github.com,['docs/source/_templates/layout.html'],True,24,5,2022
474510f2515a67412c20f023060b764cc7d20b43,"Fix documentation (#2407)

Summary:
This commit fixes multiple issues with documentation.

https://output.circle-artifacts.com/output/job/23245537-e57b-4b9d-9b81-b3df20996d1f/artifacts/0/docs/tutorials/audio_resampling_tutorial.html

1. Duplicated requirejs
The nbsphinx extension introduced in https://github.com/pytorch/audio/pull/2393 pulled a requirejs
which caused the initialization script to halt.
As a result, the right side bar was left uninitialized.

2. Undefined variable error
It turned out that PyTorch's theme expected the downstream projects
to define `collapsedSections` variable.
Currently console log shows `collapsedSections is not defined`.
As a result of this fix, we start to see the + symbol on left side.

3. Fix the behavior of default expand
Tweaks the right-side bar initialization behavior
so that expand-all only happens once, not at every resize.

4. Overwrite the link to GitHub
The `GitHub` tab in main-menu always linked PyTorch core.
This commit adds overwrite to torchaudio page

Pull Request resolved: https://github.com/pytorch/audio/pull/2407

Reviewed By: carolineechen

Differential Revision: D36612904

Pulled By: mthrok

fbshipit-source-id: 56aa7623a8925a241cf4790ac77a87424ad9237c",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/layout.html', 'docs/source/conf.py']",False,24,5,2022
38e530d77e5a194d4e5f91356cc1a191207a3b29,"Add assertion checks to multi-channel functions (#2401)

Summary:
- The multi-channel functions only support complex-valued tensors for spectrogram and PSD matrices.
- The mask can be real-valued or complex-valued, hence there is no explicit assertion for mask.
- The shape of input Tensors need to be verified before the computation. For example, the shape of PSD matrix must be `(..., freq, channel, channel)`, the shape of the mask must be `(..., freq, time)`, etc.
- The autograd unittest of `apply_beamforming` has wrong dimensions for beamform_weights detected by the assertion check. FIx it in this PR.

Pull Request resolved: https://github.com/pytorch/audio/pull/2401

Reviewed By: carolineechen

Differential Revision: D36597689

Pulled By: nateanl

fbshipit-source-id: 6ad1adebe3726851cc1d865650bdf177a98985f6",Zhaoheng Ni,zni@fb.com,"['test/torchaudio_unittest/functional/autograd_impl.py', 'torchaudio/functional/functional.py']",True,23,5,2022
af9cab3b6c02a8e8fbbb2551199f77bccfc0e8f3,"Add LibriLightLimited dataset (#2302)

Summary:
The `LibriLightLimited` dataset is created for fine-tuning SSL models, such as Wav2Vec2 and HuBERT. It is a supervised subset of [Libri-Light](https://github.com/facebookresearch/libri-light) dataset. To distinguish the unsupervised subset and the supervised one, it's clearer to put it in a separate dataset class for fine-tuning purpose.
It contains ""10 min"", ""1 hour"", ""10 hour"" splits.

Pull Request resolved: https://github.com/pytorch/audio/pull/2302

Reviewed By: mthrok

Differential Revision: D36388188

Pulled By: nateanl

fbshipit-source-id: ba49f1c9996be17db5db41127d8ca96224c94249",Zhaoheng Ni,zni@fb.com,"['docs/source/datasets.rst', 'test/torchaudio_unittest/datasets/librilightlimited_test.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/librilight_limited.py']",False,23,5,2022
48a0c17a3d233dd835d8cdd9508f6f4e3d03dcc6,"Add recipe for HuBERT model pre-training (#2198)

Summary:
Replace https://github.com/pytorch/audio/issues/2129

Pull Request resolved: https://github.com/pytorch/audio/pull/2198

Reviewed By: carolineechen

Differential Revision: D36544163

Pulled By: nateanl

fbshipit-source-id: 3f19ba5b0f2c2b9e93b0603c3b4491c1dbc40ef8",Zhaoheng Ni,zni@fb.com,"['examples/hubert/README.md', 'examples/hubert/lightning.py', 'examples/hubert/loss/__init__.py', 'examples/hubert/loss/hubert_loss.py', 'examples/hubert/train.py']",False,23,5,2022
a984872dfee71a553eb90c7eb13c9a5609d041c0,"Add file-like object support to Streaming API (#2400)

Summary:
This commit adds file-like object support to Streaming API.

## Features
- File-like objects are expected to implement `read(self, n)`.
- Additionally `seek(self, offset, whence)` is used if available.
- Without `seek` method, some formats cannot be decoded properly.
  - To work around this, one can use the existing `decoder` option to tell what decoder it should use.
  - The set of `decoder` and `decoder_option` arguments were added to `add_basic_[audio|video]_stream` method, similar to `add_[audio|video]_stream`.
  - So as to have the arguments common to both audio and video in front of the rest of the arguments, the order of the arguments are changed.
  - Also `dtype` and `format` arguments were changed to make them consistent across audio/video methods.

## Code structure

The approach is very similar to how file-like object is supported in sox-based I/O.
In Streaming API if the input src is string, it is passed to the implementation bound with TorchBind,
if the src has `read` attribute, it is passed to the same implementation bound via PyBind 11.

![Untitled drawing](https://user-images.githubusercontent.com/855818/169098391-6116afee-7b29-460d-b50d-1037bb8a359d.png)

## Refactoring involved
- Extracted to https://github.com/pytorch/audio/issues/2402
  - Some implementation in the original TorchBind surface layer is converted to Wrapper class so that they can be re-used from PyBind11 bindings. The wrapper class serves to simplify the binding.
  - `add_basic_[audio|video]_stream` methods were removed from C++ layer as it was just constructing string and passing it to `add_[audio|video]_stream` method, which is simpler to do in Python.
  - The original core Streamer implementation kept the use of types in `c10` namespace minimum. All the `c10::optional` and `c10::Dict` were converted to the equivalents of `std` at binding layer. But since they work fine with PyBind11, Streamer core methods deal them directly.

## TODO:
- [x] Check if it is possible to stream MP4 (yuv420p) from S3 and directly decode (with/without HW decoding).

Pull Request resolved: https://github.com/pytorch/audio/pull/2400

Reviewed By: carolineechen

Differential Revision: D36520073

Pulled By: mthrok

fbshipit-source-id: a11d981bbe99b1ff0cc356e46264ac8e76614bc6",moto,855818+mthrok@users.noreply.github.com,"['examples/tutorials/streaming_api_tutorial.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/io/stream_reader_test.py', 'tools/setup_helpers/extension.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/prototype.cpp', 'torchaudio/csrc/ffmpeg/pybind/pybind.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.cpp', 'torchaudio/csrc/ffmpeg/pybind/stream_reader.h', 'torchaudio/csrc/ffmpeg/streamer.cpp', 'torchaudio/io/__init__.py', 'torchaudio/io/_stream_reader.py']",False,21,5,2022
6776299322ae0c8108b34af947e6e62ccd61b5ca,"Tweak build doc job to avoid timeout (#2399)

Summary:
After https://github.com/pytorch/audio/issues/2395, build_doc job is exceeding default no-output-timeout
threshould (10m).

This commit updates the timeout threshold to 30m.
Also it moves the installation of tools to the previous step.

Pull Request resolved: https://github.com/pytorch/audio/pull/2399

Reviewed By: carolineechen

Differential Revision: D36539022

Pulled By: mthrok

fbshipit-source-id: 391764a0fb5bf87cfb2beaab401a90dcb56493e5",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,20,5,2022
010583b65cc614d85a72dcdb9cd70c8db45ade9c,"Refactor LibriSpeech tests to accommodate different dataset classes (#2392)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2392

Refactors LibriSpeech tests to accommodate different dataset classes

Reviewed By: xiaohui-zhang

Differential Revision: D36387835

fbshipit-source-id: 73b4e7565b4a077b25f036f4bd854ac7f2194b28",Jeff Hwang,jeffhwang@fb.com,"['test/torchaudio_unittest/datasets/librispeech_test.py', 'test/torchaudio_unittest/datasets/librispeech_test_impl.py']",False,20,5,2022
07ace387617e444314ab5936aabfc11538adf8fe,"Add tutorial to use NVDEC with Stream API (#2393)

Summary:
This commit adds tutorial to enable/use NVDEC with Stream API.

https://output.circle-artifacts.com/output/job/19e66a4b-1819-4804-8834-d38e6c80c4fd/artifacts/0/docs/hw_acceleration_tutorial.html

Because the use of NVDEC requires build / install FFmpeg from source,
this tutorial was authored on Google Colab, tailored to its environment.

The tutorial here is the result of the notebook execution, with
the link to the publicly accessible Google Colab notebook.

Pull Request resolved: https://github.com/pytorch/audio/pull/2393

Reviewed By: hwangjeff

Differential Revision: D36404408

Pulled By: mthrok

fbshipit-source-id: 9c820d3db4d06c5b343ecad0708489125ca06948",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'docs/requirements-tutorials.txt', 'docs/source/conf.py', 'docs/source/hw_acceleration_tutorial.ipynb', 'docs/source/index.rst']",False,20,5,2022
38cf5b7aecc9cd1ac020b4b0008dad8fa546c19c,"ci: Install libomp on macos (#2404)

Summary:
To resolve nightly / general build issues relating to OpenMP not being found, see https://hud.pytorch.org/pytorch/audio/commit/c6a376cc5679c1940e49fc3e0ba22eaead6c2467

```
-- Found Torch: /Users/distiller/miniconda3/envs/env3.10/lib/python3.10/site-packages/torch/lib/libtorch.dylib
CMake Error at /Users/distiller/miniconda3/envs/env3.10/lib/python3.10/site-packages/cmake/data/CMake.app/Contents/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:230 (message):
  Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)
Call Stack (most recent call first):
  /Users/distiller/miniconda3/envs/env3.10/lib/python3.10/site-packages/cmake/data/CMake.app/Contents/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake:594 (_FPHSA_FAILURE_MESSAGE)
  /Users/distiller/miniconda3/envs/env3.10/lib/python3.10/site-packages/cmake/data/CMake.app/Contents/share/cmake-3.22/Modules/FindOpenMP.cmake:544 (find_package_handle_standard_args)
  CMakeLists.txt:131 (find_package)

-- Configuring incomplete, errors occurred!
```

Signed-off-by: Eli Uriegas <eliuriegas@fb.com>

Pull Request resolved: https://github.com/pytorch/audio/pull/2404

Reviewed By: atalman

Differential Revision: D36495791

Pulled By: seemethere

fbshipit-source-id: 7b6fa2a62fda6fc468cfcbdf8d2163e6b9c327b0",Eli Uriegas,eliuriegas@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,19,5,2022
eed57534af5edb3ba6f8fd04ec3f372f763f62a0,"Refactor Streamer implementation (#2402)

Summary:
* Move the helper wrapping code in TorchBind layer to proper wrapper class for so that it will be re-used in PyBind11.
* Move `add_basic_[audio|video]_stream` methods from C++ to Python, as they are just string manipulation. This will make PyBind11-based binding simpler as it needs not to deal with dtype.
* Move `add_[audio|video]_stream` wrapper signature to Streamer core, so that Streamer directly deals with `c10::optional`.†

† Related to this, there is a slight change in how the empty filter expression is stored. Originally, if an empty filter expression was given to `add_[audio|video]_stream` method, the `StreamReaderOutputStream` was showing it as empty string `""""`, even though internally it was using `""anull""` or `""null""`. Now `StreamReaderOutputStream` shows the corresponding filter expression that is actually being used.

Ref https://github.com/pytorch/audio/issues/2400

Pull Request resolved: https://github.com/pytorch/audio/pull/2402

Reviewed By: nateanl

Differential Revision: D36488808

Pulled By: mthrok

fbshipit-source-id: 877ca731364d10fc0cb9d97e75d55df9180f2047",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/io/stream_reader_test.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/ffmpeg/decoder.cpp', 'torchaudio/csrc/ffmpeg/decoder.h', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/prototype.cpp', 'torchaudio/csrc/ffmpeg/sink.cpp', 'torchaudio/csrc/ffmpeg/sink.h', 'torchaudio/csrc/ffmpeg/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_processor.h', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.cpp', 'torchaudio/csrc/ffmpeg/stream_reader_wrapper.h', 'torchaudio/csrc/ffmpeg/streamer.cpp', 'torchaudio/csrc/ffmpeg/streamer.h', 'torchaudio/io/_stream_reader.py']",False,19,5,2022
647f28e4ddd5fb6f28f8cffd9083a2ccdc1722c8,"Add feature_grad_mult argument to HuBERTPretrainModel (#2335)

Summary:
In Wav2Vec2 and HuBERT model training, the convolutional feature extraction layers use `group_norm` for normalization in `Base` model, while they use `layer_norm` in `Large` and `XLarge` models. For `Base` model, the gradients of feature extraction layers will be unstable in pre-training, thus we need to scale down the gradient by multiplying 0.1.

In this PR, we add such argument to `HuBERTPretrainModel` to control the gradient of feature extractor layers. We also put the argument in the factory functions (`hubert_pretrain_base`, `hubert_pretrain_large`, and `hubert_pretrain_xlarge`. The reason is in finetuning, the feature extractor's parameters are fixed, we can multiply the gradient with 0.0 to avoid back propagating gradients.

Pull Request resolved: https://github.com/pytorch/audio/pull/2335

Reviewed By: xiaohui-zhang, mthrok

Differential Revision: D35646928

Pulled By: nateanl

fbshipit-source-id: 6a9563e227aac6e3127b634357946d860f26c994",Zhaoheng Ni,zni@fb.com,"['torchaudio/models/wav2vec2/components.py', 'torchaudio/models/wav2vec2/model.py']",False,18,5,2022
c6a376cc5679c1940e49fc3e0ba22eaead6c2467,"Expand subsections in tutorials by default (#2397)

Summary:
This commit updates the `window.sideMenus.handleRightMenu`, so that
subsections are expanded on tutorials by default.

https://output.circle-artifacts.com/output/job/98508917-87df-4666-9958-c70683b3245d/artifacts/0/docs/tutorials/audio_io_tutorial.html

Tutorial subsections are important because they have anchors so
allow us to get the link to the specific figures / audio samples.

When responding issues/questions and when there is a corresponding
code snippet in tutorial, it is often easy to answer with links to
the tutorial.

However, by default the tutorial page collapses right side bar, and
I have to click the small ""+"" symbols to navigate to the subsection,
and the state of expansion does not persist across the page refresh.

This has been a pain point since we updated the Sphinx version to 3
in https://github.com/pytorch/audio/pull/1685.

Pull Request resolved: https://github.com/pytorch/audio/pull/2397

Reviewed By: xiaohui-zhang

Differential Revision: D36429745

Pulled By: mthrok

fbshipit-source-id: 97a5ae9270e68f8e88f0bca766d5a2c1839634e3",moto,855818+mthrok@users.noreply.github.com,['docs/source/_templates/layout.html'],False,17,5,2022
8fd60cc89fb0973c10b1c37ef77f0f22ddd47bd0,"Update build_doc job to use Conda CUDA package (#2395)

Summary:
This commit moves `build_doc` job to run on top of Conda binary
build job.

The motivation is that Conda provides easy access to third party
tools that are required to build complex documentation.

Specifically in https://github.com/pytorch/audio/pull/2393,
ipynb-style tutorial is being added, which requires `nbsphinx`.

`nbsphinx` requires `pandoc` package and there was some issue
with the version from PyPI. A workaround is to use the one from
Conda package.

Pull Request resolved: https://github.com/pytorch/audio/pull/2395

Reviewed By: carolineechen, nateanl

Differential Revision: D36404407

Pulled By: mthrok

fbshipit-source-id: 26ec5ebfd5be795384306a9f24817a2eb3ec96c1",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py']",False,16,5,2022
d62875cc67f0ecae75c6edeffa1c74178308e034,"[codemod][usort] apply import merging for fbcode (8 of 11)

Summary:
Applies new import merging and sorting from µsort v1.0.

When merging imports, µsort will make a best-effort to move associated
comments to match merged elements, but there are known limitations due to
the diynamic nature of Python and developer tooling. These changes should
not produce any dangerous runtime changes, but may require touch-ups to
satisfy linters and other tooling.

Note that µsort uses case-insensitive, lexicographical sorting, which
results in a different ordering compared to isort. This provides a more
consistent sorting order, matching the case-insensitive order used when
sorting import statements by module name, and ensures that ""frog"", ""FROG"",
and ""Frog"" always sort next to each other.

For details on µsort's sorting and merging semantics, see the user guide:
https://usort.readthedocs.io/en/stable/guide.html#sorting

Reviewed By: lisroach

Differential Revision: D36402214

fbshipit-source-id: b641bfa9d46242188524d4ae2c44998922a62b4c",John Reese,jreese@fb.com,"['examples/asr/emformer_rnnt/eval.py', 'examples/asr/emformer_rnnt/global_stats.py', 'examples/asr/emformer_rnnt/librispeech/lightning.py', 'examples/asr/emformer_rnnt/mustc/lightning.py', 'examples/asr/emformer_rnnt/pipeline_demo.py', 'examples/asr/emformer_rnnt/tedlium3/lightning.py', 'examples/asr/emformer_rnnt/train.py', 'examples/asr/librispeech_conformer_rnnt/lightning.py', 'examples/asr/librispeech_conformer_rnnt/train.py', 'examples/asr/librispeech_ctc_decoder/inference.py', 'examples/hubert/dataset/__init__.py', 'examples/hubert/preprocess.py', 'examples/hubert/utils/__init__.py', 'examples/hubert/utils/common_utils.py', 'examples/hubert/utils/feature_utils.py', 'examples/hubert/utils/kmeans.py', 'examples/interactive_asr/asr.py', 'examples/interactive_asr/utils.py', 'examples/pipeline_tacotron2/datasets.py', 'examples/pipeline_tacotron2/inference.py', 'examples/pipeline_tacotron2/text/text_preprocessing.py', 'examples/pipeline_tacotron2/train.py', 'examples/pipeline_tacotron2/utils.py', 'examples/pipeline_wav2letter/main.py', 'examples/pipeline_wavernn/datasets.py', 'examples/pipeline_wavernn/main.py', 'examples/source_separation/eval.py', 'examples/source_separation/lightning_train.py', 'examples/source_separation/utils/__init__.py', 'examples/source_separation/utils/dataset/wsj0mix.py', 'setup.py', 'test/integration_tests/wav2vec2_pipeline_test.py', 'test/torchaudio_unittest/backend/soundfile/info_test.py', 'test/torchaudio_unittest/backend/soundfile/load_test.py', 'test/torchaudio_unittest/backend/soundfile/save_test.py', 'test/torchaudio_unittest/backend/sox_io/info_test.py', 'test/torchaudio_unittest/backend/sox_io/load_test.py', 'test/torchaudio_unittest/backend/sox_io/roundtrip_test.py', 'test/torchaudio_unittest/backend/sox_io/save_test.py', 'test/torchaudio_unittest/backend/sox_io/smoke_test.py', 'test/torchaudio_unittest/backend/sox_io/torchscript_test.py', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/common_utils/data_utils.py', 'test/torchaudio_unittest/compliance/kaldi/kaldi_compatibility_impl.py', 'test/torchaudio_unittest/datasets/cmuarctic_test.py', 'test/torchaudio_unittest/datasets/cmudict_test.py', 'test/torchaudio_unittest/datasets/commonvoice_test.py', 'test/torchaudio_unittest/datasets/dr_vctk_test.py', 'test/torchaudio_unittest/datasets/gtzan_test.py', 'test/torchaudio_unittest/datasets/librispeech_test.py', 'test/torchaudio_unittest/datasets/libritts_test.py', 'test/torchaudio_unittest/datasets/ljspeech_test.py', 'test/torchaudio_unittest/datasets/quesst14_test.py', 'test/torchaudio_unittest/datasets/speechcommands_test.py', 'test/torchaudio_unittest/datasets/tedlium_test.py', 'test/torchaudio_unittest/datasets/vctk_test.py', 'test/torchaudio_unittest/datasets/yesno_test.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_librispeech_lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_mustc_lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_tedlium3_lightning.py', 'test/torchaudio_unittest/example/souce_sepration/wsj0mix_test.py', 'test/torchaudio_unittest/example/tacotron2/tacotron2_loss_cpu_test.py', 'test/torchaudio_unittest/example/tacotron2/tacotron2_loss_gpu_test.py', 'test/torchaudio_unittest/example/tacotron2/tacotron2_loss_impl.py', 'test/torchaudio_unittest/example/tacotron2/test_text_preprocessing.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/functional_cpu_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/kaldi_compatibility_test_impl.py', 'test/torchaudio_unittest/functional/librosa_compatibility_test_impl.py', 'test/torchaudio_unittest/functional/sox_compatibility_test.py', 'test/torchaudio_unittest/functional/torchscript_consistency_cuda_test.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'test/torchaudio_unittest/io/stream_reader_test.py', 'test/torchaudio_unittest/models/conformer/conformer_gpu_test.py', 'test/torchaudio_unittest/models/emformer/emformer_gpu_test.py', 'test/torchaudio_unittest/models/rnnt/rnnt_gpu_test.py', 'test/torchaudio_unittest/models/rnnt_decoder/rnnt_decoder_cpu_test.py', 'test/torchaudio_unittest/models/rnnt_decoder/rnnt_decoder_gpu_test.py', 'test/torchaudio_unittest/models/rnnt_decoder/rnnt_decoder_test_impl.py', 'test/torchaudio_unittest/models/tacotron2/model_test_cpu_test.py', 'test/torchaudio_unittest/models/tacotron2/model_test_gpu_test.py', 'test/torchaudio_unittest/models/tacotron2/model_test_impl.py', 'test/torchaudio_unittest/models/wav2vec2/fairseq_integration_test.py', 'test/torchaudio_unittest/models/wav2vec2/huggingface_intergration_test.py', 'test/torchaudio_unittest/models/wav2vec2/model_test.py', 'test/torchaudio_unittest/prototype/conv_emformer_gpu_test.py', 'test/torchaudio_unittest/prototype/ctc_decoder_test.py', 'test/torchaudio_unittest/prototype/rnnt_gpu_test.py', 'test/torchaudio_unittest/sox_effect/dataset_test.py', 'test/torchaudio_unittest/sox_effect/smoke_test.py', 'test/torchaudio_unittest/sox_effect/sox_effect_test.py', 'test/torchaudio_unittest/sox_effect/torchscript_test.py', 'test/torchaudio_unittest/transforms/autograd_cpu_test.py', 'test/torchaudio_unittest/transforms/autograd_cuda_test.py', 'test/torchaudio_unittest/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/transforms/librosa_compatibility_test_impl.py', 'test/torchaudio_unittest/transforms/sox_compatibility_test.py', 'test/torchaudio_unittest/transforms/torchscript_consistency_cuda_test.py', 'test/torchaudio_unittest/transforms/torchscript_consistency_impl.py', 'test/torchaudio_unittest/transforms/transforms_cuda_test.py', 'test/torchaudio_unittest/transforms/transforms_test_impl.py', 'test/torchaudio_unittest/utils/sox_utils_test.py', 'tools/convert_voxpopuli_models.py', 'torchaudio/__init__.py', 'torchaudio/_internal/__init__.py', 'torchaudio/backend/__init__.py', 'torchaudio/backend/soundfile_backend.py', 'torchaudio/backend/sox_io_backend.py', 'torchaudio/backend/utils.py', 'torchaudio/datasets/cmuarctic.py', 'torchaudio/datasets/cmudict.py', 'torchaudio/datasets/commonvoice.py', 'torchaudio/datasets/dr_vctk.py', 'torchaudio/datasets/gtzan.py', 'torchaudio/datasets/librimix.py', 'torchaudio/datasets/libritts.py', 'torchaudio/datasets/quesst14.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/tedlium.py', 'torchaudio/datasets/vctk.py', 'torchaudio/datasets/yesno.py', 'torchaudio/functional/__init__.py', 'torchaudio/io/_stream_reader.py', 'torchaudio/models/__init__.py', 'torchaudio/models/conv_tasnet.py', 'torchaudio/models/tacotron2.py', 'torchaudio/models/wav2letter.py', 'torchaudio/models/wav2vec2/__init__.py', 'torchaudio/models/wav2vec2/components.py', 'torchaudio/models/wav2vec2/model.py', 'torchaudio/models/wav2vec2/utils/import_fairseq.py', 'torchaudio/models/wav2vec2/utils/import_huggingface.py', 'torchaudio/models/wavernn.py', 'torchaudio/pipelines/__init__.py', 'torchaudio/pipelines/_tts/impl.py', 'torchaudio/pipelines/_tts/interface.py', 'torchaudio/pipelines/_tts/utils.py', 'torchaudio/pipelines/_wav2vec2/impl.py', 'torchaudio/pipelines/rnnt_pipeline.py', 'torchaudio/prototype/ctc_decoder/_ctc_decoder.py', 'torchaudio/prototype/models/conv_emformer.py', 'torchaudio/sox_effects/__init__.py', 'torchaudio/sox_effects/sox_effects.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py', 'torchaudio/utils/__init__.py', 'torchaudio/utils/sox_utils.py']",False,15,5,2022
44f4a5ea9ce1e5c9a900589bf57e0d2a99957355,"Refactor LibriSpeech dataset (#2387)

Summary:
Refactors `librispeech.py` to clarify its logic.

Pull Request resolved: https://github.com/pytorch/audio/pull/2387

Reviewed By: nateanl

Differential Revision: D36359176

Pulled By: hwangjeff

fbshipit-source-id: 595dd1421738279896348448dd72ca57bfe7cef2",hwangjeff,iamjeffhwang@gmail.com,['torchaudio/datasets/librispeech.py'],False,13,5,2022
72b712a1eef4f3ba292b8712e2acf15519d61378,"Move Streamer API out of prototype (#2378)

Summary:
This commit moves the Streaming API out of prototype module.

* The related classes are renamed as following

  - `Streamer` -> `StreamReader`.
  - `SourceStream` -> `StreamReaderSourceStream`
  - `SourceAudioStream` -> `StreamReaderSourceAudioStream`
  - `SourceVideoStream` -> `StreamReaderSourceVideoStream`
  - `OutputStream` -> `StreamReaderOutputStream`

This change is preemptive measurement for the possibility to add
`StreamWriter` API.

* Replace BUILD_FFMPEG build arg with USE_FFMPEG

We are not building FFmpeg, so USE_FFMPEG is more appropriate

 ---

After https://github.com/pytorch/audio/issues/2377

Remaining TODOs: (different PRs)
- [ ] Introduce `is_ffmpeg_binding_available` function.
- [ ] Refactor C++ code:
   - Rename `Streamer` to `StreamReader`.
   - Rename `streamer.[h|cpp]` to `stream_reader.[h|cpp]`.
   - Rename `prototype.cpp` to `stream_reader_binding.cpp`.
   - Introduce `stream_reader` directory.
- [x] Enable FFmpeg in smoke test (https://github.com/pytorch/audio/issues/2381)

Pull Request resolved: https://github.com/pytorch/audio/pull/2378

Reviewed By: carolineechen

Differential Revision: D36359299

Pulled By: mthrok

fbshipit-source-id: 6a57b702996af871e577fb7addbf3522081c1328",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.github/workflows/integration-test.yml', 'CMakeLists.txt', 'docs/source/index.rst', 'docs/source/io.rst', 'docs/source/prototype.io.rst', 'docs/source/prototype.rst', 'examples/tutorials/device_asr.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streaming_api_tutorial.py', 'packaging/torchaudio/meta.yaml', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/io/stream_reader_test.py', 'tools/setup_helpers/extension.py', 'torchaudio/__init__.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/io/__init__.py', 'torchaudio/io/_stream_reader.py', 'torchaudio/prototype/io/__init__.py']",False,13,5,2022
9499f642fb3a46e38e44568bd7c03da579133147,"Use module-level `__getattr__` to implement delayed initialization (#2377)

Summary:
This commit updates the lazy module initialization logic for
`torchaudio.prototype.io` and `torchaudio.prototype.ctc_decoder`.

- The modules are importable regarless of optional dependencies.
i.e. `import torchaudio.prototype.io` does not trigger the check for
optional dependencies.

- Optional dependencies are checked when the actual
API is imported for the first time.
i.e. `from torchaudio.prototype.io import Streamer` triggers the check
for optional dependencies.

The downside is that;

- `import torchaudio.prototype.io.Streamer` no longer works.

## Details:

Starting from Python 3.7, modules can bave `__getattr__` function,
which serves as a fallback if the import mechanism cannot find the
attribute.

This can be used to implement lazy import.

```python
def __getattr__(name):
    global pi
    if name == 'pi':
        import math
        pi = math.pi
        return pi
    raise AttributeError(...)
```

Ref: https://twitter.com/raymondh/status/1094686528440168453

The implementation performs lazy import for the APIs that work with
external/optional dependencies. In addition, it also check if the
binding is initialized only once.

## Why is this preferable approach?

Previously, the optional dependencies were checked at the tiem module
is imported;

https://github.com/pytorch/audio/blob/2f4eb4ac2f48a597825d3631a840afd855fe6b39/torchaudio/prototype/io/__init__.py#L1-L5

As long as this module is in `prototype`, which we ask users to import
explictly, users had control whether they want/do not want to install
the optional dependencies.

This approach only works for one optional dependencies per one module.
Say, we add different I/O library as an optional dependency, we need to
put all the APIs in dedicated submodule. This prevents us from having
flat namespace.
i.e. the I/O modules with multiple optional dependencies would look like

```python
# Client code
from torchaudio.io.foo import FooFeature
from torchaudio.io.bar import BarFeature
```

where the new approach would allow

```python
#client code
from torchaudio.io import FooFeature, BarFeature
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2377

Reviewed By: nateanl

Differential Revision: D36305603

Pulled By: mthrok

fbshipit-source-id: c1eb6cac203f6dd0026d99f9a1de1af590a535ae",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/common_utils/ctc_decoder_utils.py', 'torchaudio/prototype/ctc_decoder/__init__.py', 'torchaudio/prototype/ctc_decoder/_ctc_decoder.py', 'torchaudio/prototype/io/__init__.py']",False,12,5,2022
f5036c7182f43e06ddf12f2b327cafaecf5763cf,"Refactor MVDR module (#2383)

Summary:
- Use `apply_beamforming`, `rtf_evd`, `rtf_power`, `mvdr_weights_souden`, `mvdr_weights_rtf` methods under `torchaudio.functional` to replace the class methods.
- Refactor docstrings in `PSD` and `MVDR`.
- Put `_get_mvdr_vector` outside of `MVDR` class as it doesn't call self methods inside.
- Since MVDR uses einsum for matrix operations, packing and unpacking batches are not necessary. It can be tested by the [batch_consistency_test](https://github.com/pytorch/audio/blob/main/test/torchaudio_unittest/transforms/batch_consistency_test.py#L202). Removed it from the code.

Pull Request resolved: https://github.com/pytorch/audio/pull/2383

Reviewed By: carolineechen, mthrok

Differential Revision: D36338373

Pulled By: nateanl

fbshipit-source-id: a48a6ae2825657e5967a19656245596cdf037c5f",Zhaoheng Ni,zni@fb.com,"['torchaudio/functional/functional.py', 'torchaudio/transforms/_multi_channel.py']",False,12,5,2022
096396802de3b1b304c58eb331dc59c8d27fe5de,"Fix CollateFn in HuBERT pre-training recipe (#2296)

Summary:
- When cropping the waveform and corresponding label, we use the formula `torch.div(audio_start - kernel_size * sample_rate, stride * sample_rate, rounding_mode=""floor"")` to align the audio start and label start indices. However, sometimes the value can be negative, which result in an empty label. The training example will hurt the performance after zero-padding (i.e., the labels are all zero for the input waveform).
This PR fixes the bug by checking if `label_start` is negative, and change it to zero if so.
- If `pad` is True, the `length` should be the length of each waveform instead of the max length. Fix it to make the model ignore the padding component in pre-training.

Pull Request resolved: https://github.com/pytorch/audio/pull/2296

Reviewed By: mthrok

Differential Revision: D36323217

Pulled By: nateanl

fbshipit-source-id: 1ffa71e39bbc0e8dee55c3b829911bc2e785b423",Zhaoheng Ni,zni@fb.com,"['examples/hubert/dataset/hubert_dataset.py', 'test/torchaudio_unittest/example/hubert/__init__.py', 'test/torchaudio_unittest/example/hubert/test_crop_audio_label.py']",False,12,5,2022
595dc5d3a3ebf19a5a6d0f538bf2717f30f06b1a,"[black][codemod] formatting changes from black 22.3.0

Summary:
Applies the black-fbsource codemod with the new build of pyfmt.

paintitblack

Reviewed By: lisroach

Differential Revision: D36324783

fbshipit-source-id: 280c09e88257e5e569ab729691165d8dedd767bc",John Reese,jreese@fb.com,"['examples/asr/emformer_rnnt/global_stats.py', 'examples/hubert/utils/kmeans.py', 'examples/pipeline_tacotron2/train.py', 'examples/pipeline_wavernn/datasets.py', 'examples/pipeline_wavernn/main.py', 'examples/pipeline_wavernn/processing.py', 'examples/tutorials/audio_resampling_tutorial.py', 'test/torchaudio_unittest/transforms/transforms_test.py', 'torchaudio/datasets/utils.py', 'torchaudio/functional/filtering.py', 'torchaudio/functional/functional.py', 'torchaudio/models/conv_tasnet.py', 'torchaudio/models/wav2vec2/components.py', 'torchaudio/models/wavernn.py', 'torchaudio/pipelines/_tts/utils.py']",False,12,5,2022
9877f54491a7081266207e1a999dd47bc2bba17e,"Move FFmpeg integrity test from conda smoke test to custom smoke test (#2381)

Summary:
Conda package build performs simple smoke test, which is different
from smoke_test jobs we define on our CI jobs.

Currently Conda packaging smoke test verifies the imporatability of
`torchaudio.prototype.io`, which requires FFmpeg 4.

1. We list FFmpeg 4 as runtime requirements, but this means that
conda's dependency resolver takes FFmpeg 4 into consideration.
FFmpeg 5 was release this year, and we can expect that user base
will move to FFmpeg gradually. If user environment has some constraint
on FFmpeg, torchaudio will have conflict and it will prevent users
from install torchaudio.

2. In #2377 the way optional dependency is checked/initialized is changed,
so this Conda smoke test will no longer check the integrity with FFmpeg libraries.

To solve the issues above, this commit moves the part that tests integrity with
FFmpeg libraries to the smoke test we define on CircleCI.

Pull Request resolved: https://github.com/pytorch/audio/pull/2381

Reviewed By: carolineechen

Differential Revision: D36323706

Pulled By: mthrok

fbshipit-source-id: 57ca816e0f3ad8e16d21e56062f6ed8a09ab93a3",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'packaging/torchaudio/meta.yaml', 'test/smoke_test/smoke_test.py']",True,11,5,2022
448f53e118b5b54d6798fd2e6d12604fae273618,"Move multi-channel modules to a separate file (#2382)

Summary:
The modules include:
- PSD
- MVDR
- RTFMVDR
- SoudenMVDR

Pull Request resolved: https://github.com/pytorch/audio/pull/2382

Reviewed By: carolineechen

Differential Revision: D36314096

Pulled By: nateanl

fbshipit-source-id: 9d7d962b1c70cdc435a579191ad88838dd6fc0ba",Zhaoheng Ni,zni@fb.com,"['torchaudio/transforms/__init__.py', 'torchaudio/transforms/_multi_channel.py', 'torchaudio/transforms/_transforms.py']",True,11,5,2022
961a3ae937afee6617af3925938de7035d9d442f,"Remove CodeQL (#2380)

Summary:
Since a while ago, CodeQL is always emitting red signal, but the team
does not know what this is / how to fix this. At this point, it is
purely noise while not providing a valuable signal.

Ref https://github.com/pytorch/audio/issues/2314

Pull Request resolved: https://github.com/pytorch/audio/pull/2380

Reviewed By: carolineechen

Differential Revision: D36305599

Pulled By: mthrok

fbshipit-source-id: 27ece58730066543600f3873397b9a239e54beb0",moto,855818+mthrok@users.noreply.github.com,['.github/workflows/codeql.yml'],True,11,5,2022
f35ad4618bbba732f4aa02c3b7ab7182a5df9e70,"Ignore TempDir clean up error (#2379)

Summary:
On CircleCI, Windows unittests are failing for Python 3.7 with
`PermissionError` at the end of test when it cleans up temporary
directory.

According to the discussion https://github.com/python/cpython/issues/74168,
this is caused by a known issue with `shutil.rmtree`.

In the above thread it is advised to simply ignore the error as it
is not guaranteed that temp directories are cleaned up.

This commit follows the same path and simply ignore the error
so that our CI gets back to green.

Pull Request resolved: https://github.com/pytorch/audio/pull/2379

Reviewed By: carolineechen

Differential Revision: D36305595

Pulled By: mthrok

fbshipit-source-id: d9049c2ee3447712119786311f639a1f9f8911c5",moto,855818+mthrok@users.noreply.github.com,['test/torchaudio_unittest/common_utils/case_utils.py'],False,11,5,2022
69467ea59003e950152e2abb9e447807c45cad79,"Refactor LibriSpeech Conformer RNN-T recipe (#2366)

Summary:
Modifies the example LibriSpeech Conformer RNN-T recipe as follows:
- Moves data loading and transforms logic from lightning module to data module (improves generalizability and reusability of lightning module and data module).
- Moves transforms logic from dataloader collator function to dataset (resolves dataloader multiprocessing issues on certain platforms).
- Replaces lambda functions with `partial` equivalents (resolves pickling issues in certain runtime environments).
- Modifies training script to allow for specifying path model checkpoint to restart training from.

Pull Request resolved: https://github.com/pytorch/audio/pull/2366

Reviewed By: mthrok

Differential Revision: D36305028

Pulled By: hwangjeff

fbshipit-source-id: 0b768da5d5909136c55418bf0a3c2ddd0c5683ba",hwangjeff,iamjeffhwang@gmail.com,"['examples/asr/librispeech_conformer_rnnt/data_module.py', 'examples/asr/librispeech_conformer_rnnt/eval.py', 'examples/asr/librispeech_conformer_rnnt/lightning.py', 'examples/asr/librispeech_conformer_rnnt/train.py', 'examples/asr/librispeech_conformer_rnnt/transforms.py']",True,11,5,2022
93c26d6330c94270c0f0e8c561dd4e7dd3c800d1,"Refactor the constructors of pointer wrappers (#2373)

Summary:
This commit refactor the constructor of wrapper classes so that
wrapper classes are only responsible for deallocation of underlying
FFmpeg custom structures.

The responsibility of custom initialization is moved to helper functions.

Context:

FFmpeg API uses bunch of raw pointers, which require dedicated allocater
and deallcoator. In torchaudio we wrap these pointers with
`std::unique_ptr<>` to adopt RAII semantics.

Currently all of the customization logics required for `Streamer` are
handled by the constructor of wrapper class. Like the following;

```
AVFormatContextPtr(
      const std::string& src,
      const std::string& device,
      const std::map<std::string, std::string>& option);
```

This constructor allocates the raw `AVFormatContext*` pointer,
while initializing it with the given option, then it parses the
input media.

As we consider the write/encode features, which require different way
of initializing the `AVFormatContext*`, making it the responsibility
of constructors of `AVFormatContextPtr` reduce the flexibility.

Thus this commit moves the customization to helper factory function.

- `AVFormatContextPtr(...)` -> `get_input_format_context(...)`
- `AVCodecContextPtr(...)` -> `get_decode_context(...)`

Pull Request resolved: https://github.com/pytorch/audio/pull/2373

Reviewed By: hwangjeff

Differential Revision: D36230148

Pulled By: mthrok

fbshipit-source-id: 202d57d549223904ee958193f3b386ef5a9cda3a",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/decoder.cpp', 'torchaudio/csrc/ffmpeg/decoder.h', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/streamer.cpp']",True,11,5,2022
2c79b55a0278527881f02a8ecb2f0cc5d6a4f0b4,"Add ConvEmformer module (#2358)

Summary:
Adds an implementation of the convolution-augmented streaming transformer (effectively Emformer with convolution block) described in https://arxiv.org/abs/2110.05241.

Continuation of https://github.com/pytorch/audio/issues/2324.

Pull Request resolved: https://github.com/pytorch/audio/pull/2358

Reviewed By: nateanl, xiaohui-zhang

Differential Revision: D36137992

Pulled By: hwangjeff

fbshipit-source-id: 9c7a7c233944fe9ef15b9ba397d7f0809da1f063",hwangjeff,iamjeffhwang@gmail.com,"['docs/source/prototype.models.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/models/emformer/emformer_test_impl.py', 'test/torchaudio_unittest/prototype/conv_emformer_cpu_test.py', 'test/torchaudio_unittest/prototype/conv_emformer_gpu_test.py', 'test/torchaudio_unittest/prototype/conv_emformer_test_impl.py', 'torchaudio/models/emformer.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/conv_emformer.py']",True,10,5,2022
2f4eb4ac2f48a597825d3631a840afd855fe6b39,"Fix return dtype in MVDR module (#2376)

Summary:
Address https://github.com/pytorch/audio/issues/2375
The MVDR module internally transforms the dtype of complex tensors to `torch.complex128` for computation and transforms it back to the original dtype before returning the Tensor. However, it didn't convert back successfully due to `specgram_enhanced.to(dtype)`, which should be `specgram_enhanced = specgram_enhanced.to(dtype)`. Fix it to make the output dtype consistent with original input.

Pull Request resolved: https://github.com/pytorch/audio/pull/2376

Reviewed By: hwangjeff

Differential Revision: D36280851

Pulled By: nateanl

fbshipit-source-id: 553d1b98f899547209a4e3ebc59920c7ef1f3112",Zhaoheng Ni,zni@fb.com,"['test/torchaudio_unittest/transforms/transforms_test_impl.py', 'torchaudio/transforms/_transforms.py']",False,10,5,2022
eab2f39dd688c969434cd61bb074956404ab8120,"[ROCm] Update to rocm5.1.1 (#2362)

Summary:
previous update for rocm: https://github.com/pytorch/audio/pull/2186

Pull Request resolved: https://github.com/pytorch/audio/pull/2362

Reviewed By: seemethere

Differential Revision: D36283672

Pulled By: mthrok

fbshipit-source-id: bfd38940d027c8ccd72ab48991e5ab7f84b0e9c0",Kyle Chen,kylechen@amd.com,"['.circleci/config.yml', '.circleci/regenerate.py']",True,10,5,2022
4b021ae33b8a2c17901b8c9f394e660395b915ea,"Add RTFMVDR module (#2368)

Summary:
Add a new design of MVDR module.
The RTFMVDR module supports the method based on the relative transfer function (RTF) and power spectral density (PSD) matrix of noise.
The input arguments are:
- multi-channel spectrum.
- RTF vector of the target speech
- PSD matrix of noise.
- reference channel in the microphone array.
- diagonal_loading option to enable or disable diagonal loading in matrix inverse computation.
- diag_eps for computing the inverse of the matrix.
- eps for computing the beamforming weight.
The output of the module is the single-channel complex-valued spectrum for the enhanced speech.

Pull Request resolved: https://github.com/pytorch/audio/pull/2368

Reviewed By: carolineechen

Differential Revision: D36214940

Pulled By: nateanl

fbshipit-source-id: 5f29f778663c96591e1b520b15f7876d07116937",Zhaoheng Ni,zni@fb.com,"['docs/source/transforms.rst', 'test/torchaudio_unittest/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/transforms/torchscript_consistency_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",False,10,5,2022
da1e83cc341165d5c9e35ce8d54647780e4bf4e1,"Add diagonal_loading optional to rtf_power (#2369)

Summary:
When computing the MVDR beamforming weights using the power iteration method, the PSD matrix of noise can be applied with diagonal loading to improve the robustness. This is also applicable to computing the RTF matrix (See https://github.com/espnet/espnet/blob/master/espnet2/enh/layers/beamformer.py#L614 as an example). This also aligns with current `torchaudio.transforms.MVDR` module to keep the consistency.

This PR adds the `diagonal_loading` argument with `True` as default value to `torchaudio.functional.rtf_power`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2369

Reviewed By: carolineechen

Differential Revision: D36204130

Pulled By: nateanl

fbshipit-source-id: 93a58d5c2107841a16c4e32f0c16ab0d6b2d9420",Zhaoheng Ni,zni@fb.com,"['test/torchaudio_unittest/common_utils/beamform_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/functional.py']",False,10,5,2022
aed5eb88adeba872cf9859bd5b5bfe10ba77e835,"Add SoudenMVDR module (#2367)

Summary:
Add a new design of MVDR module.
The `SoudenMVDR` module supports the method proposed by [Souden et, al.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.725.673&rep=rep1&type=pdf).
The input arguments are:
- multi-channel spectrum.
- PSD matrix of target speech.
- PSD matrix of noise.
- reference channel in the microphone array.
- diagonal_loading option to enable or disable diagonal loading in matrix inverse computation.
- diag_eps for computing the inverse of the matrix.
- eps for computing the beamforming weight.

The output of the module is the single-channel complex-valued spectrum for the enhanced speech.

Pull Request resolved: https://github.com/pytorch/audio/pull/2367

Reviewed By: hwangjeff

Differential Revision: D36198015

Pulled By: nateanl

fbshipit-source-id: 4027f4752a84aaef730ef3ea8c625e801cc35527",Zhaoheng Ni,zni@fb.com,"['docs/source/transforms.rst', 'test/torchaudio_unittest/transforms/autograd_test_impl.py', 'test/torchaudio_unittest/transforms/batch_consistency_test.py', 'test/torchaudio_unittest/transforms/torchscript_consistency_impl.py', 'torchaudio/functional/functional.py', 'torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",False,10,5,2022
54d2d04f3a8bb6094e2d28b88c790c547f31388f,"Add HW acceleration support on Streamer (#2331)

Summary:
This commits add `hw_accel` option to `Streamer::add_video_stream` method.
Specifying `hw_accel=""cuda""` allows to create the chunk Tensor directly from CUDA,
when the following conditions are met.
1. the video format is H264,
2. underlying ffmpeg is compiled with NVENC, and
3. the client code specifies `decoder=""h264_cuvid""`.

A simple benchmark yields x7 improvement in the decoding speed.

<details>

```python
import time

from torchaudio.prototype.io import Streamer

srcs = [
    ""https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4"",
    ""./NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4"",  # offline version
]

patterns = [
    (""h264_cuvid"", None, ""cuda:0""),  # NVDEC on CUDA:0 -> CUDA:0
    (""h264_cuvid"", None, ""cuda:1""),  # NVDEC on CUDA:1 -> CUDA:1
    (""h264_cuvid"", None, None),  # NVDEC -> CPU
    (None, None, None),  # CPU
]

for src in srcs:
    print(src, flush=True)
    for (decoder, decoder_options, hw_accel) in patterns:
        s = Streamer(src)
        s.add_video_stream(5, decoder=decoder, decoder_options=decoder_options, hw_accel=hw_accel)

        t0 = time.monotonic()
        num_frames = 0
	for i, (chunk, ) in enumerate(s.stream()):
	    num_frames += chunk.shape[0]
        t1 = time.monotonic()
        print(chunk.dtype, chunk.shape, chunk.device)
        print(time.monotonic() - t0, num_frames, flush=True)
```
</details>

```
https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4
torch.uint8 torch.Size([5, 3, 1080, 1920]) cuda:0
10.781158386962488 6175
torch.uint8 torch.Size([5, 3, 1080, 1920]) cuda:1
10.771313901990652 6175
torch.uint8 torch.Size([5, 3, 1080, 1920]) cpu
27.88662809302332 6175
torch.uint8 torch.Size([5, 3, 1080, 1920]) cpu
83.22728440898936 6175
./NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4
torch.uint8 torch.Size([5, 3, 1080, 1920]) cuda:0
12.945253834011964 6175
torch.uint8 torch.Size([5, 3, 1080, 1920]) cuda:1
12.870224556012545 6175
torch.uint8 torch.Size([5, 3, 1080, 1920]) cpu
28.03406483103754 6175
torch.uint8 torch.Size([5, 3, 1080, 1920]) cpu
82.6120332319988 6175
```

With HW resizing

<details>

```python
import time

from torchaudio.prototype.io import Streamer

srcs = [
    ""./NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4"",
    ""https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4"",
]

patterns = [
    # Decode with NVDEC, CUDA HW scaling -> CUDA:0
    (""h264_cuvid"", {""resize"": ""960x540""}, """", ""cuda:0""),
    # Decoded with NVDEC, CUDA HW scaling -> CPU
    (""h264_cuvid"", {""resize"": ""960x540""}, """", None),
    # CPU decoding, CPU scaling
    (None, None, ""scale=width=960:height=540"", None),
]

for src in srcs:
    print(src, flush=True)
    for (decoder, decoder_options, filter_desc, hw_accel) in patterns:
        s = Streamer(src)
        s.add_video_stream(
            5,
            decoder=decoder,
            decoder_options=decoder_options,
            filter_desc=filter_desc,
            hw_accel=hw_accel,
        )

        t0 = time.monotonic()
        num_frames = 0
        for i, (chunk, ) in enumerate(s.stream()):
            num_frames += chunk.shape[0]
        t1 = time.monotonic()
        print(chunk.dtype, chunk.shape, chunk.device)
        print(time.monotonic() - t0, num_frames, flush=True)
```

</details>

```
./NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4
torch.uint8 torch.Size([5, 3, 540, 960]) cuda:0
12.890056837990414 6175
torch.uint8 torch.Size([5, 3, 540, 960]) cpu
10.697489063022658 6175
torch.uint8 torch.Size([5, 3, 540, 960]) cpu
85.19899423001334 6175

https://download.pytorch.org/torchaudio/tutorial-assets/stream-api/NASAs_Most_Scientifically_Complex_Space_Observatory_Requires_Precision-MP4.mp4
torch.uint8 torch.Size([5, 3, 540, 960]) cuda:0
10.712715593050234 6175
torch.uint8 torch.Size([5, 3, 540, 960]) cpu
11.030170071986504 6175
torch.uint8 torch.Size([5, 3, 540, 960]) cpu
84.8515750519582 6175
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2331

Reviewed By: hwangjeff

Differential Revision: D36217169

Pulled By: mthrok

fbshipit-source-id: 7979570b083cfc238ad4735b44305d8649f0607b",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/buffer.cpp', 'torchaudio/csrc/ffmpeg/buffer.h', 'torchaudio/csrc/ffmpeg/decoder.cpp', 'torchaudio/csrc/ffmpeg/decoder.h', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/prototype.cpp', 'torchaudio/csrc/ffmpeg/sink.cpp', 'torchaudio/csrc/ffmpeg/sink.h', 'torchaudio/csrc/ffmpeg/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_processor.h', 'torchaudio/csrc/ffmpeg/streamer.cpp', 'torchaudio/csrc/ffmpeg/streamer.h', 'torchaudio/prototype/io/streamer.py']",False,10,5,2022
638120ca9b7478cb9af1c394e23172161dcfa710,"Add citations for datasets (#2371)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2371

Reviewed By: xiaohui-zhang

Differential Revision: D36246167

Pulled By: carolineechen

fbshipit-source-id: 23042a1c393711864a18c9815d248c18d1d258b4",Caroline Chen,carolinechen@fb.com,"['docs/source/datasets.rst', 'docs/source/refs.bib', 'torchaudio/datasets/cmuarctic.py', 'torchaudio/datasets/cmudict.py', 'torchaudio/datasets/commonvoice.py', 'torchaudio/datasets/dr_vctk.py', 'torchaudio/datasets/gtzan.py', 'torchaudio/datasets/librimix.py', 'torchaudio/datasets/librispeech.py', 'torchaudio/datasets/libritts.py', 'torchaudio/datasets/ljspeech.py', 'torchaudio/datasets/quesst14.py', 'torchaudio/datasets/speechcommands.py', 'torchaudio/datasets/tedlium.py', 'torchaudio/datasets/vctk.py', 'torchaudio/datasets/yesno.py']",False,10,5,2022
fe3d5d1074b91e18cc6186a4c6d0f9faa816444b,"Cleanup cuda115 unused code (#2374)

Summary:
Cleanup old version of cuda115 and other legacy versions

Pull Request resolved: https://github.com/pytorch/audio/pull/2374

Reviewed By: nateanl, mthrok

Differential Revision: D36250955

Pulled By: atalman

fbshipit-source-id: 6b7f0e2926eeb688991c939901c980428cf8e7ef",Andrey Talman,atalman@fb.com,"['packaging/build_conda.sh', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",True,9,5,2022
b7624c609f0345b16854d036d365d92ad6e19c35,"Use custom FFmpeg libraries for torchaudio binary distributions (#2355)

Summary:
This commit changes the way torchaudio binary distributions are built.

* For all the binary distributions (conda/pip on Linux/macOS/Windnows), build custom FFmpeg libraries.
* The custom FFmpeg libraries do not use `--use-gpl` nor `--use-nonfree`, so that they stay LGPL.
* The custom FFmpeg libraries employ rpath so that the torchaudio binary distributions look for the corresponding FFmpeg libraries installed in the runtime environment.
* The torchaudio binary build process will use them to bootstrap its build process.
* The custom FFmpeg libraries are NOT shipped.

This commit also add disclaimer about FFmpeg in README.

Pull Request resolved: https://github.com/pytorch/audio/pull/2355

Reviewed By: nateanl

Differential Revision: D36202087

Pulled By: mthrok

fbshipit-source-id: c30e5222ba190106c897e42f567cac9152dbd8ef",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', 'README.md', 'packaging/build_conda.sh', 'packaging/build_wheel.sh', 'packaging/ffmpeg/build.bat', 'packaging/ffmpeg/build.sh', 'packaging/pkg_helpers.bash', 'packaging/torchaudio/meta.yaml', 'tools/bootstrap_ffmpeg.sh', 'torchaudio/csrc/CMakeLists.txt']",False,6,5,2022
6a8a28bb589135ef3245d08f88a6ee87efd973ab,"Refactor smoke test executions (#2365)

Summary:
The smoke test jobs simply perform `import torchaudio` to check
if the package artifacts are sane.

Originally, the CI was executing it in the root directory.
This was fine unless the source code is checked out.
When source code is checked out, performing `import torchaudio` in
root directory would import source torchaudio directory, instead of the
installed package.

This error is difficult to notice, so this commit introduces common script to
perform the smoke test, while moving out of root directory.

Pull Request resolved: https://github.com/pytorch/audio/pull/2365

Reviewed By: carolineechen

Differential Revision: D36202069

Pulled By: mthrok

fbshipit-source-id: 4396f85fec5c54869ada4c08f51304539f1b05cf",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'test/smoke_test/run_smoke_test.sh', 'test/smoke_test/smoke_test.py']",False,6,5,2022
6beb4875a6a4228857932bf2897a466e0c83eba2,"Run smoke tests on regular PRs (#2364)

Summary:
Currently smoke tests are only executed on nightly jobs.
This is inconvenient as PRs that changes build process do not get
the signal naturally.

This commit changes it by always executing smoke tests.

Pull Request resolved: https://github.com/pytorch/audio/pull/2364

Reviewed By: atalman

Differential Revision: D36171267

Pulled By: mthrok

fbshipit-source-id: e549965ba139b5992177b7a094d87c9ef4432a7f",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/regenerate.py']",False,5,5,2022
70d7d69675b63317adf3a9483076e1e3ecaf8f2a,"Fix windows smoke test (#2361)

Summary:
This PR fixes Windows Smoke tests

Tested via  circleci :
https://app.circleci.com/pipelines/github/pytorch/audio/10572/workflows/970fd791-25cc-4af4-8183-a7835e1891bf/jobs/637607

Pull Request resolved: https://github.com/pytorch/audio/pull/2361

Reviewed By: nateanl, mthrok

Differential Revision: D36167317

Pulled By: atalman

fbshipit-source-id: 1418ebffd74614cc1110dc032d16ee9502a7d571",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,5,5,2022
a71e3a401e4a68d23900ff7d3d0437676392fa19,"Add BUILD_MAD option and default to OFF (#2354)

Summary:
libmad integration should be enabled only from source-build

Pull Request resolved: https://github.com/pytorch/audio/pull/2354

Reviewed By: nateanl

Differential Revision: D36012035

Pulled By: mthrok

fbshipit-source-id: adeda8cbfd418f96245909cae6862b648a6915a7",moto,855818+mthrok@users.noreply.github.com,"['.circleci/config.yml', '.circleci/config.yml.in', 'CMakeLists.txt', 'examples/tutorials/audio_data_augmentation_tutorial.py', 'examples/tutorials/audio_io_tutorial.py', 'third_party/CMakeLists.txt', 'third_party/sox/CMakeLists.txt', 'tools/setup_helpers/extension.py']",False,28,4,2022
3cf7f264f427f10b8b33ad1b8a4450aedf92693c,"Fix audio win smoke test to use GPU hosts for CUDA builds (#2353)

Summary:
Fix audio win smoke test to use GPU hosts for CUDA builds

Pull Request resolved: https://github.com/pytorch/audio/pull/2353

Reviewed By: mthrok

Differential Revision: D36006928

Pulled By: atalman

fbshipit-source-id: a27c4cc34093810c8cc08e01188e09b474478001",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.circleci/smoke_test/docker/Dockerfile']",False,28,4,2022
90e4959d225399ed51d0daf9aab52fc6639af281,"Fix bug with unsqueezing length tensor in RNNTBeamSearch (#2344)

Summary:
This PR amends `RNNTBeamSearch`'s streaming decoding method to correctly unsqueeze `length` when its dimension is 0.

Original comment: Is ""input.dim() == 0"" unreachable as it could only be 2 or 3 in assertion of Line 329?

Pull Request resolved: https://github.com/pytorch/audio/pull/2344

Reviewed By: carolineechen, nateanl

Differential Revision: D35899740

Pulled By: hwangjeff

fbshipit-source-id: 84c1692b8cc9e5d35798d87f4a1bd052d94af9fb",Guo Liyong,guonwpu@qq.com,['torchaudio/models/rnnt_decoder.py'],False,27,4,2022
97ed428d3c82010c652686bd8115959163283d33,"Add lexicon free CTC decoder (#2342)

Summary:
Add support for lexicon free decoding based on [fairseq's](https://github.com/pytorch/fairseq/blob/main/examples/speech_recognition/new/decoders/flashlight_decoder.py#L53) implementation. Reached numerical parity with fairseq's decoder in offline experimentation

Follow ups
- Add pretrained LM support for lex free decoding
- Add example in tutorial
- Replace flashlight C++ source code with flashlight text submodule
- [optional] fairseq compatibility test

Pull Request resolved: https://github.com/pytorch/audio/pull/2342

Reviewed By: nateanl

Differential Revision: D35856104

Pulled By: carolineechen

fbshipit-source-id: b64286550984df906ebb747e82f6fb1f21948ac7",Caroline Chen,carolinechen@fb.com,"['docs/source/prototype.ctc_decoder.rst', 'examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'test/integration_tests/prototype/ctc_decoder_integration_test.py', 'test/torchaudio_unittest/assets/decoder/kenlm_char.arpa', 'test/torchaudio_unittest/prototype/ctc_decoder_test.py', 'torchaudio/csrc/CMakeLists.txt', 'torchaudio/csrc/decoder/bindings/pybind.cpp', 'torchaudio/csrc/decoder/src/decoder/LexiconFreeDecoder.cpp', 'torchaudio/csrc/decoder/src/decoder/LexiconFreeDecoder.h', 'torchaudio/prototype/ctc_decoder/__init__.py', 'torchaudio/prototype/ctc_decoder/ctc_decoder.py']",False,26,4,2022
7c249d175bd500190d8848986634d76ccc4b22a3,"Add extra arguments to hubert pretrain factory functions (#2345)

Summary:
In different pre-training and fine-tuning settings, the `mask_prob`, `mask_channel_prob`, and `mask_channel_length` are different. For example, the settings in [pre-training](https://github.com/pytorch/fairseq/blob/main/examples/hubert/config/pretrain/hubert_base_librispeech.yaml#L70) and [fine-tuning](https://github.com/pytorch/fairseq/blob/main/examples/hubert/config/finetune/base_10h.yaml#L69-L73) are different. The motivation is to avoid overfitting when fine-tuning on a small dataset (example: [fine-tune on 10 minutes of audio](https://github.com/pytorch/fairseq/blob/main/examples/wav2vec/config/finetuning/vox_10m.yaml#L57-L59)).
This PR adds the required arguments in the factory functions to make them tunable for pre-training and fine-tuning. `mask_length` is set to `10` by default for all cases, hence it's not included in the factory function.

Pull Request resolved: https://github.com/pytorch/audio/pull/2345

Reviewed By: carolineechen, xiaohui-zhang

Differential Revision: D35845117

Pulled By: nateanl

fbshipit-source-id: 0cbb74d09535d189b8258aa8ee0f88779bdb77e7",Zhaoheng Ni,zni@fb.com,['torchaudio/models/wav2vec2/model.py'],False,26,4,2022
0986eebf7155d474a594485297fda118dfd32cf3,"Update wavernn.py (#2347)

Summary:
fix false shape

Pull Request resolved: https://github.com/pytorch/audio/pull/2347

Reviewed By: carolineechen

Differential Revision: D35921047

Pulled By: nateanl

fbshipit-source-id: 5b58820ee777920c68f13a15d80cd2bcc931af87",Bingcheng Hu,bingcheng1998@qq.com,['torchaudio/models/wavernn.py'],True,26,4,2022
892d6d3404f6777e32be628af7dea1cdde5d18c7,"Fix LibriMix documentation (#2351)

Summary:
The `LibriMix` dataset is missing on the [documentation webpage](https://pytorch.org/audio/stable/datasets.html).

Pull Request resolved: https://github.com/pytorch/audio/pull/2351

Reviewed By: carolineechen

Differential Revision: D35926695

Pulled By: nateanl

fbshipit-source-id: 168aed3bb15510d1b1ec57d77727932e481aca48",Zhaoheng Ni,zni@fb.com,['docs/source/datasets.rst'],False,26,4,2022
867cff5f86e78cee8c394b41fdca0cfa020f2326,"Fix for torchaudio windows tests (#2350)

Summary:
Fix for torchaudio windows tests
Following is an example of such test failing:
https://app.circleci.com/pipelines/github/pytorch/audio/9408/workflows/e6e5a05c-7080-4fdc-b478-2182aed5f234/jobs/531612

The following code is failing:
`conda install -v -y $(ls ~/workspace/torchaudio*.tar.bz2)`

This is because the install package is generated in the following directory:
`/workspace/conda-bld/win-64/`

Pull Request resolved: https://github.com/pytorch/audio/pull/2350

Reviewed By: mthrok

Differential Revision: D35912424

Pulled By: atalman

fbshipit-source-id: fc4f66ffca24061cc768a5f1010b448f065b9410",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,26,4,2022
d1f747fb639235cfcf5e6828038218e72dfb8e0f,"Fix python 3.10 smoke tests (#2348)

Summary:
Fix python 3.10 smoke tests

Pull Request resolved: https://github.com/pytorch/audio/pull/2348

Reviewed By: mthrok

Differential Revision: D35906343

Pulled By: atalman

fbshipit-source-id: 6dbb39e69c9751da4b86d5da38a6d11816d527c5",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/smoke_test/docker/Dockerfile']",True,25,4,2022
48facbd4499adefe622e4d618f9c5ef3f6110d0c,"Cuda 11.5 remove since we introduced cuda 11.6 (#2346)

Summary:
Cuda 11.5 remove since we introduced cuda 11.6

Pull Request resolved: https://github.com/pytorch/audio/pull/2346

Reviewed By: mthrok

Differential Revision: D35856758

Pulled By: atalman

fbshipit-source-id: d3c0cf7639fd20f9ccc52c0738f247b8598f1ed7",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/regenerate.py']",False,22,4,2022
bf89e570d5c451e7ec395de9f02626d99e983d94,"[CircleCI] Update base images to ubuntu-2004 (#2343)

Summary:
Same change as done in this vision [PR](https://github.com/pytorch/vision/pull/5802)

As Ubuntu-1604 runners will no longer be available in early May
Update ubuntu-1604-cuda-10.1:201909-23 to ubuntu-2004-cuda-11.4:202110-01
Per [CircleCI Configuration reference](https://circleci.com/docs/2.0/configuration-reference/)

Resolves https://github.com/pytorch/audio/issues/2279

Pull Request resolved: https://github.com/pytorch/audio/pull/2343

Reviewed By: mthrok

Differential Revision: D35844880

Pulled By: atalman

fbshipit-source-id: 318a9fa42455e55664f3da6ab67625cb969f72e6",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in']",False,22,4,2022
6411c9ad25acfd323b06a520cda7e8963af4afbf,"Introduce DistributedBatchSampler (#2299)

Summary:
When using customized `batch_sampler`, pytorch_lightning can't wrap the distributed sampler onto it. Hence we provide a `DistributedBatchSampler` that supports `BucketizeBatchSampler` in `ddp` mode.

The `DistributedBatchSampler` assumes `BucketizeBatchSampler.iter_list` is a list of lists, where each sub-list contains a batch of indices. Setting `shuffle` to `True` will shuffle the lists based on `seed` and current `epoch`.

The `shuffle` only happens in the initialization, and won't be changed if user don't reset it. The reason is shuffling `BucketizeBatchSampler` may have a different length than before, do shuffling in ``__iter__`` may result in mismatch between ``__len__`` and the real length value.
Hence users need to set `reload_dataloaders_every_n_epochs=1` in pytorch_lightning's Trainer. Then the value of ``__len__``  and the real length is the same.

Pull Request resolved: https://github.com/pytorch/audio/pull/2299

Reviewed By: hwangjeff

Differential Revision: D35781538

Pulled By: nateanl

fbshipit-source-id: 6e8396615497f1aeddab1ee5678830c0445c2b2a",Zhaoheng Ni,zni@fb.com,['examples/hubert/dataset/hubert_dataset.py'],False,22,4,2022
2acafdafd91d4ad3df7079d63fc51f3f3c00813a,"CUDA 11.6 for TorchAudio (#2328)

Summary:
CUDA 11.6 for TorchAudio

Pull Request resolved: https://github.com/pytorch/audio/pull/2328

Reviewed By: mthrok

Differential Revision: D35826414

Pulled By: atalman

fbshipit-source-id: 0a471f0566286d69c0c73191aea7fd5ac0647e5f",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/regenerate.py', 'packaging/build_conda.sh', 'packaging/pkg_helpers.bash', 'packaging/windows/internal/cuda_install.bat']",False,21,4,2022
6b242c29af317498ea51b465529cf8e68c2c88fd,"Change underlying implementation of RNN-T hypothesis to tuple (#2339)

Summary:
PyTorch Lite, which is becoming a standard for mobile PyTorch usage, does not support containers containing custom classes. Consequently, because TorchAudio's RNN-T decoder currently returns and accepts lists of `Hypothesis` namedtuples, it is not compatible with PyTorch Lite. This PR resolves said incompatibility by changing the underlying implementation of `Hypothesis` to tuple.

Pull Request resolved: https://github.com/pytorch/audio/pull/2339

Reviewed By: nateanl

Differential Revision: D35806529

Pulled By: hwangjeff

fbshipit-source-id: 9cbae5504722390511d35e7f9966af2519ccede5",hwangjeff,iamjeffhwang@gmail.com,"['docs/source/models.rst', 'examples/asr/emformer_rnnt/common.py', 'examples/asr/emformer_rnnt/pipeline_demo.py', 'examples/asr/emformer_rnnt/tedlium3/eval_pipeline.py', 'examples/asr/librispeech_conformer_rnnt/lightning.py', 'examples/tutorials/device_asr.py', 'examples/tutorials/online_asr_tutorial.py', 'test/integration_tests/rnnt_pipeline_test.py', 'torchaudio/models/rnnt_decoder.py', 'torchaudio/pipelines/rnnt_pipeline.py']",False,21,4,2022
9465b6bf8158a7ba657c55e354c4492925809757,"Introduce convolution-augmented Emformer layer prototype (#2324)

Summary:
Introduces prototype of convolution-augmented Emformer layer. At a high level, it incorporates Conformer's macaron feedforward network structure and convolution module with Emformer.

Pull Request resolved: https://github.com/pytorch/audio/pull/2324

Reviewed By: mthrok

Differential Revision: D35734252

Pulled By: hwangjeff

fbshipit-source-id: c7ea0bdcfe53a948b00881a74f1f1e1928f5ac57",hwangjeff,iamjeffhwang@gmail.com,['torchaudio/prototype/models/conv_emformer.py'],True,19,4,2022
aebcf6afda026fab90a67a4162c3d2f67b9ba367,"Add QUESST14 dataset (#2290)

Summary:
implementation adapted from [s3prl](https://github.com/s3prl/s3prl/blob/master/s3prl/downstream/quesst14_dtw/dataset.py)

modifying the s3prl downstream expert to [this](https://github.com/carolineechen/s3prl/commit/adc91a53d581a604f495f3795a865d84aa17f1a5) using this dataset implementation produces the same results as using the original s3prl pipeline

Pull Request resolved: https://github.com/pytorch/audio/pull/2290

Reviewed By: nateanl

Differential Revision: D35692551

Pulled By: carolineechen

fbshipit-source-id: 035ad161d4cbbd2072411cfdf89984b73a89868c",Caroline Chen,carolinechen@fb.com,"['docs/source/datasets.rst', 'test/torchaudio_unittest/datasets/quesst14_test.py', 'torchaudio/datasets/__init__.py', 'torchaudio/datasets/quesst14.py']",True,18,4,2022
86100e387216227157598abc7ad5a28d63a7cf34,"Disable clang-tidy modernize-use-trailing-return-type (#2337)

Summary:
Disable clang-tidy's `modernize-use-trailing-return-type` suggestion.

Trailing return type has no impact on performance.
The lint warning shows up everywhere, and it's nothing but noise.

Pull Request resolved: https://github.com/pytorch/audio/pull/2337

Reviewed By: hwangjeff

Differential Revision: D35635718

Pulled By: mthrok

fbshipit-source-id: beb2d3ec657f829493e08b2c159f215053b0e784",Moto Hira,moto@fb.com,['.clang-tidy'],False,15,4,2022
be243c59e7392f013fb613bcdb801782b35581df,"Support specifying decoder and its options (#2327)

Summary:
This commit adds support to specify decoder to Streamer's add stream method.
This is roughly equivalent to `ffmpeg`'s `-c:v foo` and `-c:a foo` options.

This allows to override the decoder codec and/or specify the option of
the decoder.

This change allows to specify Nvidia NVDEC codec for supported formats,
which uses dedicated hardware for decoding the video.

 ---

Note: The CL might look overwhelming, but it's essentially, add new parameters in Python, and pass them down all the way to  `AVCodecContextPtr`, which initializes the actual decoder implementation (`AVCodecContext`.)

Pull Request resolved: https://github.com/pytorch/audio/pull/2327

Reviewed By: carolineechen

Differential Revision: D35626904

Pulled By: mthrok

fbshipit-source-id: a115ed548624e53c16bacfecff5aa6c9d4e8bede",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/decoder.cpp', 'torchaudio/csrc/ffmpeg/decoder.h', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/prototype.cpp', 'torchaudio/csrc/ffmpeg/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_processor.h', 'torchaudio/csrc/ffmpeg/streamer.cpp', 'torchaudio/csrc/ffmpeg/streamer.h', 'torchaudio/prototype/io/streamer.py']",False,14,4,2022
7972be9904176aefe086f00005941d827f41627c,"Support NV12 format in video decoding (#2330)

Summary:
Support NV12 format in Streamer API.

NV12 is a biplanar format with a full sized Y plane followed by a single chroma plane with weaved U and V values.
https://chromium.googlesource.com/libyuv/libyuv/+/HEAD/docs/formats.md#nv12-and-nv21

The original UV plane is smaller than Y plane, so in this implmentation,
UV plane is upsampled to match the size of Y plane.

Pull Request resolved: https://github.com/pytorch/audio/pull/2330

Reviewed By: hwangjeff

Differential Revision: D35632351

Pulled By: mthrok

fbshipit-source-id: aab4fbc0ce2bb7a1fb67264c27208b610fb56e27",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/buffer.cpp'],False,14,4,2022
2f70e2f90708800d28128671d4e04744c87ab97e,"Add YUV420P format support to Streamer API (#2334)

Summary:
This commit adds YUV420P format support to Streamer API.
When the native format of a video is YUV420P, the Streamer will
output Tensor of YUV color channel.

Pull Request resolved: https://github.com/pytorch/audio/pull/2334

Reviewed By: hwangjeff

Differential Revision: D35632916

Pulled By: mthrok

fbshipit-source-id: a7a0078788433060266b8bd3e7cad023f41389f5",moto,855818+mthrok@users.noreply.github.com,"['torchaudio/csrc/ffmpeg/buffer.cpp', 'torchaudio/csrc/ffmpeg/prototype.cpp', 'torchaudio/prototype/io/streamer.py']",False,14,4,2022
c262758b477e793cb61df02216897f3779b2e068,"Add Conformer RNN-T LibriSpeech training recipe (#2329)

Summary:
Adds Conformer RNN-T LibriSpeech training recipe to examples directory.

Produces 30M-parameter model that achieves the following WER:

|                     |          WER |
|:-------------------:|-------------:|
| test-clean          |       0.0310 |
| test-other          |       0.0805 |
| dev-clean           |       0.0314 |
| dev-other           |       0.0827 |

Pull Request resolved: https://github.com/pytorch/audio/pull/2329

Reviewed By: xiaohui-zhang

Differential Revision: D35578727

Pulled By: hwangjeff

fbshipit-source-id: afa9146c5b647727b8605d104d928110a1d3976d",hwangjeff,iamjeffhwang@gmail.com,"['examples/asr/librispeech_conformer_rnnt/README.md', 'examples/asr/librispeech_conformer_rnnt/eval.py', 'examples/asr/librispeech_conformer_rnnt/global_stats.json', 'examples/asr/librispeech_conformer_rnnt/lightning.py', 'examples/asr/librispeech_conformer_rnnt/train.py', 'examples/asr/librispeech_conformer_rnnt/train_spm.py']",False,13,4,2022
fb51ceccb862c2b72a10f8663638589e46c6f24a,"Add nightly build installation code snippet to prototype feature tutorials (#2325)

Summary:
Tutorial notebooks that leverage TorchAudio prototype features don't run as-is on Google Colab due to its runtime's not having nightly builds pre-installed. To make it easier for users to run said notebooks in Colab, this PR adds a code block that installs nightly Pytorch and TorchAudio builds as a comment that users can copy and run locally.

Pull Request resolved: https://github.com/pytorch/audio/pull/2325

Reviewed By: xiaohui-zhang

Differential Revision: D35597753

Pulled By: hwangjeff

fbshipit-source-id: 59914e492ad72e31c0136a48cd88d697e8ea5f6c",hwangjeff,iamjeffhwang@gmail.com,"['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'examples/tutorials/device_asr.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streaming_api_tutorial.py']",False,13,4,2022
b0c8e239f7a00fda6370d54d1fa085f96c477a8f,"Add Conformer RNN-T model prototype (#2322)

Summary:
Adds Conformer RNN-T model as prototype feature, by way of factory functions `conformer_rnnt_model` and `conformer_rnnt_base`, which instantiates a baseline version of the model. Also includes the following:
- Modifies `Conformer` to accept arguments `use_group_norm` and `convolution_first` to pass to each of its `ConformerLayer` instances.
- Makes `_Predictor` an abstract class and introduces `_EmformerEncoder` and `_ConformerEncoder`.
- Introduces tests for `conformer_rnnt_model`.
- Adds docs.

Pull Request resolved: https://github.com/pytorch/audio/pull/2322

Reviewed By: xiaohui-zhang

Differential Revision: D35565987

Pulled By: hwangjeff

fbshipit-source-id: cb37bb0477ae3d5fcf0b7124f334f4cbb89b5789",hwangjeff,iamjeffhwang@gmail.com,"['docs/source/index.rst', 'docs/source/prototype.models.rst', 'docs/source/prototype.rst', 'test/torchaudio_unittest/prototype/rnnt_cpu_test.py', 'test/torchaudio_unittest/prototype/rnnt_gpu_test.py', 'test/torchaudio_unittest/prototype/rnnt_test_impl.py', 'torchaudio/models/conformer.py', 'torchaudio/models/rnnt.py', 'torchaudio/prototype/models/__init__.py', 'torchaudio/prototype/models/rnnt.py']",False,12,4,2022
bd319959cd504b718685e720cbd4f47408ee1835,"Fix ffmpeg integration for ffmpeg 5.0 (#2326)

Summary:
This commit makes the FFmpeg integration support FFmpeg 5.0

In FFmpeg 5, functions like `av_find_input_format` and `avformat_open_input` are changed,
so that they deal with constant version of `AVInputFormat`.

> 2021-04-27 - 56450a0ee4 - lavf 59.0.100 - avformat.h
>  Constified the pointers to AVInputFormats and AVOutputFormats
>  in AVFormatContext, avformat_alloc_output_context2(),
>  av_find_input_format(), av_probe_input_format(),
>  av_probe_input_format2(), av_probe_input_format3(),
>  av_probe_input_buffer2(), av_probe_input_buffer(),
>  avformat_open_input(), av_guess_format() and av_guess_codec().
>  Furthermore, constified the AVProbeData in av_probe_input_format(),
>  av_probe_input_format2() and av_probe_input_format3().

https://github.com/FFmpeg/FFmpeg/blob/4e6debe1df7d53f3f59b37449b82265d5c08a172/doc/APIchanges#L252-L260

Pull Request resolved: https://github.com/pytorch/audio/pull/2326

Reviewed By: carolineechen

Differential Revision: D35551380

Pulled By: mthrok

fbshipit-source-id: ccb4f713076ae8693d8d77ac2cb4ad865556a666",moto,855818+mthrok@users.noreply.github.com,['torchaudio/csrc/ffmpeg/ffmpeg.cpp'],True,11,4,2022
72ae755ab8951f08949ea53983418ecef02d85bb,"Add devices/properties badges (#2321)

Summary:
Add badges of supported properties and devices to functionals and transforms.

This commit adds `.. devices::` and `.. properties::` directives to sphinx.

APIs with these directives will have badges (based off of shields.io) which link to the
page with description of these features.

Continuation of https://github.com/pytorch/audio/issues/2316
Excluded dtypes for further improvement, and actually added badges to most of functional/transforms.

Pull Request resolved: https://github.com/pytorch/audio/pull/2321

Reviewed By: hwangjeff

Differential Revision: D35489063

Pulled By: mthrok

fbshipit-source-id: f68a70ebb22df29d5e9bd171273bd19007a81762",moto,855818+mthrok@users.noreply.github.com,"['.gitignore', 'docs/source/_static/css/custom.css', 'docs/source/conf.py', 'docs/source/custom_directives.py', 'docs/source/index.rst', 'docs/source/refs.bib', 'docs/source/supported_features.rst', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/transforms/torchscript_consistency_impl.py', 'torchaudio/functional/filtering.py', 'torchaudio/functional/functional.py', 'torchaudio/prototype/ctc_decoder/ctc_decoder.py', 'torchaudio/sox_effects/sox_effects.py', 'torchaudio/transforms/_transforms.py']",True,8,4,2022
eb23a24291f748b53b32022d8b3a021644c33a25,"Support GroupNorm and re-ordering Convolution/MHA in Conformer (#2320)

Summary:
Add an option to use GroupNorm rather than BatchNorm1d, and another option to re-order Convolution/MHA modules in Conformer model.

Pull Request resolved: https://github.com/pytorch/audio/pull/2320

Reviewed By: hwangjeff

Differential Revision: D35422112

Pulled By: xiaohui-zhang

fbshipit-source-id: 360a8aaa37b883b0f656da2e4f654e86688ac270",Xiaohui Zhang,xiaohuizhang@fb.com,['torchaudio/models/conformer.py'],True,6,4,2022
16958d5b479a87cae1715eb30a237ebba285a0ae,"Add an option to use Tanh instead of ReLU in RNNT joiner (#2319)

Summary:
Add an option to use Tanh instead of ReLU in RNNT joiner, which enables better training performance sometimes.

 ---

Pull Request resolved: https://github.com/pytorch/audio/pull/2319

Reviewed By: hwangjeff

Differential Revision: D35422122

Pulled By: xiaohui-zhang

fbshipit-source-id: c6a0f8b25936e47081110af046b57d0e8751f9a2",Xiaohui Zhang,xiaohuizhang@fb.com,['torchaudio/models/rnnt.py'],False,6,4,2022
f7afe29e45bb6767b934163c698b0ecab8df99ea,"Disable multiprocessing when dumping features in hubert preprocessing (#2311)

Summary:
The multi-processing works well on MFCC features. However, it sometimes makes the script hang when dumping HuBERT features. Change it to for-loop resolves the issue.

Pull Request resolved: https://github.com/pytorch/audio/pull/2311

Reviewed By: mthrok

Differential Revision: D35393813

Pulled By: nateanl

fbshipit-source-id: afdc14557a1102b20ecd5fafba0964a913250a11",Zhaoheng Ni,zni@fb.com,['examples/hubert/preprocess.py'],False,5,4,2022
11328d23f512949145d7dd256fd23b3125fd1cb0,"Raise error for resampling int waveform (#2318)

Summary:
Resolves https://github.com/pytorch/audio/issues/2294

Raise an error if the waveform to be resampled is not of floating point type. The `conv1d` operation used in resampling and `nn.Module` used for the transforms don't support integer type.

Pull Request resolved: https://github.com/pytorch/audio/pull/2318

Reviewed By: mthrok

Differential Revision: D35379276

Pulled By: carolineechen

fbshipit-source-id: f8f9539a051e7c3d22bcb45ca6a34aaef67abed0",Caroline Chen,carolinechen@fb.com,['torchaudio/functional/functional.py'],False,5,4,2022
66185e0074d06330dff4ea84cbface3b83312ec4,"Use pretrained LM API for decoder example (#2317)

Summary:
update example ASR pipeline to use the recently added pretrained LM API for decoding

Pull Request resolved: https://github.com/pytorch/audio/pull/2317

Reviewed By: mthrok

Differential Revision: D35361354

Pulled By: carolineechen

fbshipit-source-id: cac7cf55bd9f86417f319191c1405819fe2a7b46",Caroline Chen,carolinechen@fb.com,['examples/asr/librispeech_ctc_decoder/inference.py'],False,4,4,2022
4a749e2d7d0c40e8864d374c4eb663264bbe7a41,"Fix arguments in CTC decoding script (#2315)

Summary:
Some arguments in `ArgumentParser` are not used in the `lexicon_decoder`. Fix them to use the ones in the parser.

Pull Request resolved: https://github.com/pytorch/audio/pull/2315

Reviewed By: carolineechen

Differential Revision: D35357678

Pulled By: nateanl

fbshipit-source-id: 4e70418cf03708b82bc158cafd9999a80ad08f92",Zhaoheng Ni,zni@fb.com,['examples/asr/librispeech_ctc_decoder/inference.py'],False,4,4,2022
87f0d1989014f2da9d56a326b54507a7a1cbc712,"Fix loading checkpoint in hubert preprocessing (#2310)

Summary:
When checkpoint is on GPU device and preprocessing is on CPU, the script will throw an exception error. Fix it to load the model state dictionary into CPU by default.

Pull Request resolved: https://github.com/pytorch/audio/pull/2310

Reviewed By: mthrok

Differential Revision: D35316903

Pulled By: nateanl

fbshipit-source-id: d3e7183400ba133240aa6d205f5c671a421a9fed",Zhaoheng Ni,zni@fb.com,['examples/hubert/utils/feature_utils.py'],True,1,4,2022
3ed39e15625183447b4deb04abf3c923018db219,"Update GNU config files to support `arm64-apple` system (#2307)

Summary:
This commit
1. Updates the config.guess and config.sub files and
2. applies them to all the third party libraries that use them.

This resolves the following build failure on M1 mac with newer SDK.

On MacBookPro with M1 chip, with the recent OS update, something
about the development environment has been changed (probably newer
version of XCode) and the build stopeed working with the following
errors from third party dependencies.

```
checking build system type... Invalid configuration ‘arm64-apple-darwin20.0.0': machine ‘arm64-apple' not recognized
```

note: config files are taken from https://www.gnu.org/software/gettext/manual/html_node/config_002eguess.html

Pull Request resolved: https://github.com/pytorch/audio/pull/2307

Reviewed By: nateanl

Differential Revision: D35318273

Pulled By: mthrok

fbshipit-source-id: 746ac51dd1816767aa78b88445f76a29acfd29e8",moto,855818+mthrok@users.noreply.github.com,"['third_party/lzma/CMakeLists.txt', 'third_party/patches/config.guess', 'third_party/patches/config.sub', 'third_party/patches/libmad.patch', 'third_party/patches/sox.patch', 'third_party/sox/CMakeLists.txt']",True,1,4,2022
6a418a89cbf348db26309dc902bce44f00de2348,"Put CONDA_PREFIX second priority of ffmpeg search path (#2312)

Summary:
Change the cmake logic to search CONDA_PREFIX before falling back
to the other default paths and system paths.

1. FFMPEG_ROOT
2. CONDA_PREFIX
3. Other locations (Package managers and system paths)

For users with regular conda installation, ffmpeg from conda should
be picked automatically.
If anyone wants to specify the ffmpeg, then can set FFMPEG_ROOT
variable to the location of desired installation.

Pull Request resolved: https://github.com/pytorch/audio/pull/2312

Reviewed By: hwangjeff

Differential Revision: D35317383

Pulled By: mthrok

fbshipit-source-id: 52aef8f3f7f0f8f1eaf7a89a2d1ccfb6265e2c50",moto,855818+mthrok@users.noreply.github.com,['cmake/FindFFMPEG.cmake'],True,1,4,2022
72f9a4e31ed4d439ead894ec07b9f452b8232ad7,"Refactor the internal of transforms module (#2309)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2309

For upcoming improved Kaldi features which are comprised of multiple classes / functions, put all the transforms implementations in dedicated directory.

Reviewed By: nateanl

Differential Revision: D35303682

fbshipit-source-id: 5bc8c07ef639683008c0f76ffe56e3941f772659",Moto Hira,moto@fb.com,"['torchaudio/transforms/__init__.py', 'torchaudio/transforms/_transforms.py']",True,1,4,2022
d65a0f3e5422e2cd63572c6c6cd6a0f77b567d20,"Loosen atol for melscale batch test for Windows (#2305)

Summary:
The `transforms.batch_consistency_test.TestTransforms` test is failing for Windows.

https://app.circleci.com/pipelines/github/pytorch/audio/10093/workflows/bbe003c4-3dfa-4729-a3e1-c942ab1243d4/jobs/594272

```
>       self.assertEqual(items_result, batch_result, rtol=rtol, atol=atol)
E       AssertionError: Tensor-likes are not close!
E
E       Mismatched elements: 28 / 196608 (0.0%)
E       Greatest absolute difference: 2.0023435354232788e-07 at index (1, 1, 127, 100) (up to 1e-08 allowed)
E       Greatest relative difference: 0.0005069057444598896 at index (0, 0, 114, 129) (up to 1e-05 allowed)
```

The value of atol==1e-08 seems very strict but all the other batch
consistency tests are passing.

The violation is for very small number of samples, which looks
suspicious, but I think it is okay to reduce it to `1e-06` for Windows.

`1e-06` is still more strict than the majority of the comparison tests we have.

Pull Request resolved: https://github.com/pytorch/audio/pull/2305

Reviewed By: hwangjeff

Differential Revision: D35298056

Pulled By: mthrok

fbshipit-source-id: a7d20f408c16cff7d363f4a9462c64e19d1c99f7",moto,855818+mthrok@users.noreply.github.com,['test/torchaudio_unittest/transforms/batch_consistency_test.py'],True,1,4,2022
c6c6b6896bf70c7d9c854d3602e519b902d436f9,"Randomize initial phase of sinusoid data in test (#2301)

Summary:
This commit update `get_sinusoid` function in test utility so that
when a multi channel is requested, non-primal channel have randomized
initial phase.

This adds some variety in test data which should not break the tests.
Currently `get_sinusoid` returns identical waveforms for all the channels.
This multi channel support was added just to mock the input data so that
it is easy to test features with multi-channel inputs, so tests should not be
expecting the all channels to be identical.

When working on numerical parity, it is more useful if the raw waveforms
are somewhat different.

Image: waveforms generated by `get_sinusoid` after the change. left: 1st channel, right: 2nd channel
<img width=""524"" alt=""Screen Shot 2022-03-31 at 10 06 17 AM"" src=""https://user-images.githubusercontent.com/855818/161111163-1ea58ff6-51ee-4e37-bcd6-411041dd2603.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2301

Reviewed By: hwangjeff

Differential Revision: D35291689

Pulled By: mthrok

fbshipit-source-id: 9160d07ccdd1494acb6d41cb07ac434c0676dbfd",moto,855818+mthrok@users.noreply.github.com,['test/torchaudio_unittest/common_utils/data_utils.py'],False,31,3,2022
ec552b69453989ad02b6527451c5148fb739a89b,"Move Kaldi comp tests to corresponding module (#2303)

Summary:
Tests on `torchaudio.compliance.kaldi` were scattered at different places.
This commit put all of them in dedicated `test/torchaudio_unittest/compliance/kaldi/`
directory.

Pull Request resolved: https://github.com/pytorch/audio/pull/2303

Reviewed By: nateanl

Differential Revision: D35288400

Pulled By: mthrok

fbshipit-source-id: 1426f236bc7786539d7a3110f992ad6220a52f46",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/compliance/__init__.py', 'test/torchaudio_unittest/compliance/kaldi/__init__.py', 'test/torchaudio_unittest/compliance/kaldi/kaldi_compatibility_cpu_test.py', 'test/torchaudio_unittest/compliance/kaldi/kaldi_compatibility_cuda_test.py', 'test/torchaudio_unittest/compliance/kaldi/kaldi_compatibility_impl.py', 'test/torchaudio_unittest/compliance/kaldi/legacy_test.py']",False,31,3,2022
050b2fb4f6aac1b52413297d362181244dd2b8ff,"Use zlib v1.2.12 with GitHub source (#2300)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2300

Reviewed By: xiaohui-zhang

Differential Revision: D35258323

Pulled By: nateanl

fbshipit-source-id: 4b9f86600399ba0f5ec47f1c402968a812aa557d",Zhaoheng Ni,zni@fb.com,['third_party/zlib/CMakeLists.txt'],False,30,3,2022
cfa5a383d5edcd0a5d7ee4fbd0fec2a077c9e6f5,"make sure inputs live on CPU for ctc decoder (#2289)

Summary:
Addressing the issue https://github.com/pytorch/audio/issues/2274:
Raise Runtime errors when the input tensors to the CTC decoder are GPU tensors since the CTC decoder only runs on CPU. Also update the data type check to use ""raise"" rather than ""assert"".

 ---
Pull Request resolved: https://github.com/pytorch/audio/pull/2289

Reviewed By: mthrok

Differential Revision: D35255630

Pulled By: xiaohui-zhang

fbshipit-source-id: d6c6e88d9ad4b9690bb741557fa9a9504e60872e",Xiaohui Zhang,xiaohuizhang@fb.com,['torchaudio/prototype/ctc_decoder/ctc_decoder.py'],False,30,3,2022
03badcd3e91c7f54ec42f0b13c675070ef40c016,"Use sourceforge url to fetch zlib (#2297)

Summary:
This PR addresses https://github.com/pytorch/audio/issues/2295 by updating `zlib`'s url to the one on sourceforge.net.
`zlib` 1.2.11 source code is removed from the official site. According to https://zlib.net, ```Due to the bug fixes, any installations of 1.2.11 should be replaced with 1.2.12.```
sourceforge preserves the older versions thus is more stable. The PR keep 1.2.11 as currently there is no 1.2.12 on sourceforge.

Pull Request resolved: https://github.com/pytorch/audio/pull/2297

Reviewed By: mthrok

Differential Revision: D35251361

Pulled By: nateanl

fbshipit-source-id: 174c2c2e1c34bef9799bbacfd1e12c8ff13ff15d",Zhaoheng Ni,zni@fb.com,['third_party/zlib/CMakeLists.txt'],False,30,3,2022
46ed2b98bc4227f12237f14833380f48c015cf8c,"Update decoder pretrained lm docs (#2291)

Summary:
`build_docs` test is failing on CI with `ImportError: cannot import name 'environmentfilter' from 'jinja2'`, but with local build:

<img width=""902"" alt=""Screen Shot 2022-03-25 at 4 02 53 PM"" src=""https://user-images.githubusercontent.com/16568633/160157472-c91ff9b2-a2be-4c5d-959e-53b9f45425c6.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2291

Reviewed By: mthrok

Differential Revision: D35147098

Pulled By: carolineechen

fbshipit-source-id: 682b3800d0ed5c56b402d83f221136725051ba7e",Caroline Chen,carolinechen@fb.com,"['docs/source/prototype.ctc_decoder.rst', 'torchaudio/prototype/ctc_decoder/ctc_decoder.py']",False,26,3,2022
21c1ab7ec3147b345a0cb55ce36237fdd619cc31,"Update README around version compatibility matrix (#2293)

Summary:
Following the issue https://github.com/pytorch/text/issues/1662, add more clarification on LTS.
Also tidy up a bit by moving older versions in to details.

cc Nayef211

 ---

<img width=""794"" alt=""Screen Shot 2022-03-25 at 2 30 49 PM"" src=""https://user-images.githubusercontent.com/855818/160203327-acc5cbcb-ca86-43ee-b59f-48795b9e676c.png"">

Pull Request resolved: https://github.com/pytorch/audio/pull/2293

Reviewed By: hwangjeff

Differential Revision: D35159211

Pulled By: mthrok

fbshipit-source-id: 18908c62440fc02773634c2700020fc407893dd3",moto,855818+mthrok@users.noreply.github.com,['README.md'],False,25,3,2022
d484516ecb53353b576dec16f004d44480c5c57d,"Pin jinja2 version for build_docs (#2292)

Summary:
`build_docs` CircleCI currently failing with `ImportError: cannot import name 'environmentfilter' from 'jinja2'`. Pin Jinja2<3.1 to resolve this issue, see https://github.com/sphinx-doc/sphinx/issues/10291#issuecomment-1078046986

Pull Request resolved: https://github.com/pytorch/audio/pull/2292

Reviewed By: mthrok

Differential Revision: D35148397

Pulled By: carolineechen

fbshipit-source-id: 963efe2fcdee13dead4a4d542c903913c6eaa505",Caroline Chen,carolinechen@fb.com,['docs/requirements.txt'],False,25,3,2022
34c0d1154da1dfd8e5442e01f95be8e59731c174,"Add Pretrained LM Support for Decoder (#2275)

Summary:
add function to download pretrained files for LibriSpeech 3-gram/4-gram KenLM, tests, and updated tutorial

Pull Request resolved: https://github.com/pytorch/audio/pull/2275

Reviewed By: mthrok

Differential Revision: D35115418

Pulled By: carolineechen

fbshipit-source-id: 83ff22380fce9c753bb4a7b7e3d89aa66c2831c0",Caroline Chen,carolinechen@fb.com,"['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'test/integration_tests/conftest.py', 'test/integration_tests/prototype/ctc_decoder_integration_test.py', 'torchaudio/prototype/ctc_decoder/__init__.py', 'torchaudio/prototype/ctc_decoder/ctc_decoder.py']",False,25,3,2022
05592dffe8a582db1cfdfe3ed46f351b935b3fad,"Update CTC decoder docs and add citation (#2278)

Summary:
rendered:
- [tutorial](https://output.circle-artifacts.com/output/job/e7fb5a23-87cf-4dd5-b4a8-8b4f91e20eb4/artifacts/0/docs/tutorials/asr_inference_with_ctc_decoder_tutorial.html)
- [docs](https://output.circle-artifacts.com/output/job/e7fb5a23-87cf-4dd5-b4a8-8b4f91e20eb4/artifacts/0/docs/prototype.ctc_decoder.html)

Pull Request resolved: https://github.com/pytorch/audio/pull/2278

Reviewed By: mthrok

Differential Revision: D35097734

Pulled By: carolineechen

fbshipit-source-id: 1e5d5fff0b7740757cca358cf3ea44c6488fcd5c",Caroline Chen,carolinechen@fb.com,"['docs/source/prototype.ctc_decoder.rst', 'docs/source/refs.bib', 'examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'torchaudio/prototype/ctc_decoder/ctc_decoder.py']",False,24,3,2022
8844fbb78daf755e75a61029b01d9c8a5b107fb7,"Add notes about prototype features in tutorials (#2288)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2288

Reviewed By: hwangjeff

Differential Revision: D35099492

Pulled By: mthrok

fbshipit-source-id: 955c5e617469009ae2600d2764d601d794ee916f",moto,855818+mthrok@users.noreply.github.com,"['examples/tutorials/asr_inference_with_ctc_decoder_tutorial.py', 'examples/tutorials/online_asr_tutorial.py', 'examples/tutorials/streaming_api_tutorial.py']",False,24,3,2022
7444f56819f679f68eee8bf915bbb74be3da0e40,"Revise the parameterization of third party libraries (#2282)

Summary:
Originally, the global property TORCHAUDIO_THIRD_PARTIES was introduced
to handle the optional third party dependencies that can change based on
the build config.

After revising the CMake, it turned out this is not really necessary,
as our torchaudio/csrc/CMakeLists.txt properly branches out for
conditional dependencies. Rather we should leave the global scope untouched.

Pull Request resolved: https://github.com/pytorch/audio/pull/2282

Reviewed By: hwangjeff

Differential Revision: D35059838

Pulled By: mthrok

fbshipit-source-id: ed3557eaa9a669e4466d64893beab5089eca78b8",moto,855818+mthrok@users.noreply.github.com,"['third_party/CMakeLists.txt', 'torchaudio/csrc/CMakeLists.txt']",False,22,3,2022
64b98521431b8491c49f63e31e8501aa0b2a988b,"Add download utility specialized for torchaudio (#2283)

Summary:
In recent updates, torchaudio added features that download assets/models from
download.pytorch.org/torchaudio.

To reduce the code duplication, the implementations uses utilities from
``torch.hub``, but still, there are patterns repeated in implementing
the fetch mechanism, notably cache and local file path handling.

This commit introduces the utility function that handles
download/cache/local path management that can be used for
fetching pre-trained model data.

Pull Request resolved: https://github.com/pytorch/audio/pull/2283

Reviewed By: carolineechen

Differential Revision: D35050469

Pulled By: mthrok

fbshipit-source-id: 219dd806f9a96c54d2d31e981c1bbe282772702b",moto,855818+mthrok@users.noreply.github.com,"['test/integration_tests/conftest.py', 'torchaudio/pipelines/rnnt_pipeline.py', 'torchaudio/utils/__init__.py', 'torchaudio/utils/download.py']",False,22,3,2022
8395fe65a676471eafaa55e8c2ce9f303093ce70,"Fix calculation of SNR value in tutorial (#2285)

Summary:
The calculation of the SNR in tha data augmentation examples seems to be wrong to me:

![image](https://user-images.githubusercontent.com/173624/159487032-c60470c6-ef8e-48a0-ad5e-a117fcb8d606.png)

If we start from the definition of the signal-to-noise ratio using the root mean square value we get:

```
SNR = 20 log10 ( rms(scale * speech) / rms(noise) )
```
this can be transformed to
```
scale = 10^(SNR/20) rms(noise) / rms(speech)
```
In the example not `rms` is used but `lambda x: x.norm(p=2)`, but as we have the same length of the speech and noise signal, we have
```
rms(noise) / rms(speech) = noise.norm(p=2) / speech.norm(p=2)
```
this would lead us to:
```
10^(SNR/20) = e^(SNR / 10)
```
which is not true.

Hence I changed `e^(SNR / 10)` to `10^(SNR/20)`.

For the proposed SNR values of 20 dB, 10 dB, 3 dB the value of the scale would change from 7.39, 2.72, 1.35 to 10.0, 3.16, 1.41.

Pull Request resolved: https://github.com/pytorch/audio/pull/2285

Reviewed By: nateanl

Differential Revision: D35047737

Pulled By: mthrok

fbshipit-source-id: ac24c8fd48ef06b4b611e35163084644330a3ef3",Hagen Wierstorf,hwierstorf@audeering.com,['examples/tutorials/audio_data_augmentation_tutorial.py'],False,22,3,2022
1c3403ea5fc5ae42d2108421521f122047877737,"[Doc] fix typo and backlink (#2281)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2281

Reviewed By: carolineechen

Differential Revision: D34939494

Pulled By: mthrok

fbshipit-source-id: e97100b95a8e3d3e28805d8fab43b66120c2254d",moto,855818+mthrok@users.noreply.github.com,"['examples/tutorials/audio_feature_extractions_tutorial.py', 'torchaudio/datasets/cmuarctic.py']",True,17,3,2022
4b47412e91c22d75a1d5f4ea5f71e0ceaa26efd7,"Fix typos and remove comments (#2270)

Summary:
Follo-up on post-commit review from https://github.com/pytorch/audio/issues/2202

Pull Request resolved: https://github.com/pytorch/audio/pull/2270

Reviewed By: hwangjeff

Differential Revision: D34793460

Pulled By: mthrok

fbshipit-source-id: 039ddeca015fc77b89c571820b7ef2b0857f5723",moto,855818+mthrok@users.noreply.github.com,"['examples/tutorials/device_asr.py', 'torchaudio/csrc/ffmpeg/streamer.cpp', 'torchaudio/prototype/io/streamer.py']",False,10,3,2022
8a88519140ce7771145508c066729e208a3e32ad,"Fix type for lm parameter in decoder (#2273)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2273

Reviewed By: mthrok

Differential Revision: D34799335

Pulled By: carolineechen

fbshipit-source-id: d0eea79448efdbd84758a3f433ab9350b4c94e91",Caroline Chen,carolinechen@fb.com,['torchaudio/prototype/ctc_decoder/ctc_decoder.py'],False,10,3,2022
ee68fcc54ef1600625441734b499240c427394c7,"Update version table in README (#2272)

Summary:
Add torchaudio 0.11.0 version to the table.

Pull Request resolved: https://github.com/pytorch/audio/pull/2272

Reviewed By: carolineechen

Differential Revision: D34790836

Pulled By: nateanl

fbshipit-source-id: af9ec1a4b470b04b793f39d12dbf722d67c62fce",Zhaoheng Ni,zni@fb.com,['README.md'],False,10,3,2022
c4f12526512675b4522481b48661639d1bd52889,"Add HuBERT-feature support in preprocessing of HuBERT training (#2143)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2143

Reviewed By: carolineechen

Differential Revision: D34722238

Pulled By: nateanl

fbshipit-source-id: 72809c9db91c94d8e853c80ed8522eeffe5ff136",Zhaoheng Ni,zni@fb.com,"['examples/hubert/preprocess.py', 'examples/hubert/train.py', 'examples/hubert/utils/feature_utils.py', 'examples/hubert/utils/kmeans.py']",False,8,3,2022
a92ae3688afad51245d135a3f361fb7e20364d6d,"Fix Kaldi submodule integration (#2269)

Summary:
When building Kaldi submodule, it requires to run `get_version.sh`, so that version header is available.
It was pointed that the script should run with `bash`, instead of `sh`.

Fixes https://github.com/pytorch/audio/issues/2268

Pull Request resolved: https://github.com/pytorch/audio/pull/2269

Reviewed By: carolineechen

Differential Revision: D34667726

Pulled By: mthrok

fbshipit-source-id: 761b82c54b58af2bfb2836cbe18c9708f853f1e1",moto,855818+mthrok@users.noreply.github.com,['third_party/kaldi/CMakeLists.txt'],False,6,3,2022
7e1afc4073e4cc3a06a77af900283ecfe0dbca07,"Flush and reset internal state after seek (#2264)

Summary:
This commit adds the following behavior to `seek` so that `seek`
works after a frame is decoded.

1. Flush the decoder buffer.
2. Recreate filter graphs (so that internal state is re-initialized)
3. Discard the buffered tensor. (decoded chunks)

Also it disallows negative values for seek timestamp.

Pull Request resolved: https://github.com/pytorch/audio/pull/2264

Reviewed By: carolineechen

Differential Revision: D34497826

Pulled By: mthrok

fbshipit-source-id: 8b9a5bf160dfeb15f5cced3eed2288c33e2eb35d",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/prototype/io_test.py', 'torchaudio/csrc/ffmpeg/buffer.cpp', 'torchaudio/csrc/ffmpeg/buffer.h', 'torchaudio/csrc/ffmpeg/decoder.cpp', 'torchaudio/csrc/ffmpeg/decoder.h', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp', 'torchaudio/csrc/ffmpeg/ffmpeg.h', 'torchaudio/csrc/ffmpeg/filter_graph.cpp', 'torchaudio/csrc/ffmpeg/filter_graph.h', 'torchaudio/csrc/ffmpeg/sink.cpp', 'torchaudio/csrc/ffmpeg/sink.h', 'torchaudio/csrc/ffmpeg/stream_processor.cpp', 'torchaudio/csrc/ffmpeg/stream_processor.h', 'torchaudio/csrc/ffmpeg/streamer.cpp']",False,4,3,2022
04875eef1487ffb839610e881f8f01de90009246,"Make Streamer fail if an invalid option is provided (#2263)

Summary:
`torchaudio.prototype.io.Streamer` class takes context dependant options
as `option` argument in the form of mappings of strings.

Currently there is no check if the provided options were valid for
the given input.

This commit adds the check and raise an error if an invalid erro is given.

This is analogous to `ffmpeg` command error handling.

```
$ ffmpeg -foo
...
Unrecognized option 'foo'.
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2263

Reviewed By: hwangjeff

Differential Revision: D34495111

Pulled By: mthrok

fbshipit-source-id: cd068de0dc1d1273bdd5d40312c3faccb47b253f",moto,855818+mthrok@users.noreply.github.com,"['test/torchaudio_unittest/common_utils/parameterized_utils.py', 'test/torchaudio_unittest/prototype/io_test.py', 'torchaudio/csrc/ffmpeg/ffmpeg.cpp']",False,4,3,2022
17c6af7f24b72228a608ae3f60ca4b57954497a5,"Simplify setup_env.sh (#2265)

Summary:
Make them more aligned with ones in
https://github.com/pytorch/vision/blob/main/.circleci/unittest/linux/scripts/setup_env.sh

This is preliminary step towards eradicating unneeded conda-forge dependencies, see https://github.com/pytorch/audio/pull/2260

Pull Request resolved: https://github.com/pytorch/audio/pull/2265

Reviewed By: mthrok

Differential Revision: D34499635

Pulled By: malfet

fbshipit-source-id: f87a3e4568aeeab9c6787a777c3231153c4539f0",Nikita Shulga,nshulga@fb.com,"['.circleci/unittest/linux/scripts/setup_env.sh', '.circleci/unittest/windows/scripts/setup_env.sh']",True,27,2,2022
955ffb477ae495fe952b88809a8e548595fad531,"Enable ffmpeg prototyep unit test (#2261)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2261

Enables prototype ffmpeg io tests in fbcode.

Reviewed By: nateanl

Differential Revision: D33698353

fbshipit-source-id: 61de997c564135e677cd68e34fd7cc5dc0c5e036",Moto Hira,moto@fb.com,['test/torchaudio_unittest/common_utils/case_utils.py'],False,26,2,2022
9c56ffb41ddf836d2ad8156fb76596f79096f8c9,"Add apply_beamforming to torchaudio.functional (#2232)

Summary:
This PR adds ``apply_beamforming`` method to ``torchaudio.functional``.
The method employs the beamforming weight to the multi-channel noisy spectrum to obtain the single-channel enhanced spectrum.
The input arguments are the complex-valued beamforming weight Tensor and the multi-channel noisy spectrum.

Pull Request resolved: https://github.com/pytorch/audio/pull/2232

Reviewed By: mthrok

Differential Revision: D34474561

Pulled By: nateanl

fbshipit-source-id: 2910251a8f111e65375dfb50495b6a415113f06d",Zhaoheng Ni,zni@fb.com,"['docs/source/functional.rst', 'test/torchaudio_unittest/common_utils/beamform_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py']",True,26,2,2022
365313edd2658e5d048d97fad04c7729deb9815b,"Improve device streaming (#2202)

Summary:
This commit adds tutorial for device ASR, and update API for device streaming.

The changes for the interface are
1. Add `timeout` and `backoff` parameters to `process_packet` and `stream` methods.
2. Move `fill_buffer` method to private.

When dealing with device stream, there are situations where the device buffer is not
ready and the system returns `EAGAIN`. In such case, the previous implementation of
`process_packet` method raised an exception in Python layer , but for device ASR,
this is inefficient. A better approach is to retry within C++ layer in blocking manner.
The new `timeout` parameter serves this purpose.

Pull Request resolved: https://github.com/pytorch/audio/pull/2202

Reviewed By: nateanl

Differential Revision: D34475829

Pulled By: mthrok

fbshipit-source-id: bb6d0b125d800f87d189db40815af06fbd4cab59",moto,855818+mthrok@users.noreply.github.com,"['docs/source/_templates/layout.html', 'docs/source/index.rst', 'examples/tutorials/device_asr.py', 'examples/tutorials/streaming_api_tutorial.py', 'torchaudio/csrc/ffmpeg/prototype.cpp', 'torchaudio/csrc/ffmpeg/streamer.cpp', 'torchaudio/csrc/ffmpeg/streamer.h', 'torchaudio/prototype/io/streamer.py']",True,26,2,2022
ea74813d63d496a7b05f02c8bd561df8ada00083,"Add rtf_power method to torchaudio.functional (#2231)

Summary:
This PR adds ``rtf_power`` method to ``torchaudio.functional``.
The method computes the relative transfer function (RTF) or the steering vector by [the power iteration method](https://onlinelibrary.wiley.com/doi/abs/10.1002/zamm.19290090206).
[This paper](https://arxiv.org/pdf/2011.15003.pdf) describes the power iteration method in English.
The input arguments are the complex-valued power spectral density (PSD) matrix of the target speech, PSD matrix of noise, int or one-hot Tensor to indicate the reference channel, number of iterations, respectively.

Pull Request resolved: https://github.com/pytorch/audio/pull/2231

Reviewed By: mthrok

Differential Revision: D34474503

Pulled By: nateanl

fbshipit-source-id: 47011427ec4373f808755f0e8eff1efca57655eb",Zhaoheng Ni,zni@fb.com,"['docs/source/functional.rst', 'test/torchaudio_unittest/common_utils/beamform_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py']",True,25,2,2022
8c1db721135e61d4a3dfbc4e2bbe05cd50cfded1,"ci: Limit scope of unittest to one python version (#2256)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2256

Limits scope of unittesting to one python version for both macOS and
Windows. These types of workflows are particularly expensive and take a
long time so running them on every PR / every push is a bit wasteful
considering the value in signal between different python versions is
probably negligible.

Signed-off-by: Eli Uriegas <eliuriegas@fb.com>

Test Plan: Imported from OSS

Reviewed By: mthrok

Differential Revision: D34459626

Pulled By: seemethere

fbshipit-source-id: 47f5c317027f1b395edf9c1720b1b33ba689cad5",Eli Uriegas,eliuriegas@fb.com,"['.circleci/config.yml', '.circleci/regenerate.py']",True,25,2,2022
86fe4fa756d9e46d6fa1102bcca46836093f72b8,"Add rtf_evd method to torchaudio.functional (#2230)

Summary:
This PR adds `rtf_evd` method to `torchaudio.functional`.
The method computes the relative transfer function (RTF) or the steering vector by eigenvalue decomposition.
The input argument is the power spectral density (PSD) matrix of the target speech.

Pull Request resolved: https://github.com/pytorch/audio/pull/2230

Reviewed By: mthrok

Differential Revision: D34474188

Pulled By: nateanl

fbshipit-source-id: 888df4b187608ed3c2b7271b34d2231cdabb0134",Zhaoheng Ni,zni@fb.com,"['docs/source/functional.rst', 'test/torchaudio_unittest/common_utils/beamform_utils.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py']",False,25,2,2022
3566ffc5486b29975a8a5b1f670677b36664114b,"Add mvdr_weights_rtf to torchaudio.functional (#2229)

Summary:
This PR adds ``mvdr_weights_rtf`` method to ``torchaudio.functional``.
It computes the MVDR weight matrix based on the solution that applies relative transfer function (RTF). See [the paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.725.673&rep=rep1&type=pdf) for the reference.
The input arguments are the complex-valued RTF Tensor of the target speech, power spectral density (PSD) matrix of noise, int or one-hot Tensor to indicate the reference channel, respectively.

Pull Request resolved: https://github.com/pytorch/audio/pull/2229

Reviewed By: mthrok

Differential Revision: D34474119

Pulled By: nateanl

fbshipit-source-id: 2d6f62cd0858f29ed6e4e03c23dcc11c816204e2",Zhaoheng Ni,zni@fb.com,"['docs/source/functional.rst', 'test/torchaudio_unittest/common_utils/beamform_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py']",True,25,2,2022
5d06a369944c28d621ce339cd4cfbec65caa3848,"Add mvdr_weights_souden to torchaudio.functional (#2228)

Summary:
This PR adds ``mvdr_weights_souden`` method to ``torchaudio.functional``.
It computes the MVDR weight matrix based on the solution proposed by [``Souden et, al.``](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.725.673&rep=rep1&type=pdf).
The input arguments are the complex-valued power spectral density (PSD) matrix of the target speech, PSD matrix of noise, int or one-hot Tensor to indicate the reference channel, respectively.

Pull Request resolved: https://github.com/pytorch/audio/pull/2228

Reviewed By: mthrok

Differential Revision: D34474018

Pulled By: nateanl

fbshipit-source-id: 725df812f8f6e6cc81cc37e8c3cb0da2ab3b74fb",Zhaoheng Ni,zni@fb.com,"['docs/source/functional.rst', 'docs/source/refs.bib', 'test/torchaudio_unittest/common_utils/beamform_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py']",False,25,2,2022
07bd1aa3843949df2c4c34da12be0a34926785dc,"Add psd method to torchaudio.functional (#2227)

Summary:
This PR adds ``psd`` method to ``torchaudio.functional``.
It computes the power spectral density (PSD) matrix of the complex-valued spectrum.
The method also supports normalization of Time-Frequency mask.

Pull Request resolved: https://github.com/pytorch/audio/pull/2227

Reviewed By: mthrok

Differential Revision: D34473908

Pulled By: nateanl

fbshipit-source-id: c1cfc584085d77881b35d41d76d39b26fca1dda9",Zhaoheng Ni,zni@fb.com,"['docs/source/functional.rst', 'test/torchaudio_unittest/common_utils/beamform_utils.py', 'test/torchaudio_unittest/functional/autograd_impl.py', 'test/torchaudio_unittest/functional/batch_consistency_test.py', 'test/torchaudio_unittest/functional/functional_impl.py', 'test/torchaudio_unittest/functional/torchscript_consistency_impl.py', 'torchaudio/functional/__init__.py', 'torchaudio/functional/functional.py']",False,25,2,2022
34b53ee70fbb2735798ba58b43db705ffdbbe41a,"Update release notes retrieve PRs script (#2257)

Summary:
as discussed offline w/ nateanl, cherry-picked PRs are currently being included when retrieving PRs between a release branch and newer commits. this PR fixes this by removing duplicates in the commit paths

Pull Request resolved: https://github.com/pytorch/audio/pull/2257

Reviewed By: nateanl

Differential Revision: D34459533

Pulled By: carolineechen

fbshipit-source-id: 3497c1d2dca6f8067e2068146a6e28cce591d3c8",Caroline Chen,carolinechen@fb.com,['tools/release_notes/retrieve_prs.py'],False,24,2,2022
20488dd83b45cd2623f19f39d6f2f2eee5255814,"Fix style check (#2258)

Summary:
fix a style check failure from internal diff

Pull Request resolved: https://github.com/pytorch/audio/pull/2258

Reviewed By: nateanl

Differential Revision: D34459526

Pulled By: carolineechen

fbshipit-source-id: d0e6782b5689c3bf63214a4ec6a75dd757678e0d",Caroline Chen,carolinechen@fb.com,['examples/source_separation/lightning_train.py'],True,24,2,2022
f6585d9e2b72204a70f1e0d508c50c9c2b11709a,"ci: Remove CUDA 11.1 from CI (#2259)

Summary:
Pull Request resolved: https://github.com/pytorch/audio/pull/2259

We're deprecating support for CUDA 11.1 binaries since CUDA 11.3 should
be forwards compatible with CUDA 11.1 drivers

Signed-off-by: Eli Uriegas <eliuriegas@fb.com>

Test Plan: Imported from OSS

Reviewed By: atalman

Differential Revision: D34458400

Pulled By: seemethere

fbshipit-source-id: 105d96a9a175a94d85ffe6e9abcce3c77163a72f",Eli Uriegas,eliuriegas@fb.com,"['.circleci/config.yml', '.circleci/regenerate.py']",True,24,2,2022
27dff6ba2e0711d7b30b7f9e767587dd4c76c641,"Add Python 3.10 (build and test) (#2224)

Summary:
Adding py3.10 to audio

Pull Request resolved: https://github.com/pytorch/audio/pull/2224

Reviewed By: malfet, atalman, mthrok

Differential Revision: D34442377

Pulled By: seemethere

fbshipit-source-id: 2656de73427063958d609a74c01b526a476cb06a",Andrey Talman,atalman@fb.com,"['.circleci/config.yml', '.circleci/config.yml.in', '.circleci/regenerate.py', '.circleci/unittest/linux/scripts/install.sh', '.circleci/unittest/linux/scripts/setup_env.sh', '.circleci/unittest/windows/scripts/install.sh', '.circleci/unittest/windows/scripts/setup_env.sh', 'packaging/build_conda.sh', 'packaging/pkg_helpers.bash', 'packaging/torchaudio/meta.yaml', 'test/torchaudio_unittest/common_utils/__init__.py', 'test/torchaudio_unittest/common_utils/case_utils.py', 'test/torchaudio_unittest/models/tacotron2/model_test_impl.py']",False,24,2,2022
1fb1007716378822c97d902704b4b5a8015180be,"[lightning] Replace deprecated DDP accelerator with ddp_find_unused_parameters_false

Summary: We proactively remove references to the deprecated DDP accelerator to prepare for the breaking changes following the release of PyTorch Lighting 1.6 (see T112240890).

Differential Revision: D34295318

fbshipit-source-id: 7b2245ca9c7c2900f510722b33af8d8eeda49919",Binh Tang,binhtang@fb.com,['examples/source_separation/lightning_train.py'],False,23,2,2022
cbf1b8392341c61ea1db9daf81556b207e2cf9eb,"Apply minor fixes to Emformer implementation (#2252)

Summary:
Noticed some items to clean up in `Emformer`.
- Make `segment_length` a required argument in `_EmformerLayer`.
- Remove unused variables from `_unpack_state` and `_gen_attention_mask`.

These don't affect `Emformer`'s functionality or public API.

Pull Request resolved: https://github.com/pytorch/audio/pull/2252

Reviewed By: carolineechen, mthrok

Differential Revision: D34321430

Pulled By: hwangjeff

fbshipit-source-id: 38a5046f633a3e625352c476ef71c78380ccc597",hwangjeff,iamjeffhwang@gmail.com,['torchaudio/models/emformer.py'],False,18,2,2022
3184aebceedfafc7e62089d424914e4670728faa,"Update release notes labeling (#2249)

Summary:
- fix retrieve PR script to handle commits with unrecognized/invalid PR numbers, such as in 7b6b2d000023e2aa3365b769866c5f375e0d5fda
- add modifications similar to pytorch's [#71917](https://github.com/pytorch/pytorch/pull/71917), [#72085](https://github.com/pytorch/pytorch/pull/72085)

Pull Request resolved: https://github.com/pytorch/audio/pull/2249

Reviewed By: nateanl, mthrok

Differential Revision: D34304210

Pulled By: carolineechen

fbshipit-source-id: 245784219317e355b5cece4a139dee71d65bfdd1",Caroline Chen,carolinechen@fb.com,"['.github/process_commit.py', '.github/workflows/pr-labels.yml', 'tools/release_notes/retrieve_prs.py']",False,18,2,2022
9cf59e751a3762225b87859fdaea014b89eb2292,"Refactor batch consistency test in functional (#2245)

Summary:
In batch_consistency tests, the `assert_batch_consistency` method only accepts single Tensor, which is not applicable to some methods. For example, `lfilter` and `filtfilt` requires three Tensors as the arguments, hence they don't follow `assert_batch_consistency` in the tests.
This PR refactors the test to accept a tuple of Tensors which have `batch` dimension. For the other arguments like `int` or `str`, they are given as `*args` after the tuple.

Pull Request resolved: https://github.com/pytorch/audio/pull/2245

Reviewed By: mthrok

Differential Revision: D34273035

Pulled By: nateanl

fbshipit-source-id: 0096b4f062fb4e983818e5374bed6efc7b15b056",Zhaoheng Ni,zni@fb.com,['test/torchaudio_unittest/functional/batch_consistency_test.py'],True,17,2,2022
27a6dccc68d138860d8e392f80ebaf856b187f21,"Update the main version to 0.12.0 (#2250)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2250

Reviewed By: mthrok

Differential Revision: D34302192

Pulled By: nateanl

fbshipit-source-id: 4ea7047503ef87e22b5ef6075ad010314d5e3885",Zhaoheng Ni,zni@fb.com,"['packaging/build_conda.sh', 'packaging/build_wheel.sh', 'setup.py']",True,17,2,2022
b5d77b15273aacf494a1bb16a214dbb9fd0e7ec6,"Add unit tests for PyTorch Lightning modules of emformer_rnnt recipes (#2240)

Summary:
- Refactor the current `LibriSpeechRNNTModule`'s unit test.
- Add unit tests for `TEDLIUM3RNNTModule` and `MuSTCRNNTModule`
- Replace the lambda with partial in `TEDLIUM3RNNTModule` to pass the lightning unit test.

Pull Request resolved: https://github.com/pytorch/audio/pull/2240

Reviewed By: mthrok

Differential Revision: D34285195

Pulled By: nateanl

fbshipit-source-id: 4f20749c85ddd25cbb0eafc1733c64212542338f",Zhaoheng Ni,zni@fb.com,"['examples/asr/emformer_rnnt/tedlium3/lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_librispeech_lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_mustc_lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/test_tedlium3_lightning.py', 'test/torchaudio_unittest/example/emformer_rnnt/utils.py', 'torchaudio/pipelines/rnnt_pipeline.py', 'torchaudio/prototype/pipelines/rnnt_pipeline.py']",True,17,2,2022
c5c4bbfd22773b114e2f86b3b1a16a29098188a2,"Update online ASR tutorial (#2226)

Summary:
https://554729-90321822-gh.circle-artifacts.com/0/docs/tutorials/online_asr_tutorial.html

1. Add figure to explain the caching
2. Fix the initialization of stream iterator

Pull Request resolved: https://github.com/pytorch/audio/pull/2226

Reviewed By: carolineechen

Differential Revision: D34265971

Pulled By: mthrok

fbshipit-source-id: 243301e74c4040f4b8cd111b363e70da60e5dae4",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/online_asr_tutorial.py'],False,17,2,2022
38569ef02d259741cb8ebc47bf7979ea43ab3616,"Add EMFORMER_RNNT_BASE_MUSTC into pipeline demo script (#2248)

Summary:
This PR adds ``EMFORMER_RNNT_BASE_MUSTC`` support in `pipeline_demo.py`. The bundle is trained on MuST-C release 2.0 dataset. The model  preserves the casing and punctuations in the transcript.

Here is a screen recording of how it works in streaming and non-streaming modes:

https://user-images.githubusercontent.com/8653221/154356521-fe84bdc1-fb0c-41bd-8729-9edbb3224a07.mov

Pull Request resolved: https://github.com/pytorch/audio/pull/2248

Reviewed By: hwangjeff

Differential Revision: D34282598

Pulled By: nateanl

fbshipit-source-id: 42ed7e2623031dfebd176ef0c6bfd70da3c897d4",Zhaoheng Ni,zni@fb.com,['examples/asr/emformer_rnnt/pipeline_demo.py'],False,16,2,2022
87d79889d8e8bf43a8f3d4a234ac151bc46f54e1,"Refactor torchscript consistency test in functional (#2246)

Summary:
In torchscript_consistency tests, the `func` in each test method only accepts one `tensor` as the argument, for the other arguments of `F.xyz` method, they need to be defined inside the `func`. If there is no `Tensor` argument in `F.xzy`, the tests use a `dummy` tensor which is not used anywhere. In this PR, we refactor ``_assert_consistency`` and ``_assert_consistency_complex`` to accept a tuple of inputs instead of just one `tensor`.

Pull Request resolved: https://github.com/pytorch/audio/pull/2246

Reviewed By: carolineechen

Differential Revision: D34273057

Pulled By: nateanl

fbshipit-source-id: a3900edb3b2c58638e513e1490279d771ebc3d0b",Zhaoheng Ni,zni@fb.com,['test/torchaudio_unittest/functional/torchscript_consistency_impl.py'],False,16,2,2022
fdea0a7c65ee80cafce82bb27a40fbc4a4c02bb0,"Refactor pipeline_demo script in emformer_rnnt recipes (#2239)

Summary:
- Use dictionary to select the `RNNTBundle` and the corresponding dataset.
- Use the dictionary's keys as choices in ArgumentParser

Pull Request resolved: https://github.com/pytorch/audio/pull/2239

Reviewed By: mthrok

Differential Revision: D34267070

Pulled By: nateanl

fbshipit-source-id: 99c7942d5c7c1518694e1ae02a55a7decd87c220",Zhaoheng Ni,zni@fb.com,['examples/asr/emformer_rnnt/pipeline_demo.py'],False,16,2,2022
e3b40d1cf4396f010f68eca3079b48352a592db3,"Refactor eval and pipeline_demo scripts in emformer_rnnt (#2238)

Summary:
- Add docstring to `eval.py` and `pipeline_demo.py` under `emformer_rnnt` directory.
- Refactor logger and ArgumentParser

Pull Request resolved: https://github.com/pytorch/audio/pull/2238

Reviewed By: mthrok

Differential Revision: D34267059

Pulled By: nateanl

fbshipit-source-id: 4b8d3d183ee7bc0ad71ce305cab87bfa90208b2e",Zhaoheng Ni,zni@fb.com,"['examples/asr/emformer_rnnt/eval.py', 'examples/asr/emformer_rnnt/pipeline_demo.py']",False,16,2,2022
eeba91dc564e404e477ad1cc7e7805870be846e1,"Add complex dtype support in functional autograd test (#2244)

Summary:
In autograd tests, to guarantee the precision, the dtype of Tensors are converted to `torch.float64` if they are real. However, the complex dtype is not considered. This PR adds `self.complex_dtype` support to the inputs.

Pull Request resolved: https://github.com/pytorch/audio/pull/2244

Reviewed By: mthrok

Differential Revision: D34272998

Pulled By: nateanl

fbshipit-source-id: e8698a74d7b8d99ee0fcb5f5cb5f2ffc8c80b9b5",Zhaoheng Ni,zni@fb.com,['test/torchaudio_unittest/functional/autograd_impl.py'],False,16,2,2022
c2decba4efd90194b0679a260104be4107791278,"Fix lm used for ctc decoder example (#2235)

Summary:
LM in example script was unintentionally changed to None when adding no LM support previously. this changes it back and is consistent with the WERs listed in the readme

Pull Request resolved: https://github.com/pytorch/audio/pull/2235

Reviewed By: nateanl

Differential Revision: D34273042

Pulled By: carolineechen

fbshipit-source-id: 824b1ce18195e39dc534b2ec9c5312bbe3bb1812",Caroline Chen,carolinechen@fb.com,['examples/asr/librispeech_ctc_decoder/inference.py'],False,16,2,2022
aac83fe55b6542e24fff54881993cf4bf8a8599d,"Add shebang lines to scripts in emformer_rnnt recipes (#2237)

Summary: Pull Request resolved: https://github.com/pytorch/audio/pull/2237

Reviewed By: mthrok

Differential Revision: D34267000

Pulled By: nateanl

fbshipit-source-id: 4c264aea6cf3fba5d8728d5fe60f9f471815852d",Zhaoheng Ni,zni@fb.com,"['examples/asr/emformer_rnnt/eval.py', 'examples/asr/emformer_rnnt/global_stats.py', 'examples/asr/emformer_rnnt/librispeech/train_spm.py', 'examples/asr/emformer_rnnt/mustc/train_spm.py', 'examples/asr/emformer_rnnt/pipeline_demo.py', 'examples/asr/emformer_rnnt/tedlium3/eval_pipeline.py', 'examples/asr/emformer_rnnt/tedlium3/train_spm.py', 'examples/asr/emformer_rnnt/train.py']",False,16,2,2022
99b5ef5ca0c3a48d8b703d0e1260aafe3334e844,"Add EMFORMER_RNNT_BASE_MUSTC bundle to torchaudio.prototype (#2241)

Summary:
This PR provides a RNNTBundle that is pre-trained on the MuST-C release v2.0 dataset.
The model preserves the casing and punctuations of the transcripts when training the SentencePiece model.

Here is the model performance on the dev and test sets of MuST-C 2.0:
|                   |          WER |
|:-----------------:|-------------:|
| dev               |       0.190  |
| tst-COMMON        |       0.213  |
| tst-HE            |       0.186  |

Pull Request resolved: https://github.com/pytorch/audio/pull/2241

Reviewed By: mthrok

Differential Revision: D34267792

Pulled By: nateanl

fbshipit-source-id: 67bca9f277e66d41a4530d01615f249b3cec7167",Zhaoheng Ni,zni@fb.com,"['docs/source/prototype.pipelines.rst', 'torchaudio/prototype/pipelines/__init__.py', 'torchaudio/prototype/pipelines/rnnt_pipeline.py']",False,16,2,2022
81f56f6498108aea70efedb4b050f16a4085cc2e,"Refactor ArgumentParser arguments in emformer_rnnt recipes (#2236)

Summary:
Replace underscore with dash in ArgumentParser's arguments.

Pull Request resolved: https://github.com/pytorch/audio/pull/2236

Reviewed By: mthrok

Differential Revision: D34266977

Pulled By: nateanl

fbshipit-source-id: ceacac12c04016a8dbf2a1a7d6bbcf65d4d53d21",Zhaoheng Ni,zni@fb.com,"['examples/asr/emformer_rnnt/README.md', 'examples/asr/emformer_rnnt/global_stats.py', 'examples/asr/emformer_rnnt/pipeline_demo.py']",True,16,2,2022
a007e922d34028270197c0549bf452b79499d039,"Fix prototype exclusion in release (#2225)

Summary:
This commit fixes the feature to exclude `torchaudio.prototype` module.

In `setup.py` there is a special case that is triggered if the commit is on release branch or release tag, that  excludes `torchaudio.prototype`. This was introduced to make it easy for release-related work.
It turned out that the submodules under `torchaudio.prototype`, such as `torchaudio.prototype.pipelines`, are not properly excluded from packaging.
These sub modules did not exist in previous releases, so it was not an issue.

**Note** This feature is triggered only in release branch, so the fix is not visible in the CI of this PR.
https://app.circleci.com/pipelines/github/pytorch/audio/9674/workflows/d0c9a6f1-8ca9-441a-a5f5-08926075fa39/jobs/553985?invite=true#step-104-193

The following outputs were observed when running it on local env.

* Before the change

```
$ BUILD_FFMPEG=0 BUILD_SOX=0 BUILD_CTC_DECODER=0 BUILD_RNNT=0 BUILD_KALDI=0 python setup.py clean bdist_wheel
```
```
-- Git branch: prototype-exclusion
-- Git SHA: 0af1edaa420c46be10292cbea7150c34ef80a0e1
-- Git tag: None
-- PyTorch dependency: torch
-- Building version 0.11.0+0af1eda
 --- Initializing submodules
 --- Initialized submodule
Excluding torchaudio.prototype from the package.
...
creating build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype
creating build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/io
copying torchaudio/prototype/io/streamer.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/io
copying torchaudio/prototype/io/__init__.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/io
creating build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/pipelines
copying torchaudio/prototype/pipelines/__init__.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/pipelines
copying torchaudio/prototype/pipelines/rnnt_pipeline.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/pipelines
creating build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/ctc_decoder
copying torchaudio/prototype/ctc_decoder/ctc_decoder.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/ctc_decoder
copying torchaudio/prototype/ctc_decoder/__init__.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/prototype/ctc_decoder
warning: build_py: byte-compiling is disabled, skipping.
```

* After the change

```
$ BUILD_FFMPEG=0 BUILD_SOX=0 BUILD_CTC_DECODER=0 BUILD_RNNT=0 BUILD_KALDI=0 python setup.py clean bdist_wheel
```

```
-- Git branch: prototype-exclusion
-- Git SHA: 0af1edaa420c46be10292cbea7150c34ef80a0e1
-- Git tag: None
-- PyTorch dependency: torch
-- Building version 0.11.0+0af1eda
 --- Initializing submodules
 --- Initialized submodule
Excluding torchaudio.prototype from the package.
...
creating build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2
copying torchaudio/models/wav2vec2/__init__.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2
copying torchaudio/models/wav2vec2/model.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2
copying torchaudio/models/wav2vec2/components.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2
creating build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2/utils
copying torchaudio/models/wav2vec2/utils/__init__.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2/utils
copying torchaudio/models/wav2vec2/utils/import_huggingface.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2/utils
copying torchaudio/models/wav2vec2/utils/import_fairseq.py -> build/lib.macosx-11.0-arm64-3.9/torchaudio/models/wav2vec2/utils
warning: build_py: byte-compiling is disabled, skipping.
```

Pull Request resolved: https://github.com/pytorch/audio/pull/2225

Reviewed By: nateanl

Differential Revision: D34257128

Pulled By: mthrok

fbshipit-source-id: a3d6eca5803356e5aa3fe0eda82f6a9f5affb8e8",moto,855818+mthrok@users.noreply.github.com,['setup.py'],False,16,2,2022
963905e42eb6d693a653e4e553c987c7ca90e4cd,"Improve ffmpeg library discovery (#2204)

Summary:
This commit fixes the issue with ffmpeg discovery at build time.
The original implementation had issues like.

1. Wrong usage of FindFFMPEG, which caused mixture of ffmpeg libraries from system directory and user directory.
2. The optional `FFMPEG_ROOT` variable was not set within cmake.

The issue 1 is problematic when a user does not have a permission to
modify the environment. For example, an old version of ffmpeg, which is
installed in a directory managed by the system (such as `/usr/local/lib`),
then there is no way to specify a path in which user installs a supported version
of ffmpeg.

This commit changes the behavior by first searching the library
in `FFMPEG_ROOT` environment variables, then
resorting to the original behavior of searching the custom paths with
system default path.

Also this commirt removes support for `libavresample`, which is deprecated in
ffmpeg 4 and removed in ffmpeg 5.

Pull Request resolved: https://github.com/pytorch/audio/pull/2204

Reviewed By: carolineechen

Differential Revision: D34225769

Pulled By: mthrok

fbshipit-source-id: 95b0bfaaef31e2e69e6df29f789010f48a48210b",moto,855818+mthrok@users.noreply.github.com,"['cmake/FindFFMPEG.cmake', 'third_party/CMakeLists.txt', 'torchaudio/csrc/CMakeLists.txt']",True,15,2,2022
8e3c6144e88dcbbbed6dec2b47da33fac2278820,"Update context building to not delay the inference (#2213)

Summary:
Updating the context cacher so that fetched audio chunk is used for inference immediately.

https://github.com/pytorch/audio/pull/2202#discussion_r802838174

Pull Request resolved: https://github.com/pytorch/audio/pull/2213

Reviewed By: hwangjeff

Differential Revision: D34235230

Pulled By: mthrok

fbshipit-source-id: 6e4aee7cca34ca81e40c0cb13497182f20f7f04e",moto,855818+mthrok@users.noreply.github.com,['examples/tutorials/online_asr_tutorial.py'],False,15,2,2022
411b5dcf807a6a85c656efd1dd19526e5e4488d2,"Adjust Conformer args (#2223)

Summary:
Orders and names Conformer's initializer args to be more consistent with Emformer's.

Pull Request resolved: https://github.com/pytorch/audio/pull/2223

Reviewed By: mthrok

Differential Revision: D34226177

Pulled By: hwangjeff

fbshipit-source-id: 111c7ff27841aeac302ea5f6f7b50cc72c570829",hwangjeff,iamjeffhwang@gmail.com,"['test/torchaudio_unittest/models/conformer/conformer_test_impl.py', 'torchaudio/models/conformer.py']",False,15,2,2022
bc0fcadb4295ce414b711beed79344ac4c73def2,"Add fixed random seed for Emformer RNN-T recipe test (#2220)

Summary:
Adds fixed random seed to Emformer RNN-T training recipe test.

Pull Request resolved: https://github.com/pytorch/audio/pull/2220

Reviewed By: nateanl

Differential Revision: D34180644

Pulled By: hwangjeff

fbshipit-source-id: 2dc364f3f7cd666fa490514ae460538231c097e9",hwangjeff,iamjeffhwang@gmail.com,['test/torchaudio_unittest/example/emformer_rnnt/test_librispeech_lightning.py'],False,11,2,2022
4d0095a528412cfec2a549204fc01d9ebb15df7a,"Add training recipe for Emformer RNNT trained on MuST-C release v2.0 dataset (#2219)

Summary:
- Add a MUSTC dataset under examples
- Add a lightning module for MuST-C dataset
- Refactor `train.py`, `eval.py`, and `global_stats.py` scripts

Pull Request resolved: https://github.com/pytorch/audio/pull/2219

Reviewed By: hwangjeff

Differential Revision: D34180466

Pulled By: nateanl

fbshipit-source-id: 9fc74ce7527da1a81dd0738e124428f9d516d164",nateanl,nizhaoheng@gmail.com,"['examples/asr/emformer_rnnt/README.md', 'examples/asr/emformer_rnnt/common.py', 'examples/asr/emformer_rnnt/eval.py', 'examples/asr/emformer_rnnt/global_stats.py', 'examples/asr/emformer_rnnt/mustc/dataset.py', 'examples/asr/emformer_rnnt/mustc/lightning.py', 'examples/asr/emformer_rnnt/mustc/train_spm.py', 'examples/asr/emformer_rnnt/tedlium3/train_spm.py', 'examples/asr/emformer_rnnt/train.py']",False,11,2,2022
825a59763d5a400a74d5802f16d8f29f66ea7b76,"Add SentencePiece model training script for LibriSpeech Emformer RNN-T (#2218)

Summary:
Adds SentencePiece model training script for LibriSpeech Emformer RNN-T example recipe; updates readme with references.

Pull Request resolved: https://github.com/pytorch/audio/pull/2218

Reviewed By: nateanl

Differential Revision: D34177295

Pulled By: hwangjeff

fbshipit-source-id: 9f32805af792fb8c6f834f2812e20104177a6c43",hwangjeff,iamjeffhwang@gmail.com,"['examples/asr/emformer_rnnt/README.md', 'examples/asr/emformer_rnnt/librispeech/train_spm.py']",False,11,2,2022
738d2f8e4a0fb883a84178f0985a97ba74b2b569,"Pass bias and dropout args to Conformer convolution block (#2215)

Summary:
Modifies `ConformerLayer` to pass `bias=True` (to be consistent with feedforward network defaults) and `dropout=dropout` (omission was a bug) to the convolution block.

Pull Request resolved: https://github.com/pytorch/audio/pull/2215

Reviewed By: carolineechen, nateanl

Differential Revision: D34164345

Pulled By: hwangjeff

fbshipit-source-id: 59fc804a1fe3b96e69e9fa5a2f9de94194d7bc55",hwangjeff,iamjeffhwang@gmail.com,['torchaudio/models/conformer.py'],False,11,2,2022
16d02a9efc802c96925349d2a659200bc93e84f1,"Refactor pipeline_demo.py to support variant EMFORMER_RNNT bundles (#2203)

Summary:
We refactored the demo script that can apply RNNT decoding using both `torchaudio.pipelines.EMFORMER_RNNT_BASE_LIBRISPEECH` and `torchaudio.prototype.pipelines.EMFORMER_RNNT_BASE_TEDLIUM3` in both streaming and non-streaming mode. (The first hypothesis prediction is streaming and the second one is non-streaming).

We convert each token id sequence to word pieces and then manually join the word pieces. This allows us to preserve leading whitespaces on output strings and therefore account for word breaks and continuations across token processor invocations, which is particularly useful when performing streaming ASR.

https://user-images.githubusercontent.com/8653221/153627956-f0806f18-3c1c-44df-ac07-ec2def58a0cf.mov

Pull Request resolved: https://github.com/pytorch/audio/pull/2203

Reviewed By: carolineechen

Differential Revision: D34006388

Pulled By: nateanl

fbshipit-source-id: 3d31173ee10cdab8a2f5802570e22b50fcce5632",nateanl,nizhaoheng@gmail.com,"['examples/asr/emformer_rnnt/README.md', 'examples/asr/emformer_rnnt/librispeech/pipeline_demo.py', 'examples/asr/emformer_rnnt/pipeline_demo.py']",False,11,2,2022
